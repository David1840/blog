[{"title":"音视频入门(一)","date":"2018-11-19T11:55:56.000Z","path":"2018/11/19/FFmpeg入门-一/","text":"Android开发两年，真的是感觉Android应用层开发没什么前景了，于是打算在网络安全，智能硬件，音视频这几个方向发展，考虑了一段时间，最终决定选择音视频。理由就不说了，既然选择了就要好好学习了，今天就开始音视频的第一篇博客，从一些音视频的基础知识开始。 音视频相关基础知识硬解和软解视频解码分为硬解和软解，所谓“软解”就是通过软件让 CPU 进行视频解码处理；而“硬解”是指不依赖于 CPU，通过专用的设备（子卡）单独完成视频解码，比如曾经的 VCD/DVD 解压卡、视频压缩卡都被冠以“硬解”的称号。现在实现高清硬解不需要额外的子卡，也不需要额外的投入，因为硬解码模块被整合在了 GPU 内部，而目前主流的显卡（包括整合显卡）都能支持硬解码。 “硬解”其实更需要软件的支持，只是基本不需要 CPU 参与运算，从而为系统节约了很多资源开销。 RGB 和 YUVRGB 指的是红绿蓝，应用还是很广泛的，比如显示器显示， bmp 文件格式中的像素值等；而 yuv 主要指亮度和两个色差信号，被称为 luminance 和 chrominance 他们的转化关系可以自己去查一下，我们视频里面基本上都是用yuv格式。 YUV文件格式又分很多种，如果算上存储格式，就更多了，比如 yuv444、 yuv422、 yuv411、 yuv420 等等，视频压缩用到的是 420 格式，这是 因为人眼对亮度更敏感些，对色度相对要差些。 帧 Frame简单的理解帧就是为视频或者动画中的每一张画面，而视频和动画特效就是由无数张画面组合而成，每一张画面都是一帧。 帧数 Frames帧数其实就是为帧生成数量的简称，可以解释为静止画面的数量 帧率 Frame Rate帧率(Frame rate) = 帧数(Frames)/时间(Time)，单位为帧每秒(f/s, frames per second, fps) 帧率是用于测量显示帧数的量度，测量单位为“每秒显示帧数”（ Frame per Second， FPS）或“赫兹”（ Hz），一般来说 FPS 用于描述视频、电子绘图或游戏每秒播放多少幀。 FPS（ Frame per Second）每秒显示帧数FPS 是图像领域中的定义，是指画面每秒传输帧数，通俗来讲就是指动画或视频的画面数。 FPS 是测量用于保存、显示动态视频的信息数量。每秒钟帧数愈多，所显示的动作就会愈流畅。 分辨率指视频成像产品所形成的图像大小或尺寸 刷新率屏幕每秒画面被刷新的次数，分为垂直刷新率和水平刷新率，一般我们提到的都是指垂直刷新率，以赫兹(Hz)为单位，刷新率越高，图像就越稳定，图像显示就越自然清晰。 编码格式编码的目的是压缩数据量，采用编码算法压缩冗余数据。常用的编码格式有: MPEG(MPEG-2 MPEG-4) H.26X(H.263 H.264/AVC H.265/HEVC)码率 也就是比特率，比特率是单位时间播放连续的媒体(如压缩的音频和视频)的比特数量。比特率越高，带宽消耗得越多。 DTS和PTS DTS: Decode Time Stamp,主要用于标示读入内存的比特流在什么时候开始送入解码器中进行解码。 PTS: Presentation Time Stamp,主要用于度量解码后的视频帧什么时候被显示出来。 FFmpeg FFmpeg 是一套可以用来记录、转换数字音频、视频，并能将其转化为流的开源计算机程序。","tags":[{"name":"音视频","slug":"音视频","permalink":"http://yoursite.com/tags/音视频/"}]},{"title":"Netty学习(一)","date":"2018-08-28T11:25:06.000Z","path":"2018/08/28/Netty学习-一/","text":"之前有做过消息推送相关的应用，使用的Netty框架，一直对这个框架非常感兴趣，也学习了一些它的原理，但感觉还是不够，所以想从今天开始对Netty框架写一个系列的使用及原理学习的博客，提升自己，也希望对看到这篇博客的朋友有所帮助，欢迎大家一起讨论。 我一直从事Android开发岗位，后台知识是自学，没有真正参加一个后台项目，所以在文中后台开发比较简单，如有问题欢迎指出，共同学习。 今天写第一篇博客，还是先从Netty框架的使用开始，我自己做了一个easyIM的简单Demo，可以实现简单的聊天功能，使用Protocol Buffer传输数据，以后会继续完善它的功能。 服务端代码地址 Github/easyImServer 客户端代码地址 Github/easyIm 一、服务端使用SpringBoot搭建的后台服务，比较简单。 创建服务端主逻辑12345678910111213141516171819202122232425262728fun start() &#123; val boss = NioEventLoopGroup() //用于处理服务器端接收客户端连接 val worker = NioEventLoopGroup() //进行网络通信（读写） try &#123; val port = nettyConfig.port //配置文件中配置端口 val bootStrap = ServerBootstrap() //辅助工具类，用于服务器通道配置 bootStrap.group(boss, worker) //绑定两个线程组 .channel(NioServerSocketChannel::class.java) //指定NIO的模式 .childHandler(ProtocolPipeline()) //配置具体的数据处理方式 .option(ChannelOption.SO_BACKLOG, 1024) //设置TCP缓冲区 .option(ChannelOption.SO_SNDBUF, 32 * 1024) //设置发送数据缓冲大小 .option(ChannelOption.SO_RCVBUF, 32 * 1024) //设置接受数据缓冲大小 .childOption(ChannelOption.SO_KEEPALIVE, true) //保持连接 .childOption(ChannelOption.TCP_NODELAY, true) //禁用Nagle算法，降低延迟 val future = bootStrap.bind(port).sync() logger.info(\"server start finish,the port is $port\") future.channel().closeFuture().sync() &#125; catch (e: InterruptedException) &#123; logger.error(\"server start error $&#123;e.message.toString()&#125;\") &#125; finally &#123; boss.shutdownGracefully() worker.shutdownGracefully() &#125; &#125; ProtocolPipeline数据处理1234567891011121314class ProtocolPipeline : ChannelInitializer&lt;SocketChannel&gt;() &#123; override fun initChannel(ch: SocketChannel) &#123; val pipeline = ch.pipeline() pipeline.addLast(\"send heartbeat\", IdleStateHandler(60, 0, 0, TimeUnit.SECONDS)) //心跳机制，读空闲，60S // 使用Protobuf，客户端和服务端必须保持一致 pipeline.addLast(ProtobufVarint32FrameDecoder()) pipeline.addLast(\"proto decoder\", ProtobufDecoder(IMessage.Protocol.getDefaultInstance())) pipeline.addLast(ProtobufVarint32LengthFieldPrepender()) pipeline.addLast(\"proto encoder\", ProtobufEncoder()) pipeline.addLast(ServerHandler()) //接收到数据后的处理逻辑 &#125;&#125; 传输数据数据使用protobuf， 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950syntax = \"proto2\";message Protocol &#123; optional ContentType contentType = 1; //类型 optional bytes content = 2; //内容&#125;//数据类型enum ContentType &#123; Register_INFO = 0; Register_UUID = 1; Message_INFO = 2; HEART_BEAT = 3;&#125;//发送给所有人还是发给一个人enum MessageType &#123; ALL = 0; ONE = 1;&#125;//注册，客户端发给服务端message Register &#123; optional string name = 1;&#125;//注册返回，服务端发给客户端message RegisterUUID &#123; optional string name = 1; optional string UUID = 2;&#125;// 消息类message Message &#123; optional MessageType type = 1; //个人还是全部 required string uuid = 2; //如果发送给个人，此项必填 optional string message = 3; //消息具体内容&#125;//客户端发送给服务端心跳包message HeartBeat_Ping&#123; required string time = 1; required string uuid = 2;&#125;//服务端返回客户端心跳包message HeartBeat_Pong&#123; required string time = 1; required string uuid = 2;&#125; ServerHandler处理逻辑1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class ServerHandler : ChannelInboundHandlerAdapter() &#123; private val logger = LoggerFactory.getLogger(ServerHandler::class.java) // 心跳丢失计数器 private var counter: Int = 0 @Throws(Exception::class) override fun channelActive(ctx: ChannelHandlerContext) &#123; logger.info(\"有人加入了！\") &#125; override fun channelInactive(ctx: ChannelHandlerContext) &#123; logger.info(\"有人退出\") super.channelInactive(ctx) ChannelMapController.removeByChannle(ctx.channel()) &#125; override fun userEventTriggered(ctx: ChannelHandlerContext, evt: Any?) &#123; if (evt is IdleStateEvent) &#123; if (counter &gt;= 3) &#123; // 连续丢失3个心跳包 (断开连接) ctx.channel()?.close()?.sync() ChannelMapController.removeByChannle(ctx.channel()) logger.info(\"已与Client断开连接\") &#125; else &#123; counter++ logger.info(\"丢失了第 $counter 个心跳包\") &#125; &#125; &#125; override fun channelRead(ctx: ChannelHandlerContext, msg: Any?) &#123; val protoMsg = msg as IMessage.Protocol //解析Protocol val contentType = protoMsg.contentType if (contentType == IMessage.ContentType.HEART_BEAT) &#123; counter = 0 logger.info(\"收到心跳包\") &#125; else &#123; handlerMessage(ctx, msg) &#125; &#125; private fun handlerMessage(ctx: ChannelHandlerContext, msg: IMessage.Protocol) &#123; counter = 0 val contentType = msg.contentType when (contentType) &#123; IMessage.ContentType.Message_INFO -&gt; &#123; val message: IMessage.Message = IMessage.Message.parseFrom(msg.content) if (message.type == IMessage.MessageType.ALL) &#123; logger.info(\"收到全员广播消息: $&#123;message.message&#125;\") ChannelMapController.sendMsgToAll(ProtocolFactory.getMessage(message.message, IMessage.MessageType.ONE, \"\"), ctx.channel()) &#125; else if (message.type == IMessage.MessageType.ONE) &#123; logger.info(\"收到个人消息: $&#123;message.message&#125;\") &#125; &#125; IMessage.ContentType.Register_INFO -&gt; &#123; logger.info(\"收到注册消息\") val register: IMessage.Register = IMessage.Register.parseFrom(msg.content) val uuid = UUIDGenerator.getUUID() ChannelMapController.put(uuid, ctx.channel()) ctx.writeAndFlush(ProtocolFactory.getUUIDProto(register.name, uuid)) &#125; else -&gt; &#123; &#125; &#125; &#125;&#125; 二、客户端创建连接12345678910111213141516fun start() &#123; mGroup = NioEventLoopGroup() try &#123; val b = Bootstrap() b.group(mGroup) .channel(NioSocketChannel::class.java) .remoteAddress(InetSocketAddress(\"172.18.157.43\", 1088)) .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 3000) .handler(ProtocolPipeline()) mChannelFuture = b.connect().awaitUninterruptibly() mChannelFuture!!.channel().closeFuture().sync() &#125; finally &#123; mGroup!!.shutdownGracefully().sync() &#125; &#125; ProtocolPipeline数据处理12345678910111213class ProtocolPipeline : ChannelInitializer&lt;SocketChannel&gt;() &#123; override fun initChannel(ch: SocketChannel) &#123; val pipeline = ch.pipeline() pipeline.addLast(\"send heartbeat\", IdleStateHandler(0, 30, 0, TimeUnit.SECONDS)) //写延时30秒，表示30秒没有写操作就会触发心跳机制 // 和服务端保持一致 pipeline.addLast(ProtobufVarint32FrameDecoder()) pipeline.addLast(\"proto decoder\", ProtobufDecoder(IMessage.Protocol.getDefaultInstance())) pipeline.addLast(ProtobufVarint32LengthFieldPrepender()) pipeline.addLast(\"proto encoder\", ProtobufEncoder()) pipeline.addLast(ClientHandler()) &#125;&#125; ClientHandler处理逻辑123456789101112131415161718192021222324252627282930313233343536373839class ClientHandler : SimpleChannelInboundHandler&lt;IMessage.Protocol&gt;() &#123; private val TAG = \"ClientHandler\" override fun channelActive(ctx: ChannelHandlerContext) &#123; SendMsgController.setChannelHandler(ctx) // 将channel保存在一个单例中 &#125; override fun channelRead0(p0: ChannelHandlerContext?, message: IMessage.Protocol) &#123; Log.e(TAG, \"get form server $message\") val contentType = message.contentType when (contentType) &#123; IMessage.ContentType.HEART_BEAT -&gt; &#123; &#125; IMessage.ContentType.Message_INFO -&gt; &#123; &#125; IMessage.ContentType.Register_UUID -&gt; &#123; &#125; else -&gt; &#123; &#125; &#125; &#125; override fun userEventTriggered(ctx: ChannelHandlerContext?, evt: Any?) &#123; if (evt is IdleStateEvent) &#123; if (evt.state() == IdleState.WRITER_IDLE) &#123; Log.d(TAG, \"send heartbeat!\") ctx?.writeAndFlush(ProtocolFactory.getHeartBeat()) &#125; else &#123; Log.d(TAG, \"其他超时：$&#123;evt.state()&#125;\") &#125; &#125; super.userEventTriggered(ctx, evt) &#125;&#125; 单例SendMsgController123456789101112131415161718192021222324252627282930object SendMsgController &#123; val TAG = SendMsgController::class.java.simpleName var channelHandlerContext: ChannelHandlerContext? = null fun setChannelHandler(channelHandlerContext: ChannelHandlerContext) &#123; this.channelHandlerContext = channelHandlerContext &#125; fun sendMsg(msg: IMessage.Protocol) &#123; if (channelHandlerContext != null) &#123; channelHandlerContext!!.writeAndFlush(msg) &#125; else &#123; Log.e(TAG, \"channelHandlerContext is null\") &#125; &#125; fun sendMsg(msg: IMessage.Protocol, future: ChannelFutureListener) &#123; if (channelHandlerContext != null) &#123; channelHandlerContext!!.writeAndFlush(msg).addListener(future) &#125; else &#123; Log.e(TAG, \"channelHandlerContext is null\") &#125; &#125; fun close() &#123; &#125;&#125; 在连接建立后就将channel保存在一个单例中，之后所有channel相关的操作都可以使用这个单例。","tags":[{"name":"Netty","slug":"Netty","permalink":"http://yoursite.com/tags/Netty/"}]},{"title":"Java内存分配及GC回收","date":"2018-08-24T05:46:57.000Z","path":"2018/08/24/Java内存分配及GC回收/","text":"最近要准备面试了，今天特意复习一下内存分配和GC相关知识。 Java内存管理 程序计数器程序计数器是用于存储每个线程下一步将执行的JVM指令，如该方法为native的，则程序计数器中不存储任何信息。 虚拟机栈一个线程的每个方法在执行的同时，都会创建一个栈帧（Statck Frame），栈帧中存储的有局部变量表、操作站、动态链接、方法出口等，当方法被调用时，栈帧在JVM栈中入栈，当方法执行完成时，栈帧出栈。 每个线程对应着一个虚拟机栈，因此虚拟机栈也是线程私有的。 堆区堆区是理解Java GC机制最重要的区域，没有之一。在JVM所管理的内存中，堆区是最大的一块，堆区也是Java GC机制所管理的主要内存区域，堆区由所有线程共享，在虚拟机启动时创建。堆区的存在是为了存储对象实例，原则上讲，所有的对象都在堆区上分配内存（不过现代技术里，也不是这么绝对的，也有栈上直接分配的）。 方法区在Sun JDK中这块区域对应的为PermanetGeneration，又称为永久代。方法区域存放了所加载的类的信息（名称、修饰符等）、类中的静态变量、类中定义为final类型的常量、类中的Field信息、类中的方法信息，当开发人员在程序中通过Class对象中的getName、isInterface等方法来获取信息时，这些数据都来源于方法区域，同时方法区域也是全局共享的，在一定的条件下它也会被GC，当方法区域需要使用的内存超过其允许的大小时，会抛出OutOfMemory的错误信息。 本地方法栈 JVM采用本地方法栈来支持native方法的执行，此区域用于存储每个native方法调用的状态。 运行时常量池 存放的为类中的固定的常量信息、方法和Field的引用信息等，其空间从方法区域中分配。JVM在加载类时会为每个class分配一个独立的常量池，但是运行时常量池中的字符串常量池是全局共享的。 直接内存直接内存并不是JVM管理的内存，可以这样理解，直接内存，就是JVM以外的机器内存，比如，你有4G的内存，JVM占用了1G，则其余的3G就是直接内存，JDK中有一种基于通道（Channel）和缓冲区（Buffer）的内存分配方式，将由C语言实现的native函数库分配在直接内存中，用存储在JVM堆中的DirectByteBuffer来引用。由于直接内存收到本机器内存的限制，所以也可能出现OutOfMemoryError的异常。 Java内存回收机制Java内存分配和回收的机制概括的说，就是：分代分配，分代回收。对象将根据存活的时间被分为：年轻代（Young Generation）、年老代（Old Generation）、永久代（Permanent Generation，也就是方法区）。 年轻代（Young Generation）对象被创建时，内存的分配首先发生在年轻代（大对象可以直接被创建在年老代），大部分的对象在创建后很快就不再使用，因此很快变得不可达，于是被年轻代的GC机制清理掉（IBM的研究表明，98%的对象都是很快消亡的），这个GC机制被称为Minor GC或叫Young GC。注意，Minor GC并不代表年轻代内存不足，它事实上只表示在Eden区上的GC。 新生代又被进一步划分为Eden(伊甸，初次创建)和Survivor(存活)区，Survivor区又分为Survivor1和Survivor2。这里为什么要将Young划分为Eden、Survivor1、Survivor2这三块，给出的解释是： “Young中的98%的对象都是死朝生夕死，所以将内存分为一块较大的Eden和两块较小的Survivor1、Survivor2，JVM默认分配是8:1:1，每次调用Eden和其中的Survivor1，当发生回收的时候，将Eden和Survivor1存活的对象复制到Survivor2，然后直接清理掉Eden和Survivor1的空间。” 内存分配过程如下图： 年老代（Old Generation）对象如果在年轻代存活了足够长的时间而没有被清理掉（即在几次Young GC后存活了下来），则会被复制到年老代，年老代的空间一般比年轻代大，能存放更多的对象，在年老代上发生的GC次数也比年轻代少。当年老代内存不足时，将执行Major GC，也叫 Full GC。 分代收集年轻代在年轻代中，使用“停止-复制”算法进行清理，将新生代内存分为2部分，1部分 Eden区较大，1部分Survivor比较小，并被划分为两个等量的部分。每次进行清理时，将Eden区和一个Survivor中仍然存活的对象拷贝到 另一个Survivor中，然后清理掉Eden和刚才的Survivor。 老年代老年代存储的对象比年轻代多得多，而且不乏大对象，对老年代进行内存清理时，如果使用停止-复制算法，则相当低效。一般，老年代用的算法是标记-整理算法，即：标记出仍然存活的对象（存在引用的），将所有存活的对象向一端移动，以保证内存的连续。 方法区（永久代）永久代的回收有两种：常量池中的常量，无用的类信息，常量的回收很简单，没有引用了就可以被回收。对于无用的类进行回收，必须保证3点： 类的所有实例都已经被回收 加载类的ClassLoader已经被回收 类对象的Class对象没有被引用（即没有通过反射引用该类的地方） 问题以下是在看其他博客时看到的一个挺不错的问题。原文链接 思考“GC是在什么时候，对什么东西，做了什么事情？” 什么时候从字面上翻译过来就是什么时候触发我们的GC机制 ① 在程序空闲的时候。这个回答无力吐槽 ② 程序不可预知的时候/手动调用system.gc()。关于手动调用不推荐 ③ Java堆内存不足时,GC会被调用。当应用线程在运行,并在运行过程中创建新对象,若这时内存空间不足,JVM就会强制地调用GC线程,以便回收内存用于新的分配。若GC一次之后仍不能满足内存分配的要求,JVM会再进行两次GC作进一步的尝试,若仍无法满足要求,则 JVM将报“out of memory”的错误,Java应用将停止。 什么东西从字面的意思翻译过来就是能被GC回收的对象都有哪些特征 ①超出作用域的对象/引用计数为空的对象。 引用计数算法：给对象中添加一个引用计数器，每当有一个地方引用它时，计数器就加1；当引用失效时，计数器值就减1；任何时刻计数器都为0的对象就是不可能再被使用的。 ②从GC Root开始搜索，且搜索不到的对象 跟搜索算法：以一系列名为 GC Root的对象作为起点，从这些节点开始往下搜索，搜索走过的路径称为引用链，当一个对象到GC Roots没有任何引用链的时候，则就证明此对象是不可用的。 这里会提出一个思考，什么样的对象能成为GC Root ： 虚拟机中的引用的对象、方法区中的类静态属性引用的对象、方法区中常量引用的对象、本地方法栈中jni的引用对象。 ③从root搜索不到，而且经过第一次标记、清理后，仍然没有复活的对象。 做什么不同年代、不同种类的收集器很多，不过总体的作用是删除不使用的对象，腾出内存空间。补充一些诸如停止其他线程执行、运行finalize等的说明。","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"内存","slug":"内存","permalink":"http://yoursite.com/tags/内存/"},{"name":"GC","slug":"GC","permalink":"http://yoursite.com/tags/GC/"}]},{"title":"Android中的ClassLoader简析","date":"2018-08-22T04:21:56.000Z","path":"2018/08/22/Android中的ClassLoader简析/","text":"我们知道Java中的ClassLoader可以加载jar文件和Class文件（本质是加载Class文件），这一点在Android中并不适用，因为无论是DVM还是ART它们加载的不再是Class文件，而是dex文件，这就需要重新设计ClassLoader相关类，我们先来学习ClassLoader的类型。 ClassLoader类型Android中的ClassLoader类型和Java中的ClassLoader类型类似，也分为两种类型，分别是系统ClassLoader和自定义ClassLoader。其中系统ClassLoader包括三种分别是BootClassLoader、PathClassLoader和DexClassLoader。 BootClassLoaderAndroid系统启动时会使用BootClassLoader来预加载常用类，与Java中的BootClassLoader不同，它并不是由C/C++代码实现，而是由Java实现的，BootClassLoade的代码如下所示。 1234567891011class BootClassLoader extends ClassLoader &#123; private static BootClassLoader instance; @FindBugsSuppressWarnings(\"DP_CREATE_CLASSLOADER_INSIDE_DO_PRIVILEGED\") public static synchronized BootClassLoader getInstance() &#123; if (instance == null) &#123; instance = new BootClassLoader(); &#125; return instance; &#125;...&#125; BootClassLoader是ClassLoader的内部类，并继承自ClassLoader。BootClassLoader是一个单例类，需要注意的是BootClassLoader的访问修饰符是默认的，只有在同一个包中才可以访问，因此我们在应用程序中是无法直接调用的。 PathClassLoaderAndroid系统使用PathClassLoader来加载系统类和应用程序的类，如果是加载非系统应用程序类，则会加载data/app/目录下的dex文件以及包含dex的apk文件或jar文件，不管是加载那种文件，最终都是要加载dex文件，在这里为了方便理解，我们将dex文件以及包含dex的apk文件或jar文件统称为dex相关文件。PathClassLoader不建议开发直接使用。来查看它的代码： 12345678public class PathClassLoader extends BaseDexClassLoader &#123; public PathClassLoader(String dexPath, ClassLoader parent) &#123; super(dexPath, null, null, parent); &#125; public PathClassLoader(String dexPath, String librarySearchPath, ClassLoader parent) &#123; super(dexPath, null, librarySearchPath, parent); &#125;&#125; PathClassLoader继承自BaseDexClassLoader，很明显PathClassLoader的方法实现都在BaseDexClassLoader中。从PathClassLoader的构造方法也可以看出它遵循了双亲委托模式。 PathClassLoader的构造方法有三个参数： dexPath：dex文件以及包含dex的apk文件或jar文件的路径集合，多个路径用文件分隔符分隔，默认文件分隔符为‘：’。 librarySearchPath：包含 C/C++ 库的路径集合，多个路径用文件分隔符分隔分割，可以为null。 parent：ClassLoader的parent。 DexClassLoaderDexClassLoader可以加载dex文件以及包含dex的apk文件或jar文件，也支持从SD卡进行加载，这也就意味着DexClassLoader可以在应用未安装的情况下加载dex相关文件。因此，它是热修复和插件化技术的基础。来查看它的代码，如下所示。 123456public class DexClassLoader extends BaseDexClassLoader &#123; public DexClassLoader(String dexPath, String optimizedDirectory, String librarySearchPath, ClassLoader parent) &#123; super(dexPath, new File(optimizedDirectory), librarySearchPath, parent); &#125;&#125; DexClassLoader构造方法的参数要比PathClassLoader多一个optimizedDirectory参数，参数optimizedDirectory代表什么呢？我们知道应用程序第一次被加载的时候，为了提高以后的启动速度和执行效率，Android系统会对dex相关文件做一定程度的优化，并生成一个ODEX文件，此后再运行这个应用程序的时候，只要加载优化过的ODEX文件就行了，省去了每次都要优化的时间，而参数optimizedDirectory就是代表存储ODEX文件的路径，这个路径必须是一个内部存储路径。PathClassLoader没有参数optimizedDirectory，这是因为PathClassLoader已经默认了参数optimizedDirectory的路径为：/data/dalvik-cache。DexClassLoader 也继承自BaseDexClassLoader ，方法实现也都在BaseDexClassLoader中。 ClassLoader的继承关系 可以看到上面一共有8个ClassLoader相关类，其中有一些和Java中的ClassLoader相关类十分类似，下面简单对它们进行介绍： ClassLoader是一个抽象类，其中定义了ClassLoader的主要功能。BootClassLoader是它的内部类。 SecureClassLoader类和JDK8中的SecureClassLoader类的代码是一样的，它继承了抽象类ClassLoader。SecureClassLoader并不是ClassLoader的实现类，而是拓展了ClassLoader类加入了权限方面的功能，加强了ClassLoader的安全性。 URLClassLoader类和JDK8中的URLClassLoader类的代码是一样的，它继承自SecureClassLoader，用来通过URl路径从jar文件和文件夹中加载类和资源。 InMemoryDexClassLoader是Android8.0新增的类加载器，继承自BaseDexClassLoader，用于加载内存中的dex文件。 BaseDexClassLoader继承自ClassLoader，是抽象类ClassLoader的具体实现类，PathClassLoader和DexClassLoader都继承它。 DexClassLoader介绍 DexClassLoader 之前，先来看看其官方描述： A class loader that loads classes from .jar and .apk filescontaining a classes.dex entry. This can be used to execute code notinstalled as part of an application. DexClassLoader 的源码里面只有一个构造方法，这里也是遵从双亲委托模型： 1234public DexClassLoader(String dexPath, String optimizedDirectory, String libraryPath, ClassLoader parent) &#123; super(dexPath, new File(optimizedDirectory), libraryPath, parent);&#125; 参数说明： String dexPath: 包含 class.dex 的 apk、jar 文件路径 ，多个用文件分隔符(默认是 ：)分隔 String optimizedDirectory : 用来缓存优化的 dex 文件的路径，即从 apk 或 jar 文件中提取出来的 dex 文件。该路径不可以为空，且应该是应用私有的，有读写权限的路径 String libraryPath: 存储 C/C++ 库文件的路径集 ClassLoader parent : 父类加载器，遵从双亲委托模型 PathClassLoader 和 DexClassLoader，但这两者都是对 BaseDexClassLoader 的一层简单封装，真正的实现都在 BaseClassLoader 内。因此简单分析一下BaseClassLoader。 BaseClassLoader先来看一眼 BaseClassLoader 的结构： 其中有个重要的字段 private final DexPathList pathList，其继承 ClassLoader 实现的 findClass()、findResource()均是基于 pathList 来实现的（省略了部分源码）： 12345678910111213141516171819@Overrideprotected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; List&lt;Throwable&gt; suppressedExceptions = new ArrayList&lt;Throwable&gt;(); Class c = pathList.findClass(name, suppressedExceptions); ... return c;&#125;@Overrideprotected URL findResource(String name) &#123; return pathList.findResource(name);&#125;@Overrideprotected Enumeration&lt;URL&gt; findResources(String name) &#123; return pathList.findResources(name);&#125;@Overridepublic String findLibrary(String name) &#123; return pathList.findLibrary(name);&#125; 那么重要的部分则是在 DexPathList 类的内部了，DexPathList 的构造方法也较为简单，和之前介绍的类似： 1234public DexPathList(ClassLoader definingContext, String dexPath, String libraryPath, File optimizedDirectory) &#123; ...&#125; 接受之前传进来的包含 dex 的 apk/jar/dex 的路径集、native 库的路径集和缓存优化的 dex 文件的路径，然后调用 makePathElements()方法生成一个Element[] dexElements数组，Element 是 DexPathList 的一个嵌套类，其有以下字段： 12345678static class Element &#123; private final File dir; private final boolean isDirectory; private final File zip; private final DexFile dexFile; private ZipFile zipFile; private boolean initialized;&#125; makePathElements() 是如何生成 Element 数组的？继续看源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344private static Element[] makePathElements(List&lt;File&gt; files, File optimizedDirectory, List&lt;IOException&gt; suppressedExceptions) &#123; List&lt;Element&gt; elements = new ArrayList&lt;&gt;(); // 遍历所有的包含 dex 的文件 for (File file : files) &#123; File zip = null; File dir = new File(\"\"); DexFile dex = null; String path = file.getPath(); String name = file.getName(); // 判断是不是 zip 类型 if (path.contains(zipSeparator)) &#123; String split[] = path.split(zipSeparator, 2); zip = new File(split[0]); dir = new File(split[1]); &#125; else if (file.isDirectory()) &#123; // 如果是文件夹,则直接添加 Element,这个一般是用来处理 native 库和资源文件 elements.add(new Element(file, true, null, null)); &#125; else if (file.isFile()) &#123; // 直接是 .dex 文件,而不是 zip/jar 文件(apk 归为 zip),则直接加载 dex 文件 if (name.endsWith(DEX_SUFFIX)) &#123; try &#123; dex = loadDexFile(file, optimizedDirectory); &#125; catch (IOException ex) &#123; System.logE(\"Unable to load dex file: \" + file, ex); &#125; &#125; else &#123; // 如果是 zip/jar 文件(apk 归为 zip),则将 file 值赋给 zip 字段,再加载 dex 文件 zip = file; try &#123; dex = loadDexFile(file, optimizedDirectory); &#125; catch (IOException suppressed) &#123; suppressedExceptions.add(suppressed); &#125; &#125; &#125; else &#123; System.logW(\"ClassLoader referenced unknown path: \" + file); &#125; if ((zip != null) || (dex != null)) &#123; elements.add(new Element(dir, false, zip, dex)); &#125; &#125; // list 转为数组 return elements.toArray(new Element[elements.size()]); oadDexFile()方法最终会调用 JNI 层的方法来读取 dex 文件，这里不再深入探究。接下来看以下 DexPathList 的 findClass()方法，其根据传入的完整的类名来加载对应的 class，源码如下： 1234567891011121314151617public Class findClass(String name, List&lt;Throwable&gt; suppressed) &#123; // 遍历 dexElements 数组，依次寻找对应的 class，一旦找到就终止遍历 for (Element element : dexElements) &#123; DexFile dex = element.dexFile; if (dex != null) &#123; Class clazz = dex.loadClassBinaryName(name, definingContext, suppressed); if (clazz != null) &#123; return clazz; &#125; &#125; &#125; // 抛出异常 if (dexElementsSuppressedExceptions != null) &#123; suppressed.addAll(Arrays.asList(dexElementsSuppressedExceptions)); &#125; return null;&#125; 这里有关于热修复实现的一个点，就是将补丁 dex 文件放到 dexElements 数组前面，这样在加载 class 时，优先找到补丁包中的 dex 文件，加载到 class 之后就不再寻找，从而原来的 apk 文件中同名的类就不会再使用，从而达到修复的目的。 至此，BaseDexClassLader 寻找 class 的路线就清晰了： 当传入一个完整的类名，调用 BaseDexClassLader 的 findClass(String name) 方法 BaseDexClassLader 的 findClass 方法会交给 DexPathList 的 findClass(String name, List suppressed)方法处理 在 DexPathList 方法的内部，会遍历 dexFile ，通过 DexFile的dex.loadClassBinaryName(name,definingContext, suppressed)来完成类的加载 需要注意到的是，在项目中使用 BaseDexClassLoader 或者 DexClassLoader 去加载某个 dex 或者 apk 中的 class 时，是无法调用 findClass()方法的，因为该方法是包访问权限，你需要调用 loadClass(String className)，该方法其实是 BaseDexClassLoader 的父类 ClassLoader 内实现的： 123456789101112131415161718192021222324public Class&lt;?&gt; loadClass(String className) throws ClassNotFoundException &#123; return loadClass(className, false);&#125;protected Class&lt;?&gt; loadClass(String className, boolean resolve) throws ClassNotFoundException &#123; Class&lt;?&gt; clazz = findLoadedClass(className); if (clazz == null) &#123; ClassNotFoundException suppressed = null; try &#123; clazz = parent.loadClass(className, false); &#125; catch (ClassNotFoundException e) &#123; suppressed = e; &#125; if (clazz == null) &#123; try &#123; clazz = findClass(className); &#125; catch (ClassNotFoundException e) &#123; e.addSuppressed(suppressed); throw e; &#125; &#125; &#125; return clazz;&#125; 上面这段代码结合之前提到的双亲委托模型就很好理解了，先查找当前的 ClassLoader 是否已经加载过，如果没有就交给父 ClassLoader 去加载，如果父 ClassLoader 没有找到，才调用当前 ClassLoader 来加载，此时就是调用上面分析的 findClass() 方法了。 出自： 小小亭长博客 刘望舒博客","tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"},{"name":"ClassLoader","slug":"ClassLoader","permalink":"http://yoursite.com/tags/ClassLoader/"}]},{"title":"Java中的ClassLoader简析","date":"2018-08-22T04:21:15.000Z","path":"2018/08/22/Java中的ClassLoader简析/","text":"插件化和热修复都是目前比较火热的技术，而它们的实现是基于ClassLoader，因此今天先来分析一下Java中的ClassLoader。 类加载子系统首先看一下Java虚拟机结构，如下图 从图中可以看到类加载子系统是在Class文件和JVM之间的桥梁，它的作用就是通过多种类加载器来查找和加载Class文件到Java虚拟机中。 Java中的类加载器主要有两种类型，系统类加载和自定义类加载器。其中系统类加载器包括3种，分别是Bootstrap ClassLoader、 Extensions ClassLoader和 Application ClassLoader。 Bootstrap ClassLoader用C/C++代码实现的加载器，用于加载Java虚拟机运行时所需要的系统类，如java.lang.*、java.uti.*等这些系统类，它们默认在$JAVA_HOME/jre/lib目录中，也可以通过启动Java虚拟机时指定-Xbootclasspath选项，来改变Bootstrap ClassLoader的加载目录。 Java虚拟机的启动就是通过 Bootstrap ClassLoader创建一个初始类来完成的。由于Bootstrap ClassLoader是使用C/C++语言实现的， 所以该加载器不能被Java代码访问到。需要注意的是Bootstrap ClassLoader并不继承java.lang.ClassLoader。 Extensions ClassLoader用于加载 Java 的拓展类 ，用来提供除了系统类之外的额外功能。也可以通过-Djava.ext.dirs选项添加和修改Extensions ClassLoader加载的路径。 Application ClassLoader负责加载当前应用程序Classpath目录下的所有jar和Class文件。也可以加载通过-Djava.class.path选项所指定的目录下的jar和Class文件。 Custom ClassLoader除了系统提供的类加载器，还可以自定义类加载器，自定义类加载器通过继承java.lang.ClassLoader类的方式来实现自己的类加载器，Extensions ClassLoader和Application ClassLoader也继承了java.lang.ClassLoader类。 ClassLoader的继承关系运行一个Java程序需要用到几种类型的类加载器呢？如下所示。 123456789public class ClassLoaderTest &#123; public static void main(String[] args) &#123; ClassLoader loader = ClassLoaderTest.class.getClassLoader(); while (loader != null) &#123; System.out.println(loader); loader = loader.getParent(); &#125; &#125;&#125; 打印结果如下所示。 12sun.misc.Launcher$AppClassLoader@75b84c92sun.misc.Launcher$ExtClassLoader@1b6d3586 第1行说明加载ClassLoaderTest的类加载器是AppClassLoader，第2行说明AppClassLoader的父加载器为ExtClassLoader。至于为何没有打印出ExtClassLoader的父加载器Bootstrap ClassLoader，这是因为Bootstrap ClassLoader是由C/C++编写的，并不是一个Java类，因此我们无法在Java代码中获取它的引用。 我们知道系统所提供的类加载器有3种类型，但是系统提供的ClassLoader相关类却不只3个。另外，AppClassLoader的父类加载器为ExtClassLoader，并不代表AppClassLoader继承自ExtClassLoader，ClassLoader的继承关系如下所示。 可以看到上图中共有5个ClassLoader相关类，下面简单对它们进行介绍： ClassLoader是一个抽象类，其中定义了ClassLoader的主要功能。 SecureClassLoader继承了抽象类ClassLoader，但SecureClassLoader并不是ClassLoader的实现类，而是拓展了ClassLoader类加入了权限方面的功能，加强了ClassLoader的安全性。 URLClassLoader继承自SecureClassLoader，用来通过URl路径从jar文件和文件夹中加载类和资源。 ExtClassLoader和AppClassLoader都继承自URLClassLoader，它们都是Launcher 的内部类，Launcher 是Java虚拟机的入口应用，ExtClassLoader和AppClassLoader都是在Launcher中进行初始化的。 双亲委托模式类加载器查找Class所采用的是双亲委托模式，所谓双亲委托模式就是首先判断该Class是否已经加载，如果没有则不是自身去查找而是委托给父加载器进行查找，这样依次的进行递归，直到委托到最顶层的Bootstrap ClassLoader，如果Bootstrap ClassLoader找到了该Class，就会直接返回，如果没找到，则继续依次向下查找，如果还没找到则最后会交由自身去查找。这样讲可能会有些抽象，来看下面的图。 我们知道类加载子系统用来查找和加载Class文件到 Java 虚拟机中，假设我们要加载一个位于D盘的Class文件，这时系统所提供的类加载器不能满足条件，这时就需要我们自定义类加载器继承自java.lang.ClassLoader，并复写它的findClass方法。加载D盘的Class文件步骤如下： 自定义类加载器首先从缓存中要查找Class文件是否已经加载，如果已经加载就返回该Class，如果没加载则委托给父加载器也就是App ClassLoader。 按照上图中红色虚线的方向递归步骤1。 一直委托到Bootstrap ClassLoader，如果Bootstrap ClassLoader在缓存中还没有查找到Class文件，则在自己的规定路径JAVA_HOME/jre/libr中或者-Xbootclasspath选项指定路径的jar包中进行查找，如果找到则返回该Class，如果没有则交给子加载器Extensions ClassLoader。 Extensions ClassLoader查找JAVA_HOME/jre/lib/ext目录下或者-Djava.ext.dirs选项指定目录下的jar包，如果找到就返回，找不到则交给App ClassLoader。 App ClassLoade查找Classpath目录下或者-Djava.ext.dirs选项所指定的目录下的jar包和Class文件，如果找到就返回，找不到交给我们自定义的类加载器，如果还找不到则抛出异常。 总的来说就是Class文件加载到类加载子系统后，先沿着图中红色虚线的方向自下而上进行委托，再沿着黑色虚线的方向自上而下进行查找，整个过程就是先上后下。 类加载的步骤在JDK8的源码中也得到了体现，来查看抽象类的ClassLoader方法，如下所示。 1234567891011121314151617181920212223242526272829303132protected Class&lt;?&gt; More ...loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; Class&lt;?&gt; c = findLoadedClass(name);//1 if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false);//2 &#125; else &#123; c = findBootstrapClassOrNull(name);//3 &#125; &#125; catch (ClassNotFoundException e) &#123; &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name);//4 // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 注释1处用来检查类是否已经加载，如果已经加载则后面的代码不会执行，最后会返回该类。没有加载则会接着向下执行。 注释2处，如果父类加载器不为null，则调用父类加载器的loadClass方法。如果父类加载器为null则调用注释3处的findBootstrapClassOrNull方法，这个方法内部调用了Native方法findLoadedClass0，findLoadedClass0方法中最终会用Bootstrap Classloader来查找类。如果Bootstrap Classloader仍没有找到该类，也就说明向上委托没有找到该类，则调用注释4处的findClass方法继续向下进行查找。 双亲委托模式的好处采取双亲委托模式主要有两点好处： 避免重复加载，如果已经加载过一次Class，就不需要再次加载，而是先从缓存中直接读取。 更加安全，如果不使用双亲委托模式，就可以自定义一个String类来替代系统的String类，这显然会造成安全隐患，采用双亲委托模式会使得系统的String类在Java虚拟机启动时就被加载，也就无法自定义String类来替代系统的String类，除非我们修改类加载器搜索类的默认算法。还有一点，只有两个类名一致并且被同一个类加载器加载的类，Java虚拟机才会认为它们是同一个类，想要骗过Java虚拟机显然不会那么容易。 自定义ClassLoader系统提供的类加载器只能够加载指定目录下的jar包和Class文件，如果想要加载网络上的或者是D盘某一文件中的jar包和Class文件则需要自定义ClassLoader。 实现自定义ClassLoader需要两个步骤： 定义一个自定义ClassLoade并继承抽象类ClassLoader。 复写findClass方法，并在findClass方法中调用defineClass方法。 下面我们就自定义一个ClassLoader用来加载位于D:\\lib的Class文件。 编写测试Class文件首先编写测试类并生成Class文件，如下所示。 123456package com.example;public class Jobs &#123; public void say() &#123; System.out.println(\"One more thing\"); &#125;&#125; 将这个Jobs.java放入到D:\\lib中，使用cmd命令进入D:\\lib目录中，执行Javac Jobs.java对该java文件进行编译，这时会在D:\\lib中生成Jobs.class。 编写自定义ClassLoader接下来编写自定义ClassLoader，如下所示。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import java.io.ByteArrayOutputStream;import java.io.File;import java.io.FileInputStream;import java.io.IOException;import java.io.InputStream;public class DiskClassLoader extends ClassLoader &#123; private String path; public DiskClassLoader(String path) &#123; this.path = path; &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; Class clazz = null; byte[] classData = loadClassData(name);//1 if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; clazz= defineClass(name, classData, 0, classData.length);//2 &#125; return clazz; &#125; private byte[] loadClassData(String name) &#123; String fileName = getFileName(name); File file = new File(path,fileName); InputStream in=null; ByteArrayOutputStream out=null; try &#123; in = new FileInputStream(file); out = new ByteArrayOutputStream(); byte[] buffer = new byte[1024]; int length=0; while ((length = in.read(buffer)) != -1) &#123; out.write(buffer, 0, length); &#125; return out.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; if(in!=null) &#123; in.close(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; try&#123; if(out!=null) &#123; out.close(); &#125; &#125;catch (IOException e)&#123; e.printStackTrace(); &#125; &#125; return null; &#125; private String getFileName(String name) &#123; int index = name.lastIndexOf('.'); if(index == -1)&#123;//如果没有找到'.'则直接在末尾添加.class return name+\".class\"; &#125;else&#123; return name.substring(index+1)+\".class\"; &#125; &#125;&#125; 这段代码有几点需要注意的，注释1处的loadClassData方法会获得class文件的字节码数组，并在注释2处调用defineClass方法将class文件的字节码数组转为Class类的实例。loadClassData方法中需要对流进行操作，关闭流的操作要放在finally语句块中，并且要对in和out分别采用try语句，如果in和out共同在一个try语句中，那么如果in.close()发生异常，则无法执行 out.close()。 最后我们来验证DiskClassLoader是否可用，代码如下所示。 123456789101112131415161718192021222324252627import java.lang.reflect.InvocationTargetException;import java.lang.reflect.Method;public class ClassLoaderTest &#123; public static void main(String[] args) &#123; DiskClassLoader diskClassLoader = new DiskClassLoader(\"D:\\\\lib\");//1 try &#123; Class c = diskClassLoader.loadClass(\"com.example.Jobs\");//2 if (c != null) &#123; try &#123; Object obj = c.newInstance(); System.out.println(obj.getClass().getClassLoader()); Method method = c.getDeclaredMethod(\"say\", null); method.invoke(obj, null);//3 &#125; catch (InstantiationException | IllegalAccessException | NoSuchMethodException | SecurityException | IllegalArgumentException | InvocationTargetException e) &#123; e.printStackTrace(); &#125; &#125; &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 注释1出创建DiskClassLoader并传入要加载类的路径，注释2处加载Class文件，需要注意的是，不要在项目工程中存在名为com.example.Jobs的Java文件，否则就不会使用DiskClassLoader来加载，而是AppClassLoader来负责加载，这样我们定义DiskClassLoader就变得毫无意义。接下来在注释3通过反射来调用Jobs的say方法，打印结果如下： 12com.example.DiskClassLoader@4554617cOne more thing 使用了DiskClassLoader来加载Class文件，say方法也正确执行，显然我们的目的达到了。","tags":[{"name":"ClassLoader","slug":"ClassLoader","permalink":"http://yoursite.com/tags/ClassLoader/"},{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"LinkedHashMap和LRU","date":"2018-08-20T06:28:05.000Z","path":"2018/08/20/LinkedHashMap和LRU/","text":"刚好正在研究Android中LruCache缓存，它的实现其实也是使用了LinkedHashMap，所以今天就专门写博客记录一下相关知识。 存储结构LinkedHashMap实际上是使用HashMap+双向链表，有关HashMap的详细知识就请看之前相关博客HashMap源码分析。我们知道HashMap是以散列表的形式存储数据的，LinkedHashMap继承HashMap，所以它也是使用散列表存储数据，但是，会有额外的“Linked”双向链表把所有的数据连接起来。为什么要这样做？HashMap是无序的，而加上双向链表，就将所有数据有序管理起来。具体如下图： 在HashMap的基础上多了befor和after字段，用来形成双向链表。 两个例子LinkedHashMap的核心就是存在存储顺序和可以实现LRU算法，所以下面我用两个例子证明这两种情况： 存储顺序1234567891011121314151617181920212223public class LinkedHashMapTest &#123; public static void main(String[] args) &#123; LinkedHashMap&lt;Integer, Integer&gt; map = new LinkedHashMap&lt;Integer, Integer&gt;(); for (int i = 0; i &lt; 10; i++) &#123;//按顺序放入1~9 map.put(i, i); &#125; System.out.println(\"原数据：\"+map.toString()); map.get(3); System.out.println(\"查询存在的某一个：\"+map.toString()); map.put(4, 4); System.out.println(\"插入已存在的某一个：\"+map.toString()); //直接调用已存在的toString方法，不然自己需要用迭代器实现 map.put(10, 10); System.out.println(\"插入一个原本没存在的：\"+map.toString()); &#125; //输出结果// 原数据：&#123;0=0, 1=1, 2=2, 3=3, 4=4, 5=5, 6=6, 7=7, 8=8, 9=9&#125;// 查询存在的某一个：&#123;0=0, 1=1, 2=2, 3=3, 4=4, 5=5, 6=6, 7=7, 8=8, 9=9&#125;// 插入已存在的某一个：&#123;0=0, 1=1, 2=2, 3=3, 4=4, 5=5, 6=6, 7=7, 8=8, 9=9&#125;// 插入一个原本没存在的：&#123;0=0, 1=1, 2=2, 3=3, 4=4, 5=5, 6=6, 7=7, 8=8, 9=9, 10=10&#125;&#125; 观察以上代码，其实它是符合先进先出的规则的，不管你怎么查询插入已存在的数据，不会对排序造成影响，如果有新插入的数据将会放在最尾部。 LRU启用LinkedHashMap的LRU规则是要使用它的三个参数的构造方法。 1234567891011121314151617/** * Constructs an empty &lt;tt&gt;LinkedHashMap&lt;/tt&gt; instance with the * specified initial capacity, load factor and ordering mode. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @param accessOrder the ordering mode - &lt;tt&gt;true&lt;/tt&gt; for * access-order, &lt;tt&gt;false&lt;/tt&gt; for insertion-order * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */ public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder;//是否开启LRU规则 &#125; 1234567891011121314151617181920212223public class LinkedHashMapTest &#123; public static void main(String[] args) &#123; LinkedHashMap&lt;Integer, Integer&gt; map = new LinkedHashMap&lt;Integer, Integer&gt;(20, 0.75f, true); for (int i = 0; i &lt; 10; i++) &#123;//按顺序放入1~9 map.put(i, i); &#125; System.out.println(\"原数据：\"+map.toString()); map.get(3); System.out.println(\"查询存在的某一个：\"+map.toString()); map.put(4, 4); System.out.println(\"插入已存在的某一个：\"+map.toString()); //直接调用已存在的toString方法，不然自己需要用迭代器实现 map.put(10, 10); System.out.println(\"插入一个原本没存在的：\"+map.toString()); &#125; //输出结果// 原数据：&#123;0=0, 1=1, 2=2, 3=3, 4=4, 5=5, 6=6, 7=7, 8=8, 9=9&#125;// 查询存在的某一个：&#123;0=0, 1=1, 2=2, 4=4, 5=5, 6=6, 7=7, 8=8, 9=9, 3=3&#125; //被访问（get）的3放到了最后面// 插入已存在的某一个：&#123;0=0, 1=1, 2=2, 5=5, 6=6, 7=7, 8=8, 9=9, 3=3, 4=4&#125;//被访问（put）的4放到了最后面// 插入一个原本没存在的：&#123;0=0, 1=1, 2=2, 5=5, 6=6, 7=7, 8=8, 9=9, 3=3, 4=4, 10=10&#125;//新增一个放到最后面&#125; 从上面可以看出，每当我get或者put一个已存在的数据，就会把这个数据放到双向链表的尾部，put一个新的数据也会放到双向链表的尾部。 实现原理构造函数12345678910111213141516171819202122232425262728public LinkedHashMap(int initialCapacity, float loadFactor) &#123; super(initialCapacity, loadFactor); accessOrder = false; &#125; public LinkedHashMap(int initialCapacity) &#123; super(initialCapacity); accessOrder = false; &#125; public LinkedHashMap() &#123; super(); accessOrder = false; &#125; public LinkedHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; super(m); accessOrder = false; &#125; public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder; &#125; 5个构造函数，可以设置容量和加载因子，且默认情况下是不开启LRU规则。 双向链表12345678910111213141516171819/** * HashMap.Node subclass for normal LinkedHashMap entries. */ static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; Entry&lt;K,V&gt; before, after; //指向前后节点 Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125; &#125; /** * The head (eldest) of the doubly linked list. */ transient LinkedHashMap.Entry&lt;K,V&gt; head;//双向链表头节点（最老） /** * The tail (youngest) of the doubly linked list. */ transient LinkedHashMap.Entry&lt;K,V&gt; tail;//双向列表尾节点（最新 LRU实现1234567891011121314151617181920212223242526272829303132333435363738void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // 把当前节点e放到双向链表尾部 LinkedHashMap.Entry&lt;K,V&gt; last; //accessOrder就是我们前面说的LRU控制，当它为true，同时e对象不是尾节点（如果访问尾节点就不需要设置，该方法就是把节点放置到尾节点） if (accessOrder &amp;&amp; (last = tail) != e) &#123; //用a和b分别记录该节点前面和后面的节点 LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; //释放当前节点与后节点的关系 p.after = null; //如果当前节点的前节点是空， if (b == null) //那么头节点就设置为a head = a; else //如果b不为null，那么b的后节点指向a b.after = a; //如果a节点不为空 if (a != null) //a的后节点指向b a.before = b; else //如果a为空，那么b就是尾节点 last = b; //如果尾节点为空 if (last == null) //那么p为头节点 head = p; else &#123; //否则就把p放到双向链表最尾处 p.before = last; last.after = p; &#125; //设置尾节点为P tail = p; //LinkedHashMap对象操作次数+1 ++modCount; &#125; &#125; 开启LRU后，put，get等方法都会调用这个函数来调整顺序。 12345678public V get(Object key) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return null; if (accessOrder)//如果启用了LRU规则 afterNodeAccess(e);//那么把该节点移到双向链表最后面 return e.value; &#125; 移除Eldest123protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false; &#125; LinkedHashMap有一个自带的移除最老数据的方法，默认返回false，我们可以在继承的时候重写这个方法，给定一个条件就可以控制存储在LinkedHashMap中的最老数据何时删除。触发这个删除机制，一般是在PUT一个数据进入的时候，但是LinkedHashMap并没有重写Put方法如何实现呢?在LinekdHashMap中，这个方法被包含在afterNodeInsertion()方法之中，而这个方法是重写了HashMap的，但是HashMap中并没有去实现它，所以在put的时候就会触发删除这个机制。","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"LRU","slug":"LRU","permalink":"http://yoursite.com/tags/LRU/"}]},{"title":"Android JNI学习","date":"2018-08-17T08:26:23.000Z","path":"2018/08/17/Android-JNI学习/","text":"JNI是Android中比较重要的一块知识，Java层与C/C++层进行调用的桥梁。所以今天就来学习一下JNI相关的知识。 JNI（Java Native Interface）JNI(Java Native Interface):java本地开发接口,JNI是一个协议，这个协议用来沟通java代码和外部的本地代码(c/c++),外部的c/c++代码也可以调用java代码。 ####为什么使用JNI？ 效率上 C/C++是本地语言，比java更高效 代码移植，如果之前用C语言开发过模块，可以复用已经存在的c代码 java反编译比C语言容易，一般加密算法都是用C语言编写，不容易被反编译 Java基本数据类型与C语言基本数据类型的对应 引用类型对应 JNI例子在AS3.0之后，AS对JNI的工程构建做了一些改动，可以非常方便地创建一个支持JNI的工程。 只要在创建工程的时候选择包括C++，其他都是正常的创建流程。 最终创建出的工程结构如下图： 默认生成一个stringFromJNI的方法，返回值为String类型。 生成的对应C代码为： 123456789101112#include &lt;jni.h&gt;#include &lt;string&gt;extern \"C\" JNIEXPORT jstringJNICALLJava_com_liuwei_ndktest_MainActivity_stringFromJNI( JNIEnv *env, jobject /* this */) &#123; std::string hello = \"Hello from C++\"; return env-&gt;NewStringUTF(hello.c_str());&#125; AS帮我们创建一个CPP文件夹用来保存我们的C／C++文件，CMakeList文件也帮我们创建成功，可以直接运行，极大方便了我们Android开发程序员。 C/C++中生成方法的名称规范为：Java _ 包名 _ 类名 _ 方法名 JNI传递一个数组上面AS自动生成的示例代码展示了JNI对String的操作，然后我们看一下JNI传递一个数组。 Java代码1public native void change(int[] arr); 生成C/C++代码在AS3.0之后也不用我们去自己写对应的C/C++代码，AS可以帮我们自动生成。 生成的模版代码： 12345678910extern \"C\" JNIEXPORT void JNICALLJava_com_liuwei_ndktest_MainActivity_change(JNIEnv *env, jobject instance, jintArray arr_) &#123; jint *arr = env-&gt;GetIntArrayElements(arr_, NULL); // TODO env-&gt;ReleaseIntArrayElements(arr_, arr, 0);&#125; 自动生成的代码连获取数组数据以及释放数组内存都帮我们写好了，简直了～ 然后我们做一些操作： 123456789101112131415extern \"C\" JNIEXPORT voidJNICALLJava_com_liuwei_ndktest_MainActivity_change(JNIEnv *env, jobject instance, jintArray arr_) &#123; int length = env-&gt;GetArrayLength(arr_); jint *arr = env-&gt;GetIntArrayElements(arr_, NULL); //每个数据加10 for (int i = 0; i &lt; length; ++i) &#123; *(arr + i) += 10; &#125; env-&gt;ReleaseIntArrayElements(arr_, arr, 0);&#125; 在Java中调用该方法 1234567int[] a = &#123;1, 2, 3, 4, 5, 6&#125;; change(a); for (int i = 0; i &lt; a.length; i++) &#123; Log.e(\"Test\", \"a\" + i + \"= \" + a[i]); &#125; 打印结果： 123456E/Test: a0= 11E/Test: a1= 12 a2= 13 a3= 14 a4= 15 a5= 16 每个数据都加了10，OK。 可以看到我们在这个方法中没有返回值，直接打印相同的数组，但实际结果也发生了改变，这是因为：传递数组其实是传递一个堆内存的数组首地址的引用过去，所以实际操作的是同一块内存，当调用完方法，不需要返回值,实际上参数内容已经改变，Android中很多操作硬件的方法都是这种C语言的传引用的思路。 在C++中调用java方法Java中： 12345public void sayJavaHi() &#123; Log.e(\"Test\", \"Hi Java\"); &#125; public native void say(); 我们调用say方法，然后由C调用sayJavaHi方法。 C++方法： 12345678910111213141516#include &lt;android/log.h&gt;#define LOG_TAG \"System.out\"#define LOGD(...) __android_log_print(ANDROID_LOG_DEBUG, LOG_TAG, __VA_ARGS__)extern \"C\" JNIEXPORT void JNICALLJava_com_liuwei_ndktest_MainActivity_say(JNIEnv *env, jobject instance) &#123; LOGD(\"debug日志\"); jclass jclass1 = env-&gt;FindClass(\"com/liuwei/ndktest/MainActivity\"); jmethodID methodID = env-&gt;GetMethodID(jclass1, \"sayJavaHi\", \"()V\"); env-&gt;CallVoidMethod(instance, methodID);&#125; 在C++方法中我们使用反射调用Java层的代码。 最终结果： 1208-17 20:30:05.637 8791-8791/com.liuwei.ndktest D/System.out: debug日志08-17 20:30:05.637 8791-8791/com.liuwei.ndktest E/Test: Hi Java 补充这里说一下GetMethodID方法，第一个参数：Java类对象；第二个参数：参数名（或方法名）；第三个参数：该参数（或方法）的签名。 比较麻烦的是第三个参数，JNI是以”(*)+”形式表示函数的有哪些传入参数，传入参数的类型，返回值的类型。”()” 中的字符表示传入参数，后面的则代表返回值。 例如： “()V” 就表示void Func(); “(II)V” 表示 void Func(int, int); “(Ljava/lang/String;Ljava/lang/String;)I”.表示 int Func(String,String) 另外数组类型的简写,则用”[“加上如表A所示的对应类型的简写形式进行表示就可以了，比如：[I 表示 int [];[L/java/lang/objects;表示Objects[],另外。引用类型（除基本类型的数组外）的标示最后都有个”;” 补充二对于这个方法参数中的JNIEnv* env参数的解释: JNIEnv类型实际上代表了Java环境，通过这个JNIEnv* 指针，就可以对Java端的代码进行操作。例如，创建Java对象，调用Java对象的方法，获取Java对象中的属性等等。JNIEnv的指针会被JNI传入到本地方法的实现函数中来对Java端的代码进行操作。 JNIEnv类中有很多函数可以用： NewObject:创建Java类中的对象 NewString:创建Java类中的String对象 NewArray:创建类型为Type的数组对象 GetField:获取类型为Type的字段 SetField:设置类型为Type的字段的值 GetStaticField:获取类型为Type的static的字段 SetStaticField:设置类型为Type的static的字段的值 CallMethod:调用返回类型为Type的方法 CallStaticMethod:调用返回值类型为Type的static方法 等许多的函数。","tags":[{"name":"JNI","slug":"JNI","permalink":"http://yoursite.com/tags/JNI/"},{"name":"NDK","slug":"NDK","permalink":"http://yoursite.com/tags/NDK/"}]},{"title":"Java动态代理","date":"2018-08-15T09:27:15.000Z","path":"2018/08/15/Java动态代理/","text":"Java动态代理在平时的开发中经常会听到，感觉挺高大上，但一直没有认真理解其中的原理，今天就来学习一下Java动态代理(最常见的retrofit框架就使用了动态代理)。 代理模式首先我们需要了解下什么是代理模式。代理模式是Java常用的设计模式，它的特征就是代理类与委托类有相同的接口。代理类主要负责为委托类预处理消息、过滤消息、把消息转发给委托类，以及事后处理消息等。 代理类与委托类之间通常会存在关联关系，一个代理类的对象与一个委托类的对象关联，代理类的对象本身并不真正实现服务，而是通过调用委托类的对象的相关方法，来提供特定的服务。简单的说就是，我们在访问实际对象时，是通过代理对象来访问的，代理模式就是在访问实际对象时引入一定程度的间接性，因为这种间接性，可以附加多种用途。 按照代理的创建时期，代理类可以被分为两类： 静态代理(由程序员创建代理类或特定工具自动生成源代码再对其编译。在程序运行前代理类的.class文件就已经存在了) 动态代理(在程序运行时运用反射机制动态创建而成) 静态代理根据上面代理模式的类图，来写一个简单的静态代理的例子。我这儿举一个比较粗糙的例子，假如一个班的同学要向老师交班费，但是都是通过班长把自己的钱转交给老师。这里，班长就是代理学生上交班费，班长就是学生的代理。 首先，我们创建一个Person接口。这个接口就是学生（被代理类），和班长（代理类）的公共接口，他们都有上交班费的行为。这样，学生上交班费就可以让班长来代理执行。 12345678/** * 创建Person接口 * @author Gonjan */public interface Person &#123; //上交班费 void giveMoney();&#125; Student类实现Person接口。Student可以具体实施上交班费的动作。 1234567891011public class Student implements Person &#123; private String name; public Student(String name) &#123; this.name = name; &#125; @Override public void giveMoney() &#123; System.out.println(name + \"上交班费50元\"); &#125;&#125; StudentsProxy类，这个类也实现了Person接口，但是还另外持有一个学生类对象，由于实现了Peson接口，同时持有一个学生对象，那么他可以代理学生类对象执行上交班费（执行giveMoney()方法）行为。 123456789101112131415161718192021/** * 学生代理类，也实现了Person接口，保存一个学生实体，这样既可以代理学生产生行为 * @author Gonjan * */public class StudentsProxy implements Person&#123; //被代理的学生 Student stu; public StudentsProxy(Person stu) &#123; // 只代理学生对象 if(stu.getClass() == Student.class) &#123; this.stu = (Student)stu; &#125; &#125; //代理上交班费，调用被代理学生的上交班费行为 public void giveMoney() &#123; stu.giveMoney(); &#125;&#125; 下面测试一下，看如何使用代理模式： 123456789101112public class StaticProxyTest &#123; public static void main(String[] args) &#123; //被代理的学生张三，他的班费上交有代理对象monitor（班长）完成 Person zhangsan = new Student(\"张三\"); //生成代理对象，并将张三传给代理对象 Person monitor = new StudentsProxy(zhangsan); //班长代理上交班费 monitor.giveMoney(); &#125;&#125; 运行结果： 这里并没有直接通过张三（被代理对象）来执行上交班费的行为，而是通过班长（代理对象）来代理执行了。这就是代理模式。 代理模式最主要的就是有一个公共接口（Person），一个具体的类（Student），一个代理类（StudentsProxy）,代理类持有具体类的实例，代为执行具体类实例方法。上面说到，代理模式就是在访问实际对象时引入一定程度的间接性，因为这种间接性，可以附加多种用途。这里的间接性就是指不直接调用实际对象的方法，那么我们在代理过程中就可以加上一些其他用途。就这个例子来说，加入班长在帮张三上交班费之前想要先反映一下张三最近学习有很大进步，通过代理模式很轻松就能办到： 1234567891011121314151617public class StudentsProxy implements Person&#123; //被代理的学生 Student stu; public StudentsProxy(Person stu) &#123; // 只代理学生对象 if(stu.getClass() == Student.class) &#123; this.stu = (Student)stu; &#125; &#125; //代理上交班费，调用被代理学生的上交班费行为 public void giveMoney() &#123; System.out.println(\"张三最近学习有进步！\"); stu.giveMoney(); &#125;&#125; 运行结果： 可以看到，只需要在代理类中帮张三上交班费之前，执行其他操作就可以了。这种操作，也是使用代理模式的一个很大的优点。最直白的就是在Spring中的面向切面编程（AOP），我们能在一个切点之前执行一些操作，在一个切点之后执行一些操作，这个切点就是一个个方法。这些方法所在类肯定就是被代理了，在代理过程中切入了一些其他操作。 动态代理代理类在程序运行时创建的代理方式被成为动态代理。 我们上面静态代理的例子中，代理类(studentProxy)是自己定义好的，在程序运行之前就已经编译完成。然而动态代理，代理类并不是在Java代码中定义的，而是在运行时根据我们在Java代码中的“指示”动态生成的。相比于静态代理， 动态代理的优势在于可以很方便的对代理类的函数进行统一的处理，而不用修改每个代理类中的方法。 比如说，想要在每个代理的方法前都加上一个处理方法： 12345public void giveMoney() &#123; //调用被代理方法前加入处理方法 beforeMethod(); stu.giveMoney(); &#125; 这里只有一个giveMoney方法，就写一次beforeMethod方法，但是如果出了giveMonney还有很多其他的方法，那就需要写很多次beforeMethod方法，麻烦。那看看下面动态代理如何实现。 动态代理的实现在java的java.lang.reflect包下提供了一个Proxy类和一个InvocationHandler接口，通过这个类和这个接口可以生成JDK动态代理类和动态代理对象。 还是上面静态代理的例子，班长需要帮学生代交班费。 首先是定义一个Person接口: 12345678/** * 创建Person接口 * @author Gonjan */public interface Person &#123; //上交班费 void giveMoney();&#125; 创建需要被代理的实际类： 1234567891011121314151617public class Student implements Person &#123; private String name; public Student(String name) &#123; this.name = name; &#125; @Override public void giveMoney() &#123; try &#123; //假设数钱花了一秒时间 Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(name + \"上交班费50元\"); &#125;&#125; 再定义一个检测方法执行时间的工具类，在任何方法执行前先调用start方法，执行后调用finsh方法，就可以计算出该方法的运行时间，这也是一个最简单的方法执行时间检测工具。 1234567891011121314public class MonitorUtil &#123; private static ThreadLocal&lt;Long&gt; tl = new ThreadLocal&lt;&gt;(); public static void start() &#123; tl.set(System.currentTimeMillis()); &#125; //结束时打印耗时 public static void finish(String methodName) &#123; long finishTime = System.currentTimeMillis(); System.out.println(methodName + \"方法耗时\" + (finishTime - tl.get()) + \"ms\"); &#125;&#125; 创建StuInvocationHandler类，实现InvocationHandler接口，这个类中持有一个被代理对象的实例target。InvocationHandler中有一个invoke方法，所有执行代理对象的方法都会被替换成执行invoke方法。 再在invoke方法中执行被代理对象target的相应方法。当然，在代理过程中，我们在真正执行被代理对象的方法前加入自己其他处理。这也是Spring中的AOP实现的主要原理，这里还涉及到一个很重要的关于java反射方面的基础知识。 123456789101112131415161718192021222324public class StuInvocationHandler&lt;T&gt; implements InvocationHandler &#123; //invocationHandler持有的被代理对象 T target; public StuInvocationHandler(T target) &#123; this.target = target; &#125; /** * proxy:代表动态代理对象 * method：代表正在执行的方法 * args：代表调用目标方法时传入的实参 */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(\"代理执行\" +method.getName() + \"方法\"); */ //代理过程中插入监测方法,计算该方法耗时 MonitorUtil.start(); Object result = method.invoke(target, args); MonitorUtil.finish(method.getName()); return result; &#125;&#125; 做完上面的工作后，我们就可以具体来创建动态代理对象了，我们使用简化的方式创建动态代理对象： 12345678910111213141516public class ProxyTest &#123; public static void main(String[] args) &#123; //创建一个实例对象，这个对象是被代理的对象 Person zhangsan = new Student(\"张三\"); //创建一个与代理对象相关联的InvocationHandler InvocationHandler stuHandler = new StuInvocationHandler&lt;Person&gt;(zhangsan); //创建一个代理对象stuProxy来代理zhangsan，代理对象的每个执行方法都会替换执行Invocation中的invoke方法 Person stuProxy = (Person) Proxy.newProxyInstance(Person.class.getClassLoader(), new Class&lt;?&gt;[]&#123;Person.class&#125;, stuHandler)； //代理执行上交班费的方法 stuProxy.giveMoney(); &#125;&#125; 我们执行这个ProxyTest类，先想一下，我们创建了一个需要被代理的学生张三，将zhangsan对象传给了stuHandler中，我们在创建代理对象stuProxy时，将stuHandler作为参数了的，上面也有说到所有执行代理对象的方法都会被替换成执行invoke方法，也就是说，最后执行的是StuInvocationHandler中的invoke方法。所以在看到下面的运行结果也就理所当然了。 上面说到，动态代理的优势在于可以很方便的对代理类的函数进行统一的处理，而不用修改每个代理类中的方法。是因为所有被代理执行的方法，都是通过在InvocationHandler中的invoke方法调用的，所以我们只要在invoke方法中统一处理，就可以对所有被代理的方法进行相同的操作了。例如，这里的方法计时，所有的被代理对象执行的方法都会被计时，然而我只做了很少的代码量。 动态代理的过程，代理对象和被代理对象的关系不像静态代理那样一目了然，清晰明了。因为动态代理的过程中，我们并没有实际看到代理类，也没有很清晰地的看到代理类的具体样子，而且动态代理中被代理对象和代理对象是通过InvocationHandler来完成的代理过程的，其中具体是怎样操作的，为什么代理对象执行的方法都会通过InvocationHandler中的invoke方法来执行。带着这些问题，我们就需要对java动态代理的源码进行简要的分析，弄清楚其中缘由。 动态代理原理分析上面我们利用Proxy类的newProxyInstance方法创建了一个动态代理对象，查看该方法的源码，发现它只是封装了创建动态代理类的步骤： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; Objects.requireNonNull(h); final Class&lt;?&gt;[] intfs = interfaces.clone(); final SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; checkProxyAccess(Reflection.getCallerClass(), loader, intfs); &#125; /* * Look up or generate the designated proxy class. */ Class&lt;?&gt; cl = getProxyClass0(loader, intfs); /* * Invoke its constructor with the designated invocation handler. */ try &#123; if (sm != null) &#123; checkNewProxyPermission(Reflection.getCallerClass(), cl); &#125; final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; if (!Modifier.isPublic(cl.getModifiers())) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;); &#125; return cons.newInstance(new Object[]&#123;h&#125;); &#125; catch (IllegalAccessException|InstantiationException e) &#123; throw new InternalError(e.toString(), e); &#125; catch (InvocationTargetException e) &#123; Throwable t = e.getCause(); if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new InternalError(t.toString(), t); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString(), e); &#125; &#125; 其实，我们最应该关注的是 Class&lt;?&gt; cl = getProxyClass0(loader, intfs);这句，这里产生了代理类，后面代码中的构造器也是通过这里产生的类来获得，可以看出，这个类的产生就是整个动态代理的关键，由于是动态生成的类文件，我这里不具体进入分析如何产生的这个类文件，只需要知道这个类文件时缓存在java虚拟机中的，我们可以通过下面的方法将其打印到文件里面，一睹真容： 123456789byte[] classFile = ProxyGenerator.generateProxyClass(\"$Proxy0\", Student.class.getInterfaces()); String path = \"G:/javacode/javase/Test/bin/proxy/StuProxy.class\"; try(FileOutputStream fos = new FileOutputStream(path)) &#123; fos.write(classFile); fos.flush(); System.out.println(\"代理类class文件写入成功\"); &#125; catch (Exception e) &#123; System.out.println(\"写文件错误\"); &#125; 对这个class文件进行反编译，我们看看jdk为我们生成了什么样的内容： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.lang.reflect.UndeclaredThrowableException;import proxy.Person;public final class $Proxy0 extends Proxy implements Person&#123; private static Method m1; private static Method m2; private static Method m3; private static Method m0; /** *注意这里是生成代理类的构造方法，方法参数为InvocationHandler类型，看到这，是不是就有点明白 *为何代理对象调用方法都是执行InvocationHandler中的invoke方法，而InvocationHandler又持有一个 *被代理对象的实例，不禁会想难道是....？ 没错，就是你想的那样。 * *super(paramInvocationHandler)，是调用父类Proxy的构造方法。 *父类持有：protected InvocationHandler h; *Proxy构造方法： * protected Proxy(InvocationHandler h) &#123; * Objects.requireNonNull(h); * this.h = h; * &#125; * */ public $Proxy0(InvocationHandler paramInvocationHandler) throws &#123; super(paramInvocationHandler); &#125; //这个静态块本来是在最后的，我把它拿到前面来，方便描述 static &#123; try &#123; //看看这儿静态块儿里面有什么，是不是找到了giveMoney方法。请记住giveMoney通过反射得到的名字m3，其他的先不管 m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", new Class[] &#123; Class.forName(\"java.lang.Object\") &#125;); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\", new Class[0]); m3 = Class.forName(\"proxy.Person\").getMethod(\"giveMoney\", new Class[0]); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\", new Class[0]); return; &#125; catch (NoSuchMethodException localNoSuchMethodException) &#123; throw new NoSuchMethodError(localNoSuchMethodException.getMessage()); &#125; catch (ClassNotFoundException localClassNotFoundException) &#123; throw new NoClassDefFoundError(localClassNotFoundException.getMessage()); &#125; &#125; /** * *这里调用代理对象的giveMoney方法，直接就调用了InvocationHandler中的invoke方法，并把m3传了进去。 *this.h.invoke(this, m3, null);这里简单，明了。 *来，再想想，代理对象持有一个InvocationHandler对象，InvocationHandler对象持有一个被代理的对象， *再联系到InvacationHandler中的invoke方法。嗯，就是这样。 */ public final void giveMoney() throws &#123; try &#123; this.h.invoke(this, m3, null); return; &#125; catch (Error|RuntimeException localError) &#123; throw localError; &#125; catch (Throwable localThrowable) &#123; throw new UndeclaredThrowableException(localThrowable); &#125; &#125; //注意，这里为了节省篇幅，省去了toString，hashCode、equals方法的内容。原理和giveMoney方法一毛一样。&#125; jdk为我们的生成了一个叫$Proxy0（这个名字后面的0是编号，有多个代理类会一次递增）的代理类，这个类文件时放在内存中的，我们在创建代理对象时，就是通过反射获得这个类的构造方法，然后创建的代理实例。通过对这个生成的代理类源码的查看，我们很容易能看出，动态代理实现的具体过程。 我们可以对InvocationHandler看做一个中介类，中介类持有一个被代理对象，在invoke方法中调用了被代理对象的相应方法。通过聚合方式持有被代理对象的引用，把外部对invoke的调用最终都转为对被代理对象的调用。 代理类调用自己方法时，通过自身持有的中介类对象来调用中介类对象的invoke方法，从而达到代理执行被代理对象的方法。也就是说，动态代理通过中介类实现了具体的代理功能。 总结生成的代理类：$Proxy0 extends Proxy implements Person，我们看到代理类继承了Proxy类，所以也就决定了java动态代理只能对接口进行代理，Java的继承机制注定了这些动态代理类们无法实现对class的动态代理。上面的动态代理的例子，其实就是AOP的一个简单实现了，在目标对象的方法执行之前和执行之后进行了处理，对方法耗时统计。Spring的AOP实现其实也是用了Proxy和InvocationHandler这两个东西的。 转自：Gonjian","tags":[]},{"title":"ConcurrentHashMap源码分析","date":"2018-08-13T11:36:53.000Z","path":"2018/08/13/ConcurrentHashMap源码分析/","text":"HashMap、HashTable是JDK中提供的两种的容器，在平时开发中经常会使用到。但在并发编程中，HashMap可能会导致程序死循环，而HashTable就是在所有涉及对该哈希表操作的方法上都加上了synchronized关键字，进行加锁操作。这么做实现了线程安全，但是效率非常低。因此就有了ConcurrentHashMap。 JDK1.7在JDK1.7中ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。 Segment是一个可重入锁，HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个SegMent数组，Segment的结构和HashMap类似，是一种数组和链表结构。一个Segment里包含了一个HashEntry数组，每个HashEntry是一个链表结构的元素，每个Segment守护着一个HashEntry数组里的元素，当对HashEntry的数据进行修改时，必须先获得与它对应的Segment锁。 get先经过一次再散列，然后使用这个散列值通过散列运算定位到Segment，再通过散列算法定位到元素。get操作的高效之处在于get方法将要使用的共享变量都定义成volatile类型。 put当执行put方法插入数据时，根据key的hash值，在Segment数组中找到相应的位置，如果相应位置的Segment还未初始化，则通过CAS进行赋值，接着执行Segment对象的put方法通过加锁机制插入数据，实现如下： 线程A和线程B同时执行相同Segment对象的put方法 线程A执行tryLock()方法成功获取锁，则把HashEntry对象插入到相应的位置； 线程B获取锁失败，则执行scanAndLockForPut()方法，在scanAndLockForPut方法中，会通过重复执行tryLock()方法尝试获取锁，在多处理器环境下，重复次数为64，单处理器重复次数为1，当执行tryLock()方法的次数超过上限时，则执行lock()方法挂起线程B； 当线程A执行完插入操作时，会通过unlock()方法释放锁，接着唤醒线程B继续执行； sizeSegment中的全局变量count是一个volatile变量。先尝试两次通过不锁住Segment的方式统计各个Segment大小，如果两次统计结果相同，则说明计算出的元素个数是准确的。如果两次结果不同，则给每个Segment加锁，在进行一次计算。 JDK1.8在JDK1.8中已经抛弃了Segment分段锁机制，利用CAS+Synchronized来保证并发更新的安全，底层采用数组+链表+红黑树的存储结构。 1、重要属性sizeCtl这个属性在ConcurrentHashMap中出镜率很高，因为它是一个控制标识符，在不同的地方有不同用途，而且它的取值不同，也代表不同的含义。 负数代表正在进行初始化或扩容操作 -1代表正在初始化 -N 表示有N-1个线程正在进行扩容操作 正数或0代表hash表还没有被初始化，这个数值表示初始化或下一次进行扩容的大小，这一点类似于扩容阈值的概念。还后面可以看到，它的值始终是当前ConcurrentHashMap容量的0.75倍，这与loadfactor是对应的。 1234567891011121314151617181920212223242526272829303132333435363738 /** * 盛装Node元素的数组 它的大小是2的整数次幂 * Size is always a power of two. Accessed directly by iterators. */ transient volatile Node&lt;K,V&gt;[] table;/** * Table initialization and resizing control. When negative, the * table is being initialized or resized: -1 for initialization, * else -(1 + the number of active resizing threads). Otherwise, * when table is null, holds the initial table size to use upon * creation, or 0 for default. After initialization, holds the * next element count value upon which to resize the table. hash表初始化或扩容时的一个控制位标识量。 负数代表正在进行初始化或扩容操作 -1代表正在初始化 -N 表示有N-1个线程正在进行扩容操作 正数或0代表hash表还没有被初始化，这个数值表示初始化或下一次进行扩容的大小 */ private transient volatile int sizeCtl; // 以下两个是用来控制扩容的时候 单线程进入的变量 /** * The number of bits used for generation stamp in sizeCtl. * Must be at least 6 for 32bit arrays. */ private static int RESIZE_STAMP_BITS = 16;/** * The bit shift for recording size stamp in sizeCtl. */ private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS; /* * Encodings for Node hash fields. See above for explanation. */ static final int MOVED = -1; // hash值是-1，表示这是一个forwardNode节点 static final int TREEBIN = -2; // hash值是-2 表示这时一个TreeBin节点 2、重要的类NodeNode是最核心的内部类，它包装了key-value键值对，所有插入ConcurrentHashMap的数据都包装在这里面。它与HashMap中的定义很相似，但是但是有一些差别它对value和next属性设置了volatile同步锁(与JDK7的Segment相同)，它不允许调用setValue方法直接改变Node的value域，它增加了find方法辅助map.get()方法。 1234567static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; ......&#125; 其中value和next都用volatile修饰，保证并发的可见性。 TreeNode树节点类，另外一个核心的数据结构。当链表长度过长的时候，会转换为TreeNode。但是与HashMap不相同的是，它并不是直接转换为红黑树，而是把这些结点包装成TreeNode放在TreeBin对象中，由TreeBin完成对红黑树的包装。而且TreeNode在ConcurrentHashMap集成自Node类，而并非HashMap中的集成自LinkedHashMap.Entry&lt;K,V&gt;类，也就是说TreeNode带有next指针，这样做的目的是方便基于TreeBin的访问。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Nodes for use in TreeBins */ static final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next, TreeNode&lt;K,V&gt; parent) &#123; super(hash, key, val, next); this.parent = parent; &#125; Node&lt;K,V&gt; find(int h, Object k) &#123; return findTreeNode(h, k, null); &#125; /** * Returns the TreeNode (or null if not found) for the given key * starting at given root. */ final TreeNode&lt;K,V&gt; findTreeNode(int h, Object k, Class&lt;?&gt; kc) &#123; if (k != null) &#123; TreeNode&lt;K,V&gt; p = this; do &#123; int ph, dir; K pk; TreeNode&lt;K,V&gt; q; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right; if ((ph = p.hash) &gt; h) p = pl; else if (ph &lt; h) p = pr; else if ((pk = p.key) == k || (pk != null &amp;&amp; k.equals(pk))) return p; else if (pl == null) p = pr; else if (pr == null) p = pl; else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; (dir = compareComparables(kc, k, pk)) != 0) p = (dir &lt; 0) ? pl : pr; else if ((q = pr.findTreeNode(h, k, kc)) != null) return q; else p = pl; &#125; while (p != null); &#125; return null; &#125; &#125; TreeBin这个类并不负责包装用户的key、value信息，而是包装的很多TreeNode节点。它代替了TreeNode的根节点，也就是说在实际的ConcurrentHashMap“数组”中，存放的是TreeBin对象，而不是TreeNode对象，这是与HashMap的区别。另外这个类还带有了读写锁。 123456789101112131415161718/** * TreeNodes used at the heads of bins. TreeBins do not hold user * keys or values, but instead point to list of TreeNodes and * their root. They also maintain a parasitic read-write lock * forcing writers (who hold bin lock) to wait for readers (who do * not) to complete before tree restructuring operations. */ static final class TreeBin&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; root; volatile TreeNode&lt;K,V&gt; first; volatile Thread waiter; volatile int lockState; // values for lockState static final int WRITER = 1; // set while holding write lock static final int WAITER = 2; // set when waiting for write lock static final int READER = 4; // increment value for setting read lock ......&#125; ForwardingNode一个用于连接两个table的节点类。它包含一个nextTable指针，用于指向下一张表。而且这个节点的key value next指针全部为null，它的hash值为-1. 这里面定义的find的方法是从nextTable里进行查询节点，而不是以自身为头节点进行查找。 1234567891011121314151617181920212223242526272829303132 /** * Encapsulates traversal for methods such as containsValue; also * serves as a base class for other iterators and spliterators. * * Method advance visits once each still-valid node that was * reachable upon iterator construction. It might miss some that * were added to a bin after the bin was visited, which is OK wrt * consistency guarantees. Maintaining this property in the face * of possible ongoing resizes requires a fair amount of * bookkeeping state that is difficult to optimize away amidst * volatile accesses. Even so, traversal maintains reasonable * throughput. * * Normally, iteration proceeds bin-by-bin traversing lists. * However, if the table has been resized, then all future steps * must traverse both the bin at the current index as well as at * (index + baseSize); and so on for further resizings. To * paranoically cope with potential sharing by users of iterators * across threads, iteration terminates if a bounds checks fails * for a table read. */ static class Traverser&lt;K,V&gt; &#123; Node&lt;K,V&gt;[] tab; // current table; updated if resized Node&lt;K,V&gt; next; // the next entry to use TableStack&lt;K,V&gt; stack, spare; // to save/restore on ForwardingNodes int index; // index of bin to use next int baseIndex; // current index of initial table int baseLimit; // index bound for initial table final int baseSize; // initial table size ......&#125; 3、核心方法ConcurrentHashMap定义了三个原子操作，用于对指定位置的节点进行操作。正是这些原子操作保证了ConcurrentHashMap的线程安全。 12345678910111213 //获得在i位置上的Node节点 static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE); &#125;//利用CAS算法设置i位置上的Node节点。之所以能实现并发是因为他指定了原来这个节点的值是多少 static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v); &#125;//利用volatile方法设置节点位置的值 static final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) &#123; U.putObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, v); &#125; 3.1 初始化对于ConcurrentHashMap来说，调用它的构造方法仅仅是设置了一些参数而已。而整个table的初始化是在向ConcurrentHashMap中插入元素的时候发生的。如调用put、computeIfAbsent、compute、merge等方法的时候，调用时机是检查table==null。 1234567891011121314151617181920212223242526/** * Initializes table, using the size recorded in sizeCtl. */ private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; //sizeCtl表示有其他线程正在进行初始化操作，把线程挂起。对于table的初始化工作，只能有一个线程在进行。 if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123;//利用CAS方法把sizectl的值置为-1 表示本线程正在进行初始化 try &#123; if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(\"unchecked\") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; sc = n - (n &gt;&gt;&gt; 2); //相当于0.75*n 设置一个扩容的阈值 &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab; &#125; 3.2 扩容 如果新增节点之后，所在链表的元素个数达到了阈值 8，则会调用treeifyBin方法把链表转换成红黑树,不过在结构转换之前，会对数组长度进行判断,如果数组长度n小于阈值MIN_TREEIFY_CAPACITY，默认是64，则会调用tryPresize方法把数组长度扩大到原来的两倍，并触发transfer方法，重新调整节点的位置。 新增节点之后，会调用addCount方法记录元素个数，并检查是否需要进行扩容，当数组元素个数达到阈值时，会触发transfer方法，重新调整节点的位置。 transfer实现整个扩容操作分为两个部分： 第一部分是构建一个nextTable,它的容量是原来的两倍，这个操作是单线程完成的。这个单线程的保证是通过RESIZE_STAMP_SHIFT这个常量经过一次运算来保证的； 第二个部分就是将原来table中的元素复制到nextTable中，这里允许多线程进行操作。 先来看一下单线程是如何完成的，它的大体思想就是遍历、复制的过程。首先根据运算得到需要遍历的次数i，然后利用tabAt方法获得i位置的元素： 如果这个位置为空，就在原table中的i位置放入forwardNode节点，这个也是触发并发扩容的关键点； 如果这个位置是Node节点（fh&gt;=0），如果它是一个链表的头节点，就构造一个反序链表，把他们分别放在nextTable的i和i+n的位置上 如果这个位置是TreeBin节点（fh&lt;0），也做一个反序处理，并且判断是否需要untreefi，把处理的结果分别放在nextTable的i和i+n的位置上 遍历过所有的节点以后就完成了复制工作，这时让nextTable作为新的table，并且更新sizeCtl为新容量的0.75倍 ，完成扩容。 再看一下多线程是如何完成的： 如果遍历到的节点是forward节点，就向后继续遍历，再加上给节点上锁的机制，就完成了多线程的控制。多线程遍历节点，处理了一个节点，就把对应点的值set为forward，另一个线程看到forward，就向后遍历。这样交叉就完成了复制工作。而且还很好的解决了线程安全的问题。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157/** * Moves and/or copies the nodes in each bin to new table. See * above for explanation. */private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; // 将 length / 8 然后除以 CPU核心数。如果得到的结果小于 16，那么就使用 16。 // 这里的目的是让每个 CPU 处理的桶一样多，避免出现转移任务不均匀的现象，如果桶较少的话，默认一个 CPU（一个线程）处理 16 个桶 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range if (nextTab == null) &#123; // initiating try &#123; @SuppressWarnings(\"unchecked\") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1];//构造一个nextTable对象 它的容量是原来的两倍 nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; int nextn = nextTab.length; ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab);//构造一个连节点指针 用于标志位 boolean advance = true;//并发扩容的关键属性 如果等于true 说明这个节点已经处理过 boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; //这个while循环体的作用就是在控制i-- 通过i--可以依次遍历原hash表中的节点 while (advance) &#123; int nextIndex, nextBound; if (--i &gt;= bound || finishing) advance = false; else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; if (finishing) &#123; //如果所有的节点都已经完成复制工作 就把nextTable赋值给table 清空临时对象nextTable nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1);//扩容阈值设置为原来容量的1.5倍 依然相当于现在容量的0.75倍 return; &#125; //利用CAS方法更新这个扩容阈值，在这里面sizectl值减一，说明新加入一个线程参与到扩容操作 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit &#125; &#125; //如果遍历到的节点为空 则放入ForwardingNode指针 else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); //如果遍历到ForwardingNode节点 说明这个点已经被处理过了 直接跳过 这里是控制并发扩容的核心 else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; //节点上锁 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; //如果fh&gt;=0 证明这是一个Node节点 if (fh &gt;= 0) &#123; int runBit = fh &amp; n; //以下的部分在完成的工作是构造两个链表 一个是原链表 另一个是原链表的反序排列 Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; //在nextTable的i位置上插入一个链表 setTabAt(nextTab, i, ln); //在nextTable的i+n的位置上插入另一个链表 setTabAt(nextTab, i + n, hn); //在table的i位置上插入forwardNode节点 表示已经处理过该节点 setTabAt(tab, i, fwd); //设置advance为true 返回到上面的while循环中 就可以执行i--操作 advance = true; &#125; //对TreeBin对象进行处理 与上面的过程类似 else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; //构造正序和反序两个链表 for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; //如果扩容后已经不再需要tree的结构 反向转换为链表结构 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; //在nextTable的i位置上插入一个链表 setTabAt(nextTab, i, ln); //在nextTable的i+n的位置上插入另一个链表 setTabAt(nextTab, i + n, hn); //在table的i位置上插入forwardNode节点 表示已经处理过该节点 setTabAt(tab, i, fwd); //设置advance为true 返回到上面的while循环中 就可以执行i--操作 advance = true; &#125; &#125; &#125; &#125; &#125;&#125; 3.3 put这个put方法依然沿用HashMap的put方法的思想，根据hash值计算这个新插入的点在table中的位置i，如果i位置是空的，直接放进去，否则进行判断，如果i位置是树节点，按照树的方式插入新的节点，否则把i插入到链表的末尾。ConcurrentHashMap中依然沿用这个思想，有一个最重要的不同点就是ConcurrentHashMap不允许key或value为null值。另外由于涉及到多线程，put方法就要复杂一点。在多线程中可能有以下两个情况: 如果一个或多个线程正在对ConcurrentHashMap进行扩容操作，当前线程也要进入扩容的操作中。这个扩容的操作之所以能被检测到，是因为transfer方法中在空结点上插入forward节点，如果检测到需要插入的位置被forward节点占有，就帮助进行扩容； 如果检测到要插入的节点是非空且不是forward节点，就对这个节点加锁，这样就保证了线程安全。尽管这个有一些影响效率，但是还是会比hashTable的synchronized要好得多。‘ 整体流程就是首先定义不允许key或value为null的情况放入 对于每一个放入的值，首先利用spread方法对key的hashcode进行一次hash计算，由此来确定这个值在table中的位置。 如果这个位置是空的，那么直接放入，而且不需要加锁操作。 如果这个位置存在结点，说明发生了hash碰撞，首先判断这个节点的类型。如果是链表节点（fh&gt;0）,则得到的结点就是hash值相同的节点组成的链表的头节点。需要依次向后遍历确定这个新加入的值所在位置。如果遇到hash值与key值都与新加入节点是一致的情况，则只需要更新value值即可。否则依次向后遍历，直到链表尾插入这个结点。如果加入这个节点以后链表长度大于8，就把这个链表转换成红黑树。如果这个节点的类型已经是树节点的话，直接调用树节点的插入方法进行插入新的值。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394/** * Maps the specified key to the specified value in this table. * Neither the key nor the value can be null. * * &lt;p&gt;The value can be retrieved by calling the &#123;@code get&#125; method * with a key that is equal to the original key. * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with &#123;@code key&#125;, or * &#123;@code null&#125; if there was no mapping for &#123;@code key&#125; * @throws NullPointerException if the specified key or value is null */ public V put(K key, V value) &#123; return putVal(key, value, false); &#125; /** Implementation for put and putIfAbsent */ final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; //死循环 何时插入成功 何时跳出 for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; //如果table为空的话，初始化table if (tab == null || (n = tab.length) == 0) tab = initTable(); //根据hash值计算出在table里面的位置 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //如果这个位置没有值 ，直接放进去，不需要加锁 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; //当遇到表连接点时，需要进行整合表的操作 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; //结点上锁 这里的结点可以理解为hash值相同组成的链表的头结点 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; //fh&gt;0 说明这个节点是一个链表的节点 不是树的节点 if (fh &gt;= 0) &#123; binCount = 1; //在这里遍历链表所有的结点 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; //如果hash值和key值相同 则修改对应结点的value值 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; //如果遍历到了最后一个结点，那么就证明新的节点需要插入 就把它插入在链表尾部 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; //如果这个节点是树节点，就按照树的方式插入值 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; //如果链表长度已经达到临界值8 就需要把链表转换为树结构 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; //将当前ConcurrentHashMap的元素数量+1 addCount(1L, binCount); return null; &#125; 我们可以发现JDK8中的实现也是锁分离的思想，只是锁住的是一个Node，而不是JDK7中的Segment，而锁住Node之前的操作是无锁的并且也是线程安全的，建立在之前提到的3个原子操作上。 3.4 getget方法比较简单，给定一个key来确定value的时候，必须满足两个条件 key相同 hash值相同，对于节点可能在链表或树上的情况，需要分别去查找。 123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; //计算hash值 int h = spread(key.hashCode()); //根据hash值确定节点位置 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; //如果搜索到的节点key与传入的key相同且不为null,直接返回这个节点 if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; //如果eh&lt;0 说明这个节点在树上 直接寻找 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; //否则遍历链表 找到对应的值并返回 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null; &#125;","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://yoursite.com/tags/多线程/"},{"name":"源码","slug":"源码","permalink":"http://yoursite.com/tags/源码/"}]},{"title":"ThreadLocal解析","date":"2018-08-13T01:27:38.000Z","path":"2018/08/13/ThreadLocal解析/","text":"在面试中，ThreadLocal是一个经常会被问到的知识点，所以今天就好好分析一下它的实现原理。(基于JDK1.8) 什么是ThreadLocalThreadLocal是一个数据结构，类似于HashMap，可以保存key:value键值对，但是一个ThreadLocal只能保存一个，并且各个线程之间的数据互不干扰。 看下它的set(T value)和get()方法的源码 12345678910111213141516171819202122232425262728public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); &#125; public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125; 可以看到每个线程中都会有一个ThreadLocal数据结构，set方法是将值保存到当前线程中的threadLocals变量中，get方法是从当前线程中的threadLocals变量中获取。所以对于线程1中的数据在线程2中是无法访问的，保证了线程之间的互不干扰。 那接下来就看其中的关键类ThreadLocalMap是什么了。 ThreadLocalMapThreadLocalMap是ThreadLocal的一个静态内部类。它也是Thread类的一个属性。 123456789101112131415161718192021222324252627282930313233343536373839404142 static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; /** * 初始化大小，必须是二的幂. */ private static final int INITIAL_CAPACITY = 16; /** * The table, resized as necessary. * table.length MUST always be a power of two. */ private Entry[] table; /** * The number of entries in the table. */ private int size = 0; /** * The next size value at which to resize. */ private int threshold; // Default to 0 ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); &#125;&#125; 在ThreadLocal中，初始化了一个大小为16的Entry数组，Entry对象用来保存key-value键值对，只不过在这里key永远都是ThreadLocal对象(map.set(this, value);)。 Entry继承的是WeakReference，并且Entry中没有next字段，所以不会形成链表。 Thread、ThreadLocal和ThreadLocalMap的关系 set1234567891011121314151617181920212223242526private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; 内存泄漏由于Entry是继承WeakReference，这就导致了在ThreadLocal没有外部强引用时，发生GC时就会被回收，如果创建ThreadLocal的线程一直持续运行，那么这个Entry对象中的value就有可能一直得不到回收，发生内存泄露。 如何避免内存泄露remove方法，如果使用ThreadLocal的set方法之后，没有显示的调用remove方法，就有可能发生内存泄露，所以养成良好的编程习惯十分重要，使用完ThreadLocal之后，记得调用remove方法。 123456ThreadLocal&lt;String&gt; localName = new ThreadLocal();try &#123; localName.set(\"哈哈\");&#125; finally &#123; localName.remove();&#125;","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://yoursite.com/tags/多线程/"}]},{"title":"HashMap源码分析","date":"2018-08-12T05:31:13.000Z","path":"2018/08/12/HashMap源码分析/","text":"在JDK1.6，JDK1.7中，HashMap采用位桶+链表实现，即使用链表处理冲突，同一hash值的链表都存储在一个链表里。但是当位于一个桶中的元素较多，即hash值相等的元素较多时，通过key值依次查找的效率较低。而JDK1.8中，HashMap采用位桶+链表+红黑树实现，当链表长度超过阈值（8）时，将链表转换为红黑树，这样大大减少了查找时间。这里就主要研究一下JDK1.8的HashMap源码。 先简单说下HashMap的实现原理： 首先有一个每个元素都是链表的数组，当添加一个元素（key-value）时，就首先计算元素key的hash值，以此确定插入数组中的位置，但是可能存在同一hash值的元素已经被放在数组同一位置了，这时就添加到同一hash值的元素的后面，他们在数组的同一位置，但是形成了链表，同一各链表上的Hash值是相同的，所以说数组存放的是链表。而当链表长度太长时，链表就转换为红黑树，这样大大提高了查找的效率。 当链表数组的容量超过初始容量的0.75时，再散列将链表数组扩大2倍，把原链表数组的搬移到新的数组中 数据结构1、 位桶数组 1transient Node&lt;k,v&gt;[] table;//存储（位桶）的数组&lt;/k,v&gt; 2、 数组元素Node&lt;K,V&gt; 123456789101112131415161718192021222324252627282930313233343536373839//Node是单向链表，它实现了Map.Entry接口static class Node&lt;k,v&gt; implements Map.Entry&lt;k,v&gt; &#123; final int hash; final K key; V value; Node&lt;k,v&gt; next; //构造函数Hash值 键 值 下一个节点 Node(int hash, K key, V value, Node&lt;k,v&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + = + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; //判断两个node是否相等,若key和value都相等，返回true。可以与自身比较为true public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;!--?,?--&gt; e = (Map.Entry&lt;!--?,?--&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; 3、红黑树 12345678910111213141516171819//红黑树static final class TreeNode&lt;k,v&gt; extends LinkedHashMap.Entry&lt;k,v&gt; &#123; TreeNode&lt;k,v&gt; parent; // 父节点 TreeNode&lt;k,v&gt; left; //左子树 TreeNode&lt;k,v&gt; right;//右子树 TreeNode&lt;k,v&gt; prev; // needed to unlink next upon deletion boolean red; //颜色属性 TreeNode(int hash, K key, V val, Node&lt;k,v&gt; next) &#123; super(hash, key, val, next); &#125; //返回当前节点的根节点 final TreeNode&lt;k,v&gt; root() &#123; for (TreeNode&lt;k,v&gt; r = this, p;;) &#123; if ((p = r.parent) == null) return r; r = p; &#125; &#125; 数据域1234567891011121314151617181920212223242526272829303132333435-------类常量------------//默认hash桶初始长度16static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 //hash表最大容量2的30次幂static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//默认负载因子 0.75static final float DEFAULT_LOAD_FACTOR = 0.75f;//链表的数量大于等于8个并且桶的数量大于等于64时链表树化 static final int TREEIFY_THRESHOLD = 8;//hash表某个节点链表的数量小于等于6时树拆分static final int UNTREEIFY_THRESHOLD = 6;//树化时最小桶的数量static final int MIN_TREEIFY_CAPACITY = 64;------实例变量---------//hash桶transient Node&lt;K,V&gt;[] table; //键值对的数量transient int size;//HashMap结构修改的次数transient int modCount;//扩容的阀值，当键值对的数量超过这个阀值会产生扩容int threshold;//负载因子final float loadFactor; 构造函数1234567891011121314151617181920212223242526272829303132//构造函数1public HashMap(int initialCapacity, float loadFactor) &#123; //指定的初始容量非负 if (initialCapacity &lt; 0) throw new IllegalArgumentException(Illegal initial capacity: + initialCapacity); //如果指定的初始容量大于最大容量,置为最大容量 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //填充比为正 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(Illegal load factor: + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);//新的扩容临界值&#125; //构造函数2public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125; //构造函数3public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125; //构造函数4用m的元素初始化散列映射public HashMap(Map&lt;!--? extends K, ? extends V--&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125; tableSizeFor(initialCapacity)方法，这个方法的作用是，将你传入的initialCapacity做计算，返回一个大于等于initialCapacity 最小的2的幂次方。所以这个操作保证无论你传入的初始化Hash桶长度参数是多少，最后hash表初始化的长度都是2的幂次方。比如你输入的是6，计算出来结果就是8。 123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; get12345678910111213141516171819202122232425262728293031323334353637public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; /** * Implements Map.get and related methods * * @param hash hash for key * @param key the key * @return the node, or null if none */ final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab;//Entry对象数组 Node&lt;K,V&gt; first,e; //在tab数组中经过散列的第一个位置 int n; K k; /*找到插入的第一个Node，方法是hash值和n-1相与，tab[(n - 1) &amp; hash]*/ //也就是说在一条链上的hash值相同的 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;(first = tab[(n - 1) &amp; hash]) != null) &#123; /*检查第一个Node是不是要找的Node*/ if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))//判断条件是hash值要相同，key值要相同 return first; /*检查first后面的node*/ if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); /*遍历后面的链表，找到key值和hash值都相同的Node*/ do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; get(key)方法时获取key的hash值，计算hash&amp;(n-1)得到在链表数组中的位置first=tab[hash&amp;(n-1)],先判断first的key是否与参数key相等，不等就遍历后面的链表找到相同的key值返回对应的Value值即可 put123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //当table为空时，这里初始化table，不是通过构造函数初始化，而是在插入时通过扩容初始化， //有效防止了初始化HashMap没有数据插入造成空间浪费可能造成内存泄露的情况 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //存放新键值对 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); //表示有冲突,开始处理冲突 else &#123; Node&lt;K,V&gt; e; K k; //旧键值对的覆盖 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //在红黑树中查找旧键值对更新 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //将新键值对放在链表的最后 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //当链表的长度大于等于树化阀值，并且hash桶的长度大于等于MIN_TREEIFY_CAPACITY，链表转化为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //链表中包含键值对 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //map中含有旧key，返回旧值 if (e != null) &#123; V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; //map调整次数加1 ++modCount; //键值对的数量达到阈值需要扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 对key的hashCode()进行hash后计算数组下标index; 如果当前数组table为null，进行resize()初始化； 如果没碰撞直接放到对应下标的位置上； 如果碰撞了，且节点已经存在，就替换掉 value； 如果碰撞后发现为树结构，挂载到树上。 如果碰撞后为链表，添加到链表尾，并判断链表如果过长(大于等于TREEIFY_THRESHOLD，默认8)，就把链表转换成树结构； 数据 put 后，如果数据量超过threshold，就要resize。 扩容机制resize()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798 /** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */ final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; /*如果旧表的长度不是空*/ if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125;/*把新表的长度设置为旧表长度的两倍，newCap=2*oldCap*/ else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) /*把新表的门限设置为旧表门限的两倍，newThr=oldThr*2*/ newThr = oldThr &lt;&lt; 1; // double threshold &#125; /*如果旧表的长度的是0，就是说第一次初始化表*/ else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor;//新表长度乘以加载因子 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;)/*下面开始构造新表，初始化表中的数据*/ Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab;//把新表赋值给table if (oldTab != null) &#123;//原表不是空要把原表中数据移动到新表中 /*遍历原来的旧表*/ for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null)//说明这个node没有链表直接放在新表的e.hash &amp; (newCap - 1)位置 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); /*如果e后边有链表,到这里表示e后面带着个单链表，需要遍历单链表，将每个结点重*/ else &#123; // preserve order保证顺序 ////新计算在新表的位置，并进行搬运 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next;//记录下一个结点 //新表是旧表的两倍容量，实例上就把单链表拆分为两队， //e.hash&amp;oldCap为偶数一队，e.hash&amp;oldCap为奇数一对 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123;//lo队不为null，放在新表原位置 loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123;//hi队不为null，放在新表j+oldCap位置 hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 那么什么时候回产生扩容呢？ （1）初始化HashMap时，第一次进行put操作 （2）当键值对的个数大于threshold阀值时产生扩容，threshold=size*loadFactor","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://yoursite.com/tags/多线程/"},{"name":"源码","slug":"源码","permalink":"http://yoursite.com/tags/源码/"}]},{"title":"TCP的可靠性传输","date":"2018-08-10T01:44:49.000Z","path":"2018/08/10/TCP的可靠性传输/","text":"TCP通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输。 通过序列号与确认应答提高可靠性TCP通过肯定的确认应答(ACK)实现可靠的数据传输。当发送端将数据发出后会等待对端的确认应答。如果有确认应答，说明数据已经成功到达对端。反之，则数据丢失的可能性很大。 没有收到确认应答并不意味着数据一定丢失。也又可能是对方已经收到了数据，只是返回的确认应答在途中丢失。这种情况也会导致发送端没有收到确认应答而认为数据没有到达目的地，最终重发数据。 主机B已经收到了1-1000的数据，再有相同的数据到达时会丢弃相同数据。 有很多因素会导致确认应答延迟到达，源发送主机只要按照重发机制重发数据即可。但对于目标主机来说，这是一种“灾难”。它会反复收到相同的数据。而为了对上层应用提供可靠的传输，必须得放弃重复的数据包。因此就要使用一种能够识别是否已经接收数据，又能判断是否需要接收的机制。 上述这些确认应答、重发机制以及重复控制等功能都可以通过序列号实现。序列号是按顺序给发送的数据的每一个字节(8位字节)都标上号码的编号。接收端查询接收数据TCP首部中的序列号和数据的长度，将自己下一步应该接收的序号作为确认应答返送回去。就这样，通过序列号和确认应答号，TCP就可以实现可靠传输。 序列号的初始值并非为0。而是在建立连接后由随机数生成。而后的计算则是对每一字节加一。 重发超时的确定重发超时是指在重发数据之前，等待确认应答到来的那个特定时间。如果超过了这个时间仍未收到确认应答，发送端将进行数据重发。 在Unix以及Windows系统中，超时都是以0.5秒为单位进行控制，因此重发超时都是0.5的整数倍。由于最初的数据包还不知道往返时间，所以其重发超时一般设置在6秒左右。 数据重发之后若还是收不到确认应答，则进行再次发送。此时，等待应答的时间将会以2倍、4倍的指数函数延长。 此外，数据也不会无限、反复地重发。达到一定重发次数之后，如果仍然没有任何确认应答返回，就会判断为网络或对端主机发生异常，强制关闭连接。并且通知应用通信异常强行终止。 连接管理(三次握手四次挥手)TCP提供面向有连接的通信传输。面向有连接是指在数据通信开始之前先做好通信两端之间的准备工作。 TCP在数据通信之前，通过TCP首部发送一个SYN包作为建立连接的请求等待确认应答。如果对端发来确认应答，则认为可以进行数据通信。如果对端的确认应答未能到达，就不会进行数据通信。此外，在通信结束时会进行断开连接的处理(FIN包)。 TCP以段发送数据在建立TCP连接的同时，也可以确定发送数据包的单位，称其为“最大消息长度”(MSS)。最理想的情况是IP中不被分片处理的最大数据长度。 TCP在传输大量数据时，是以MSS的大小将数据进行分割发送。进行重发时也是以MSS为单位。(在上面的两张图中，传输数据都是1-1000，表示MSS的大小为1000) MSS是在三次握手的时候，在两端主机之间被计算得出。两端的主机在发出建立连接的请求时，会在TCP首部中写入MSS选项，告诉对方自己的接口能够适应的MSS的大小。然后会在两者之间选择一个较小的值投入使用。 利用窗口控制提高速度TCP以一个段为单位，每发一个段进行一次确认应答的处理。这样的传输方式有一个缺点。那就是包的往返时间越长通信性能就越低。 为了解决这个问题，TCP引入了窗口这个概念。即时在往返时间较长的情况下，它也能控制网络性能的下降。 如图所示，确认应答不再是以每个分段，而是以更大的单位进行确认时，转发时间将被大幅度缩短。也就是说，发送端主机在发送了一个段以后不必一直等待确认应答，而是继续发送。 窗口大小就是指无需等待确认应答而可以继续发送数据的最大值。上图中窗口大小为3个段。 如下图所示，黄色部分表示窗口。这个窗口中的数据即便没有收到应答确认也可以被发送出去。不过，在整个窗口的确认应答没有到达之前，如果其中部分数据出现丢包，那么发送端仍然需要重传。在收到确认应答的情况下，将窗口滑动到确认应答中的序列号的位置。这样可以顺序得将多个段同时发送提高通信性能。这种机制也被称为窗口滑动机制。 窗口控制与重发控制在使用窗口控制中，如果出现段丢失该怎么办？ 首先考虑确认应答未能返回的情况。在这种情况下，数据已经到达对端，是不需要进行重发的。使用了窗口机制，某些确认应答即便丢失也无需重发。可以通过下一个确认应答进行确认。 在来考虑一下某个报文段丢失的情况，如下图所示，接收主机如果收到一个自己应该接收的序号以外的数据时，会针对当前为止收到数据返回确认应答。当一段报文段丢失后，发送端回一直收到序号为1001的确认应答，这个确认应答好像在提醒发送端“我想接受的是1001开始的数据”。因此，在窗口比较大，又出现报文段丢失的情况下，同一个序号的确认应答将会被重复不断的返回。而发送端主机如果连续三次接收到同一个确认应答，就会将其对应的数据进行重发。这种机制比之前提到的超时管理更加高效，因此也被称为高速重发控制。 流控制(窗口大小)发送端根据自己的实际情况发送数据。但是，接收端可能收到的是一个毫无关系的数据包又可能会在处理其他问题上花费一些时间。因此在为这个数据包做其他处理时会耗费一些时间，甚至在高负荷的情况下无法接收任何数据。如此一来，如果接收端将本应该接收的数据丢弃的话，就又会触发重发机制，导致网络流量的无端浪费。 TCP提供一种机制可以让发送端根据接收端的实际接收能力控制发送数据的数量。这就是流控制。具体操作就是接收端主机向发送端主机通知自己可以接收数据的大小，于是发送端会发送不超过这个限度的数据。该大小限度就被称作窗口大小。 TCP首部中，专门有一个字段用来通知窗口大小。接收主机将自己可以接收的缓冲区大小放入到这个字段中通知给发送端。这个字段的值越大，说明网络的吞吐量越大。当接收端的这个缓冲区一旦面临数据溢出时，窗口大小的值也会随之被设置成一个更小的值发送给发送端，从而控制数据发送量。 拥塞控制有了TCP的窗口控制，收发主机之间即使不再以一个数据段为单位发送确认应答，也能够连续发送大量数据包。然而，如果在通信刚开始的时候就发送大量数据，也可能会引发其他问题。 一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。在网络出现拥堵时，如果突然发送一个较大量的数据，极有可能导致整个网络的瘫痪。 TCP为了防止该问题的出现，在通信一开始的时候就会通过一个叫做慢启动的算法得出的数值，对发送数据量进行控制。 首先为了在发送端调节所要发送数据的量，定义了一个叫做“拥塞窗口”的概念。于是在慢启动的时候，将这个拥塞窗口的大小设置为1个数据段(1MSS)发送数据。之后每收到一次确认应答，拥塞窗口的值就加1。在发送数据包时，将拥塞窗口的大小与接收端主机通知的窗口大小做比较，然后按照它们当中较小的那个值，发送比其还小的数据量。","tags":[{"name":"TCP","slug":"TCP","permalink":"http://yoursite.com/tags/TCP/"}]},{"title":"Java队列同步器AQS","date":"2018-08-08T08:37:20.000Z","path":"2018/08/08/Java队列同步器AQS/","text":"队列同步器，AbstractQueuedSynchronized,简称AQS，是用来构建锁或者其他同步组建的基础框架，常用的有ReentrantLock、ReadWriteLock（实现类ReentrantReadWriteLock），内部实现都依赖于它。Doug Lea大神期望它能够成为实现大部分同步需求的基础。 定义123456789101112131415public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; //等待队列的头节点 private transient volatile Node head; //等待队列的尾节点 private transient volatile Node tail; //同步状态 private volatile int state; protected final int getState() &#123; return state;&#125; protected final void setState(int newState) &#123; state = newState;&#125; protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update); &#125; ...&#125; AQS使用了一个int成员变量state表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作。基本结构如图所示： 当前线程获取同步状态失败时，AQS会将当前线程以及等待状态等信息构造成一个节点(Node)并将其加入到队列中(添加到队尾，要保证线程安全，使用CAS)，同时阻塞当前线程。当同步状态释放时，会把首节点的线程唤醒，使其再尝试获取同步状态。 节点类： 1234567891011121314static final class Node &#123; static final Node SHARED = new Node(); static final Node EXCLUSIVE = null; static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; volatile int waitStatus; volatile Node prev; volatile Node next; volatile Thread thread; Node nextWaiter; ... &#125; 每个节点中， 除了存储了当前线程，前后节点的引用以外，还有一个waitStatus变量，用于描述节点当前的状态。一共有4中状态： CANCELLED 取消状态 SIGNAL 等待触发状态 CONDITION 等待条件状态 PROPAGATE 状态需要向后传播 等待队列是FIFO先进先出，只有前一个节点的状态为SIGNAL时，当前节点的线程才能被挂起。 实现原理AQS的主要使用方式是继承，子类通过继承同步器并实现它的抽象方法来管理同步状态。子类重写tryAcquire和tryRelease方法通过CAS指令修改状态变量state。 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 上述代码主要完成了同步状态获取、节点构造、加入同步队列以及在同步队列中自旋等待的相关工作。首先调用自定义同步器实现的tryAcquire(arg)，该方法保证线程安全地获取同步状态，如果获取同步状态失败，则构造同步节点并通过addWaiter(Node node)方法加入到同步队列的尾部，最后调用acquireQueued(Node node, int arg)方法使该节点以”死循环”的方式获取同步状态。如果获取不到则阻塞节点中的线程，而被阻塞的线程唤醒主要依靠前驱节点的出队或阻塞线程被中断来实现。 1、节点构造和加入同步队列1234567891011121314private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node; &#125; 123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; 2、节点进入自旋123456789101112131415161718192021222324final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; //p为node的前驱节点 final Node p = node.predecessor(); //前驱节点是头节点才尝试获取同步状态 //如果成功，将自己设为头节点 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 尝试获取失败则进入下面方法 123456789101112131415161718192021222324252627private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125; 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted(); &#125; 如果pred的waitStatus == 0，则通过CAS指令修改waitStatus为Node.SIGNAL。 如果pred的waitStatus &gt; 0，表明pred的线程状态CANCELLED，需从队列中删除。 如果pred的waitStatus为Node.SIGNAL，则通过LockSupport.park()方法把线程A挂起，并等待被唤醒 线程每次被唤醒时，都要进行中断检测，如果发现当前线程被中断，那么抛出InterruptedException并退出循环。从无限循环的代码可以看出，并不是被唤醒的线程一定能获得锁，必须调用tryAccquire重新竞争，因为锁是非公平的，有可能被新加入的线程获得，从而导致刚被唤醒的线程再次被阻塞，这个细节充分体现了“非公平”的精髓。 3、释放123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125; 1234567891011121314151617181920212223242526private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 如果头结点head的waitStatus值为-1，则用CAS指令重置为0； 找到waitStatus值小于0的节点s，通过LockSupport.unpark(s.thread)唤醒线程。 总结在获取同步状态时，同步器维护了一个同步队列，获取状态失败的线程都会被加入到队列中并在队列中进行自旋；移出或停止自旋的条件是前驱节点为头节点且成功获取到了同步状态。在释放同步状态时，同步器调用tryRelease(int arg)方法释放同步状态，然后唤醒头节点的后续节点。","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://yoursite.com/tags/多线程/"},{"name":"同步","slug":"同步","permalink":"http://yoursite.com/tags/同步/"},{"name":"AQS","slug":"AQS","permalink":"http://yoursite.com/tags/AQS/"}]},{"title":"Binder机制简析(四)","date":"2018-08-07T03:23:28.000Z","path":"2018/08/07/Binder机制简析-四/","text":"binder在framework层，采用JNI技术来调用native(C/C++)层的binder架构，从而为上层应用程序提供服务。 看过binder系列之前的文章，我们知道native层中，binder是C/S架构，分为Bn端(Server)和Bp端(Client)。对于java层在命名与架构上非常相近，同样实现了一套IPC通信架构。 framework Binder架构图 图解： 图中红色代表整个framework层 binder架构相关组件； 图中蓝色代表Native层Binder架构相关组件； 上层framework层的Binder逻辑是建立在Native层架构基础之上的，核心逻辑都是交予Native层方法来处理。 framework层的ServiceManager类与Native层的功能并不完全对应，framework层的ServiceManager类的实现最终是通过BinderProxy传递给Native层来完成的 Binder完整通信流程 图解: 发起端线程向Binder Driver发起binder ioctl请求后, 便采用环不断talkWithDriver,此时该线程处于阻塞状态, 直到收到如下BR_XXX命令才会结束该过程. 左图中waitForResponse收到BR_TRANSACTION_COMPLETE,则直接退出循环, 则没有机会执行executeCommand()方法, 故将其颜色画为灰色. 除以上5种BR_XXX命令, 当收到其他BR命令,则都会执行executeCommand过程. 目标Binder线程创建后, 便进入joinThreadPool()方法, 采用循环不断地循环执行getAndExecuteCommand()方法, 当bwr的读写buffer都没有数据时,则阻塞在binder_thread_read的wait_event过程. 另外,正常情况下binder线程一旦创建则不会退出.","tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"},{"name":"系统","slug":"系统","permalink":"http://yoursite.com/tags/系统/"},{"name":"binder","slug":"binder","permalink":"http://yoursite.com/tags/binder/"}]},{"title":"Binder机制简析(三)","date":"2018-08-05T12:01:04.000Z","path":"2018/08/05/Binder机制简析-三/","text":"注册ServiceService组件运行在Server进程中，首先要将Service注册到Service Manager中，再启动一个Binder线程池来等待和处理Client的通信请求。 注册过程(addService)核心工作：在服务所在进程创建binder_node，在ServiceManager进程创建binder_ref. 以Media服务为例，注册的过程涉及到MediaPlayerService(作为Client进程)和Service Manager(作为Service进程)，通信流程图如下所示： 过程分析： MediaPlayerService进程调用ioctl()向Binder驱动发送IPC数据，该过程可以理解成一个事务binder_transaction(记为T1)，执行当前操作的线程binder_thread(记为thread1)，则T1-&gt;from_parent=NULL，T1-&gt;from = thread1，thread1-&gt;transaction_stack=T1。其中IPC数据内容包含： Binder协议为BC_TRANSACTION； Handle等于0； RPC代码为ADD_SERVICE； RPC数据为”media.player” Binder驱动收到该Binder请求，生成BR_TRANSACTION命令，选择目标处理该请求的线程，即ServiceManager的binder线程(记为thread2)，则 T1-&gt;to_parent = NULL，T1-&gt;to_thread = thread2。并将整个binder_transaction数据(记为T2)插入到目标线程的todo队列； Service Manager的线程thread2收到T2后，调用服务注册函数将服务”media.player”注册到服务目录中。当服务注册完成后，生成IPC应答数据(BC_REPLY)，T2-&gt;form_parent = T1，T2-&gt;from = thread2, thread2-&gt;transaction_stack = T2。 Binder驱动收到该Binder应答请求，生成BR_REPLY命令，T2-&gt;to_parent = T1，T2-&gt;to_thread = thread1, thread1-&gt;transaction_stack = T2。 在MediaPlayerService收到该命令后，知道服务注册完成便可以正常使用。 获取Service请求服务(getService)过程，就是向servicemanager进程查询指定服务，当执行binder_transaction()时，会区分请求服务所属进程情况。 当请求服务的进程与服务属于不同进程，则为请求服务所在进程创建binder_ref对象，指向服务进程中的binder_node; 最终readStrongBinder()，返回的是BpBinder对象； 当请求服务的进程与服务属于同一进程，则不再创建新对象，只是引用计数加1，并且修改type为BINDER_TYPE_BINDER或BINDER_TYPE_WEAK_BINDER。 最终readStrongBinder()，返回的是BBinder对象的真实子类；","tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"},{"name":"系统","slug":"系统","permalink":"http://yoursite.com/tags/系统/"},{"name":"binder","slug":"binder","permalink":"http://yoursite.com/tags/binder/"}]},{"title":"Binder机制简析(二)","date":"2018-08-03T12:01:04.000Z","path":"2018/08/03/Binder机制简析-二/","text":"在Binder机制简析(一)中大概分析了Binder驱动，本章主要分析Service Manager。 Service Manager它扮演着Binder进程间通信机制上下文管理者的角色，同时负责管理系统中的Service组件，并且向Client组件提供获取Service代理对象的服务(主要工作：查询和注册服务) Service Manager启动主要有下面几个步骤： binder_open 打开驱动，将其映射到本进程的地址空间。 binder_become_context_manager 注册为binder服务的大管家 binder_loop 进入无限循环，处理从Client进程(Service和Client组件对Service Manager来说都是Client进程)通信请求。（循环调用binder_thread_read来检查Service Manager进程是否有新的进程间通信请求需要处理，如果有就交给binder_parse方法处理，在binder_parse中调用svcmgr_handler来解析信息，调用对应的方法，查询服务、注册服务、列举所有服务） 流程图： main1234567891011121314151617181920212223242526272829int main(int argc, char **argv) &#123; struct binder_state *bs; //打开binder驱动，申请128k字节大小的内存空间 【见小节2.2】 bs = binder_open(128*1024); ... //成为上下文管理者 if (binder_become_context_manager(bs)) &#123; return -1; &#125; selinux_enabled = is_selinux_enabled(); //selinux权限是否使能 sehandle = selinux_android_service_context_handle(); selinux_status_open(true); if (selinux_enabled &gt; 0) &#123; if (sehandle == NULL) &#123; abort(); //无法获取sehandle &#125; if (getcon(&amp;service_manager_context) != 0) &#123; abort(); //无法获取service_manager上下文 &#125; &#125; ... //进入无限循环，处理client端发来的请求 binder_loop(bs, svcmgr_handler); return 0;&#125; binder_loop123456789101112131415161718192021222324252627282930313233void binder_loop(struct binder_state *bs, binder_handler func) &#123; int res; struct binder_write_read bwr; uint32_t readbuf[32]; bwr.write_size = 0; bwr.write_consumed = 0; bwr.write_buffer = 0; readbuf[0] = BC_ENTER_LOOPER; //将BC_ENTER_LOOPER命令发送给binder驱动，让Service Manager进入循环 binder_write(bs, readbuf, sizeof(uint32_t)); for (;;) &#123; bwr.read_size = sizeof(readbuf); bwr.read_consumed = 0; bwr.read_buffer = (uintptr_t) readbuf; res = ioctl(bs-&gt;fd, BINDER_WRITE_READ, &amp;bwr); //进入循环，不断地binder读写过程 if (res &lt; 0) &#123; break; &#125; // 解析binder信息 res = binder_parse(bs, 0, (uintptr_t) readbuf, bwr.read_consumed, func); if (res == 0) &#123; break; &#125; if (res &lt; 0) &#123; break; &#125; &#125;&#125; binder_parse12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970int binder_parse(struct binder_state *bs, struct binder_io *bio, uintptr_t ptr, size_t size, binder_handler func)&#123; int r = 1; uintptr_t end = ptr + (uintptr_t) size; while (ptr &lt; end) &#123; uint32_t cmd = *(uint32_t *) ptr; ptr += sizeof(uint32_t); switch(cmd) &#123; case BR_NOOP: //无操作，退出循环 break; case BR_TRANSACTION_COMPLETE: break; case BR_INCREFS: case BR_ACQUIRE: case BR_RELEASE: case BR_DECREFS: ptr += sizeof(struct binder_ptr_cookie); break; case BR_TRANSACTION: &#123; struct binder_transaction_data *txn = (struct binder_transaction_data *) ptr; ... binder_dump_txn(txn); if (func) &#123; unsigned rdata[256/4]; struct binder_io msg; struct binder_io reply; int res; bio_init(&amp;reply, rdata, sizeof(rdata), 4); bio_init_from_txn(&amp;msg, txn); //从txn解析出binder_io信息 //func在这里就指向svcmgr_handler res = func(bs, txn, &amp;msg, &amp;reply); binder_send_reply(bs, &amp;reply, txn-&gt;data.ptr.buffer, res); &#125; ptr += sizeof(*txn); break; &#125; case BR_REPLY: &#123; struct binder_transaction_data *txn = (struct binder_transaction_data *) ptr; ... binder_dump_txn(txn); if (bio) &#123; bio_init_from_txn(bio, txn); bio = 0; &#125; ptr += sizeof(*txn); r = 0; break; &#125; case BR_DEAD_BINDER: &#123; struct binder_death *death = (struct binder_death *)(uintptr_t) *(binder_uintptr_t *)ptr; ptr += sizeof(binder_uintptr_t); // binder死亡消息 death-&gt;func(bs, death-&gt;ptr); break; &#125; case BR_FAILED_REPLY: r = -1; break; case BR_DEAD_REPLY: r = -1; break; default: return -1; &#125; &#125; return r;&#125; svcmgr_handler12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758int svcmgr_handler(struct binder_state *bs, struct binder_transaction_data *txn, struct binder_io *msg, struct binder_io *reply)&#123; struct svcinfo *si; uint16_t *s; size_t len; uint32_t handle; uint32_t strict_policy; int allow_isolated; ... strict_policy = bio_get_uint32(msg); s = bio_get_string16(msg, &amp;len); ... switch(txn-&gt;code) &#123; case SVC_MGR_GET_SERVICE: case SVC_MGR_CHECK_SERVICE: s = bio_get_string16(msg, &amp;len); //服务名 //根据名称查找相应服务 handle = do_find_service(bs, s, len, txn-&gt;sender_euid, txn-&gt;sender_pid); bio_put_ref(reply, handle); return 0; case SVC_MGR_ADD_SERVICE: s = bio_get_string16(msg, &amp;len); //服务名 handle = bio_get_ref(msg); //handle allow_isolated = bio_get_uint32(msg) ? 1 : 0; //注册指定服务 if (do_add_service(bs, s, len, handle, txn-&gt;sender_euid, allow_isolated, txn-&gt;sender_pid)) return -1; break; case SVC_MGR_LIST_SERVICES: &#123; uint32_t n = bio_get_uint32(msg); if (!svc_can_list(txn-&gt;sender_pid)) &#123; return -1; &#125; si = svclist; while ((n-- &gt; 0) &amp;&amp; si) si = si-&gt;next; if (si) &#123; bio_put_string16(reply, si-&gt;name); return 0; &#125; return -1; &#125; default: return -1; &#125; bio_put_uint32(reply, 0); return 0;&#125; 该方法的功能：查询服务，注册服务，以及列举所有服务 核心工作servicemanager的核心工作就是注册服务和查询服务: 注册服务记录服务名和handle信息，保存到svclist列表1234567891011121314151617181920212223242526272829303132333435363738394041424344int do_add_service(struct binder_state *bs, const uint16_t *s, size_t len, uint32_t handle, uid_t uid, int allow_isolated, pid_t spid)&#123; struct svcinfo *si; if (!handle || (len == 0) || (len &gt; 127)) return -1; //权限检查 if (!svc_can_register(s, len, spid)) &#123; return -1; &#125; //服务检索 si = find_svc(s, len); if (si) &#123; if (si-&gt;handle) &#123; svcinfo_death(bs, si); //服务已注册时，释放相应的服务 &#125; si-&gt;handle = handle; &#125; else &#123; si = malloc(sizeof(*si) + (len + 1) * sizeof(uint16_t)); if (!si) &#123; //内存不足，无法分配足够内存 return -1; &#125; si-&gt;handle = handle; si-&gt;len = len; memcpy(si-&gt;name, s, (len + 1) * sizeof(uint16_t)); //内存拷贝服务信息 si-&gt;name[len] = '\\0'; si-&gt;death.func = (void*) svcinfo_death; si-&gt;death.ptr = si; si-&gt;allow_isolated = allow_isolated; si-&gt;next = svclist; // svclist保存所有已注册的服务 svclist = si; &#125; //以BC_ACQUIRE命令，handle为目标的信息，通过ioctl发送给binder驱动 binder_acquire(bs, handle); //以BC_REQUEST_DEATH_NOTIFICATION命令的信息，通过ioctl发送给binder驱动，主要用于清理内存等收尾工作。 binder_link_to_death(bs, handle, &amp;si-&gt;death); return 0;&#125; 注册服务的分以下3部分工作： svc_can_register：检查权限，检查selinux权限是否满足； find_svc：服务检索，根据服务名来查询匹配的服务； svcinfo_death：释放服务，当查询到已存在同名的服务，则先清理该服务信息，再将当前的服务加入到服务列表svclist； 查询服务根据服务名查询相应的的handle信息 1234567891011121314151617181920212223uint32_t do_find_service(struct binder_state *bs, const uint16_t *s, size_t len, uid_t uid, pid_t spid)&#123; //查询相应的服务 struct svcinfo *si = find_svc(s, len); if (!si || !si-&gt;handle) &#123; return 0; &#125; if (!si-&gt;allow_isolated) &#123; uid_t appid = uid % AID_USER; //检查该服务是否允许孤立于进程而单独存在 if (appid &gt;= AID_ISOLATED_START &amp;&amp; appid &lt;= AID_ISOLATED_END) &#123; return 0; &#125; &#125; //服务是否满足查询条件 if (!svc_can_find(s, len, spid)) &#123; return 0; &#125; return si-&gt;handle;&#125; 查询到目标服务，并返回该服务所对应的handle 获取Service Manager代理由于Service Manager本身也是一个Service组件，因此，其他Service组件和Client组件在使用它提供的组件之前，也要获取它的代理对象。Service Manager代理对象的类型为BpServiceManager，它用来描述一个实现了IServiceManager接口的Client组件。 IServiceManager接口定义了getService()、chaekService()、addService()、listService()方法。 Android系统在应用程序框架层的Binder库中提供了一个函数defaultServiceManager()，该方法为单例模式，保证一个进程中最多只有一个Service Manager代理对象。 123456789101112131415sp&lt;IServiceManager&gt; defaultServiceManager()&#123; if (gDefaultServiceManager != NULL) return gDefaultServiceManager; &#123; AutoMutex _l(gDefaultServiceManagerLock); //加锁 while (gDefaultServiceManager == NULL) &#123; //关键代码 gDefaultServiceManager = interface_cast&lt;IServiceManager&gt;(ProcessState::self()-&gt;getContextObject(NULL)); if (gDefaultServiceManager == NULL) sleep(1); &#125; &#125; return gDefaultServiceManager;&#125; 当尝试创建或获取ServiceManager时，ServiceManager可能尚未准备就绪，这时通过sleep 1秒后，循环尝试获取直到成功。 gDefaultServiceManager的创建过程,可分解为以下3个步骤： ProcessState::self()：用于获取ProcessState对象(也是单例模式)，每个进程有且只有一个ProcessState对象，存在则直接返回，不存在则创建。 ProcessState::self()主要工作： 调用open()，打开/dev/binder驱动设备； 再利用mmap()，创建大小为1M-8K的内存地址空间； 设定当前进程最大的最大并发Binder线程个数为16。 getContextObject()： 用于获取BpBinder对象，对于handle=0的BpBinder对象，存在则直接返回，不存在才创建。 interface_cast&lt;IServiceManager&gt;()：用于获取BpServiceManager对象。 在整个Binder系统中handle=0代表ServiceManager所对应的BBinder defaultServiceManager 等价于 new BpServiceManager(new BpBinder(0));","tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"},{"name":"系统","slug":"系统","permalink":"http://yoursite.com/tags/系统/"},{"name":"binder","slug":"binder","permalink":"http://yoursite.com/tags/binder/"}]},{"title":"Binder机制简析(一)","date":"2018-08-02T12:00:52.000Z","path":"2018/08/02/Binder机制简析-一/","text":"Binder是Android系统提供的一种IPC机制，是Android系统中的最重要的组成。 Binder进程间通信机制主要涉及到Client、Service、Service Manager和Binder驱动程序。它们的关系如下图： Client、Service和Service Manager运行在用户空间，而Binder驱动程序运行在内核空间。Client、Service和Service Manager均是通过系统调用open、mmap和ioctl来访问设备文件/dev/binder，从而实现与Binder驱动程序的交互，而交互的目的就是为了能够间接地执行进程间通信。 Binder驱动一、Binder设备的初始化(binder_init)Binder设备的初始化是在Binder驱动程序的初始化函数binder_init中进行。主要工作就是在目标设备上创建一个Binder设备文件/dev/binder，这个设备文件的操作方法列表由全局变量binder_fops指定，主要提供binder_open、binder_mmap和binder_ioctl。 12345678910static const struct file_operations binder_fops = &#123; .owner = THIS_MODULE, .poll = binder_poll, .unlocked_ioctl = binder_ioctl, .compat_ioctl = binder_ioctl, .mmap = binder_mmap, .open = binder_open, .flush = binder_flush, .release = binder_release,&#125;; 创建一个/proc/binder/proc目录，每一个使用了Binder进程间通信的进程在该目录下都会有一个对应文件，以进程ID命名，通过它们可以读取到每个进程的Binder线程池、Binder实体对象、Binder引用对象及内核缓冲区等信息。 二、Binder设备的打开过程(binder_open)一个进程在使用Binder之前，要调用open打开设备文件/dev/binder来获得一个文件描述符，然后才能通过这个文件描述符来和Binder驱动程序交互。 1234567891011121314151617181920212223static int binder_open(struct inode *nodp, struct file *filp)&#123; struct binder_proc *proc; proc = kzalloc(sizeof(*proc), GFP_KERNEL); // 为binder_proc结构体在分配kernel内存空间 if (proc == NULL) return -ENOMEM; get_task_struct(current); proc-&gt;tsk = current; //将当前线程的task保存到binder进程的tsk INIT_LIST_HEAD(&amp;proc-&gt;todo); //初始化todo列表 init_waitqueue_head(&amp;proc-&gt;wait); //初始化wait队列 proc-&gt;default_priority = task_nice(current); //将当前进程的nice值转换为进程优先级 binder_lock(__func__); //同步锁，因为binder支持多线程访问 binder_stats_created(BINDER_STAT_PROC); //BINDER_PROC对象创建数加1 hlist_add_head(&amp;proc-&gt;proc_node, &amp;binder_procs); //将proc_node节点添加到binder_procs为表头的队列 proc-&gt;pid = current-&gt;group_leader-&gt;pid; INIT_LIST_HEAD(&amp;proc-&gt;delivered_death); //初始化已分发的死亡通知列表 filp-&gt;private_data = proc; //file文件指针的private_data变量指向binder_proc数据 binder_unlock(__func__); //释放同步锁 return 0;&#125; 创建binder_proc对象，并把当前进程等信息保存到binder_proc对象，该对象管理IPC所需的各种信息并拥有其他结构体的根结构体；再把binder_proc对象保存到文件指针filp，以及把binder_proc加入到全局链表binder_procs。 三、内存映射(binder_mmap)首先在内核虚拟地址空间申请一块与用户虚拟内存相同大小的内存，然后再申请一个page大小的物理内存，再将同一块物理内存分别映射到内核虚拟地址空间和用户虚拟空间，从而实现了用户空间的Buffer和内核空间Buffer同步操作的功能。 四、IO控制(binder_ioctl)binder_ioctl()函数负责在两个进程间收发IPC数据和IPC reply数据。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152static long binder_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)&#123; int ret; struct binder_proc *proc = filp-&gt;private_data; struct binder_thread *thread; // binder线程 unsigned int size = _IOC_SIZE(cmd); void __user *ubuf = (void __user *)arg; //进入休眠状态，直到中断唤醒 ret = wait_event_interruptible(binder_user_error_wait, binder_stop_on_user_error &lt; 2); if (ret) goto err_unlocked; binder_lock(__func__); //获取binder_thread【见2.4.1】 thread = binder_get_thread(proc); if (thread == NULL) &#123; ret = -ENOMEM; goto err; &#125; switch (cmd) &#123; case BINDER_WRITE_READ: //进行binder的读写操作 ...... break; case BINDER_SET_MAX_THREADS: //设置binder最大支持的线程数 ...... break; case BINDER_SET_CONTEXT_MGR: //成为binder的上下文管理者，也就是ServiceManager成为守护进程 ...... break; case BINDER_THREAD_EXIT: //当binder线程退出，释放binder线程 ...... break; case BINDER_VERSION: &#123; //获取binder的版本号 ...... break; &#125; default: ret = -EINVAL; goto err; &#125; ret = 0;err: if (thread) thread-&gt;looper &amp;= ~BINDER_LOOPER_STATE_NEED_RETURN; binder_unlock(__func__); wait_event_interruptible(binder_user_error_wait, binder_stop_on_user_error &lt; 2);err_unlocked: trace_binder_ioctl_done(ret); return ret;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748case BINDER_WRITE_READ: &#123; struct binder_write_read bwr; if (size != sizeof(struct binder_write_read)) &#123; ret = -EINVAL; goto err; &#125; if (copy_from_user(&amp;bwr, ubuf, sizeof(bwr))) &#123; //把用户空间数据ubuf拷贝到bwr ret = -EFAULT; goto err; &#125; binder_debug(BINDER_DEBUG_READ_WRITE, \"binder: %d:%d write %ld at %08lx, read %ld at %08lx\\n\", proc-&gt;pid, thread-&gt;pid, bwr.write_size, bwr.write_buffer, bwr.read_size, bwr.read_buffer); if (bwr.write_size &gt; 0) &#123; //当写缓存中有数据，则执行binder写操作 ret = binder_thread_write(proc, thread, (void __user *)bwr.write_buffer, bwr.write_size, &amp;bwr.write_consumed); trace_binder_write_done(ret); if (ret &lt; 0) &#123;//当写失败，再将bwr数据写回用户空间，并返回 bwr.read_consumed = 0; if (copy_to_user(ubuf, &amp;bwr, sizeof(bwr))) ret = -EFAULT; goto err; &#125; &#125; if (bwr.read_size &gt; 0) &#123; //当读缓存中有数据，则执行binder读操作 ret = binder_thread_read(proc, thread, (void __user *)bwr.read_buffer, bwr.read_size, &amp;bwr.read_consumed, filp-&gt;f_flags &amp; O_NONBLOCK); trace_binder_read_done(ret); if (!list_empty(&amp;proc-&gt;todo)) wake_up_interruptible(&amp;proc-&gt;wait);//唤醒等待状态的线程 if (ret &lt; 0) &#123;//当读失败，再将bwr数据写回用户空间，并返回 if (copy_to_user(ubuf, &amp;bwr, sizeof(bwr))) ret = -EFAULT; goto err; &#125; &#125; binder_debug(BINDER_DEBUG_READ_WRITE, \"binder: %d:%d wrote %ld of %ld, read return %ld of %ld\\n\", proc-&gt;pid, thread-&gt;pid, bwr.write_consumed, bwr.write_size, bwr.read_consumed, bwr.read_size); if (copy_to_user(ubuf, &amp;bwr, sizeof(bwr))) &#123; ret = -EFAULT; goto err; &#125; break; &#125; BINDER_WRITE_READ的流程如下： 首先，把用户空间数据ubuf拷贝到内核空间bwr； 当bwr写缓存有数据，则执行binder_thread_write；当写失败则将bwr数据写回用户空间并退出； 当bwr读缓存有数据，则执行binder_thread_read；当读失败则再将bwr数据写回用户空间并退出； 最后，把内核数据bwr拷贝到用户空间ubuf。 Binder通信 Binder协议包含在IPC数据中，分为两类: BINDER_COMMAND_PROTOCOL：binder请求码，以”BC_“开头，简称BC码，用于从IPC层传递到Binder Driver层； BINDER_RETURN_PROTOCOL ：binder响应码，以”BR_“开头，简称BR码，用于从Binder Driver层传递到IPC层； 通信过程 其中binder_work.type共有6种类型： 123456BINDER_WORK_TRANSACTION //最常见类型BINDER_WORK_TRANSACTION_COMPLETEBINDER_WORK_NODEBINDER_WORK_DEAD_BINDERBINDER_WORK_DEAD_BINDER_AND_CLEARBINDER_WORK_CLEAR_DEATH_NOTIFICATION 通信对象在Client和Server的一次通信过程中，涉及到4中类型对象。 Binder驱动程序中的Binder实体对象(binder_node),Binder引用对象(binder_ref) Binder库中的Binder本地对象(BBinder),Binder代理对象(BpBinder)","tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"},{"name":"系统","slug":"系统","permalink":"http://yoursite.com/tags/系统/"},{"name":"binder","slug":"binder","permalink":"http://yoursite.com/tags/binder/"}]},{"title":"C++指针学习","date":"2018-08-01T10:28:02.000Z","path":"2018/08/01/C-指针学习/","text":"C++是在大学时候有学习过，但自从开始Android开发之路后就再也没有写过C++代码了。最近打算重拾C++，就从指针开始。 什么是指针指针是一个变量，其值为另一个变量的地址，即内存位置的直接地址。指针变量的声明方式为： 1type *var-name; 在这里，type 是指针的基类型，它必须是一个有效的 C++ 数据类型，var-name 是指针变量的名称。用来声明指针的星号 * 与乘法中使用的星号是相同的。但是，在这个语句中，星号是用来指定一个变量是指针。以下是有效的指针声明： 1234int *ip; /* 一个整型的指针 */double *dp; /* 一个 double 型的指针 */float *fp; /* 一个浮点型的指针 */char *ch; /* 一个字符型的指针 */ 所有指针的值的实际数据类型，不管是整型、浮点型、字符型，还是其他的数据类型，都是一样的，都是一个代表内存地址的长的十六进制数。不同数据类型的指针之间唯一的不同是，指针所指向的变量或常量的数据类型不同。 使用指针123456789101112131415161718192021222324#include &lt;iostream&gt; using namespace std; int main ()&#123; int var = 20; // 实际变量的声明 int *ip; // 指针变量的声明 ip = &amp;var; // 在指针变量中存储 var 的地址 cout &lt;&lt; \"Value of var variable: \"; cout &lt;&lt; var &lt;&lt; endl; // 输出在指针变量中存储的地址 cout &lt;&lt; \"Address stored in ip variable: \"; cout &lt;&lt; ip &lt;&lt; endl; // 访问指针中地址的值 cout &lt;&lt; \"Value of *ip variable: \"; cout &lt;&lt; *ip &lt;&lt; endl; return 0;&#125; 当上面的代码被编译和执行时，它会产生下列结果： 123Value of var variable: 20Address stored in ip variable: 0xbfc601acValue of *ip variable: 20 指针和数组指针和数组是密切相关的。事实上，指针和数组在很多情况下是可以互换的。 12345678910111213141516171819202122232425#include &lt;iostream&gt; using namespace std;const int MAX = 3; int main ()&#123; int var[MAX] = &#123;10, 100, 200&#125;; int *ptr; // 指针中的数组地址 ptr = var; for (int i = 0; i &lt; MAX; i++) &#123; cout &lt;&lt; \"var[\" &lt;&lt; i &lt;&lt; \"]的内存地址为 \"; cout &lt;&lt; ptr &lt;&lt; endl; cout &lt;&lt; \"var[\" &lt;&lt; i &lt;&lt; \"] 的值为 \"; cout &lt;&lt; *ptr &lt;&lt; endl; // 移动到下一个位置 ptr++; &#125; return 0;&#125; 123456var[0]的内存地址为 0x7fff59707adcvar[0] 的值为 10var[1]的内存地址为 0x7fff59707ae0var[1] 的值为 100var[2]的内存地址为 0x7fff59707ae4var[2] 的值为 200 指针和数组并不是完全互换的。 12345678910111213141516#include &lt;iostream&gt; using namespace std;const int MAX = 3; int main ()&#123; int var[MAX] = &#123;10, 100, 200&#125;; for (int i = 0; i &lt; MAX; i++) &#123; *var = i; // 这是正确的语法 var++; // 这是不正确的 &#125; return 0;&#125; 把指针运算符 * 应用到 var 上是完全可以的，但修改 var 的值是非法的。这是因为 var 是一个指向数组开头的常量，不能作为左值。 由于一个数组名对应一个指针常量，只要不改变数组的值，仍然可以用指针形式的表达式。例如，下面是一个有效的语句，把 var[2] 赋值为 500： 1*(var + 2) = 500; 上面的语句是有效的，且能成功编译，因为 var 未改变。 指针数组123456789101112131415161718192021#include &lt;iostream&gt; using namespace std;const int MAX = 3; int main ()&#123; int var[MAX] = &#123;10, 100, 1000&#125;; int *ptr[MAX]; //MAX个整数指针 for (int i = 0; i &lt; MAX; i++) &#123; ptr[i] = &amp;var[i]; // 赋值为整数的地址 &#125; for (int i = 0; i &lt; MAX; i++) &#123; cout &lt;&lt; \"Value of var[\" &lt;&lt; i &lt;&lt; \"] = \"; cout &lt;&lt; *ptr[i] &lt;&lt; endl; &#125; return 0;&#125; 123Value of var[0] = 10Value of var[1] = 100Value of var[2] = 1000 指向指针的指针指向指针的指针是一种多级间接寻址的形式，或者说是一个指针链。通常，一个指针包含一个变量的地址。当我们定义一个指向指针的指针时，第一个指针包含了第二个指针的地址，第二个指针指向包含实际值的位置。 一个指向指针的指针变量必须如下声明，即在变量名前放置两个星号。例如，下面声明了一个指向 int 类型指针的指针： 1int **var; 当一个目标值被一个指针间接指向到另一个指针时，访问这个值需要使用两个星号运算符，如下面实例所示： 12345678910111213141516171819202122232425#include &lt;iostream&gt; using namespace std; int main ()&#123; int var; int *ptr; int **pptr; var = 3000; // 获取 var 的地址 ptr = &amp;var; // 使用运算符 &amp; 获取 ptr 的地址 pptr = &amp;ptr; // 使用 pptr 获取值 cout &lt;&lt; \"Value of var :\" &lt;&lt; var &lt;&lt; endl; cout &lt;&lt; \"Value available at *ptr :\" &lt;&lt; *ptr &lt;&lt; endl; cout &lt;&lt; \"Value available at **pptr :\" &lt;&lt; **pptr &lt;&lt; endl; return 0;&#125; 123Value of var = 3000Value available at *ptr = 3000Value available at **pptr = 3000 传递指针给函数C++ 允许您传递指针给函数，只需要简单地声明函数参数为指针类型即可。 下面的实例中，我们传递一个无符号的 long 型指针给函数，并在函数内改变这个值： 12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;ctime&gt; using namespace std;void getSeconds(unsigned long *par); int main ()&#123; unsigned long sec; getSeconds( &amp;sec ); // 输出实际值 cout &lt;&lt; \"Number of seconds :\" &lt;&lt; sec &lt;&lt; endl; return 0;&#125; void getSeconds(unsigned long *par)&#123; // 获取当前的秒数 *par = time( NULL ); return;&#125; 1Number of seconds :1294450468","tags":[{"name":"C++","slug":"C","permalink":"http://yoursite.com/tags/C/"},{"name":"指针","slug":"指针","permalink":"http://yoursite.com/tags/指针/"}]},{"title":"Java内存模型(JMM)","date":"2018-07-31T11:20:28.000Z","path":"2018/07/31/Java内存模型/","text":"Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。因此在开发过程中很可能遇到各种奇怪的内存可见性问题。 JMMJava线程之间的通信由Java内存模型(JMM)控制，JMM决定了一个线程对共享变量的写入何时对另一个线程可见。 如图，线程A和线程B之间要通信的话，必须经历： 线程A把本地内存A中更新过的共享变量刷新到主内存中去。 线程B到主内存中去读取线程A之前已经更新过的数据。 线程A向B发送消息，而这个通信过程必须要经过主内存，JMM就是通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性保证。 那JMM具体是如何控制这个过程呢？我们需要认识几个基础概念：内存屏障（memory Barriers），指令重排序，happens-before规则，as-if-serial语义 内存屏障内存屏障，又称内存栅栏，是一个CPU指令，主要功能如下： 保证特定操作的执行顺序 影响某些数据(或是某条指令的执行结果)的内存可见性 编译器和CPU能够重排序指令，保证最终相同的结果，尝试优化性能。插入一条Memory Barrier会告诉编译器和CPU：不管什么指令都不能和这条Memory Barrier指令重排序。 Memory Barrier所做的另外一件事是强制刷出各种CPU cache，如一个 Write-Barrier（写入屏障）将刷出所有在 Barrier 之前写入 cache 的数据，因此，任何CPU上的线程都能读取到这些数据的最新版本。 在Java中，volatile是基于Memory Barrier实现的。 指令重排序指令重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。但是，JMM确保在不同的编译器和不同的处理器平台之上，通过插入特定类型的Memory Barrier来禁止特定类型的编译器重排序和处理器重排序，为上层提供一致的内存可见性保证。 编译器优化重排序：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序：如果不存l在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序：处理器使用缓存和读写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 数据依赖性如果两个操作访问同一个变量，其中一个为写操作，此时这两个操作之间存在数据依赖性。 上面三种情况，只要重排序两个操作的执行顺序，程序的执行结果就会被改变。因此，编译器和处理器不会改变存在数据依赖性关系的两个操作的执行顺序，即不会重排序。 happens-before规则在JMM中，如果一个操作的执行结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系，这个的两个操作既可以在同一个线程，也可以在不同的两个线程中。 与程序员密切相关的happens-before规则如下： 程序顺序规则：一个线程中的每个操作，happens-before于该线程中任意的后续操作。 监视器锁规则：对一个锁的解锁操作，happens-before于随后对这个锁的加锁操作。 volatile域规则：对一个volatile域的写操作，happens-before于任意线程后续对这个volatile域的读。 传递性规则：如果 A happens-before B，且 B happens-before C，那么A happens-before C。 两个操作之间具有happens-before关系，并不意味前一个操作必须要在后一个操作之前执行！仅仅要求前一个操作的执行结果，对于后一个操作是可见的，且前一个操作按顺序排在后一个操作之前 as-if-serial语义不管怎么重排序，单线程下的执行结果不能被改变，编译器、runtime和处理器都必须遵守as-if-serial语义。","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://yoursite.com/tags/多线程/"},{"name":"同步","slug":"同步","permalink":"http://yoursite.com/tags/同步/"},{"name":"JMM","slug":"JMM","permalink":"http://yoursite.com/tags/JMM/"}]},{"title":"synchronized关键字","date":"2018-07-30T12:48:47.000Z","path":"2018/07/30/synchronized关键字/","text":"在java中每一个对象都可以作为锁： 对于普通方法，锁是当前实例对象 对于静态同步方法，锁是当前类的class对象 对于同步方法，锁是synchronized括号里配置的对象。 synchronized实现原理JVM是基于进入Monitor对象(monitorenter)和退出Monitor对象(monitorexit)来实现方法同步和代码同步。 123456static void Sort(int [] array)&#123; synchronized (array)&#123; //now sort elements in array &#125; &#125; 上面这一段代码通过javap编译后生成字节码： monitorenter指令是在编译后插入到代码块的开始位置，monitorexit插入到结束和异常处。任何对象都有一个monitor与之关联，当有一个monitor被劫持后，它将处于锁定状态。线程执行到monitorenter时，将会尝试获取对象所对应的monitor的所有权，即尝试获取对象的锁。 Java对象头HotSpot虚拟机中，对象在内存中的布局分为三块区域：对象头、实例数据和对齐填充。 synchronized用的锁是存在Java对象头中的。如果对象是数组类型，则虚拟机使用3个字宽(Word)存储对象头，如果对象是非数组类型，则用2字宽存储对象头。 其中Mark Word里默认存储对象的HashCode、分代年龄和锁标记位。32位JVM的Mark Word默认存储结构如下图。 锁状态 25bit 4bit 1bit是否是偏向锁 2bit锁标志位 无锁状态 对象的hashCode 对象分代年龄 0 01 在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下四种数据: JDK对锁的优化简单来说在JVM中monitorenter和monitorexit字节码依赖于底层的操作系统的Mutex Lock来实现的，但是由于使用Mutex Lock需要将当前线程挂起并从用户态切换到内核态来执行，这种切换的代价是非常昂贵的；然而在现实中的大部分情况下，同步方法是运行在单线程环境（无锁竞争环境）如果每次都调用Mutex Lock那么将严重的影响程序的性能。 在Java SE 1.6中对锁的实现引入了大量的优化，如锁粗化（Lock Coarsening）、锁消除（Lock Elimination）、轻量级锁（Lightweight Locking）、偏向锁（Biased Locking）、适应性自旋（Adaptive Spinning）等技术来减少锁操作的开销。 锁粗化（Lock Coarsening）：也就是减少不必要的紧连在一起的unlock，lock操作，将多个连续的锁扩展成一个范围更大的锁。 锁消除（Lock Elimination）：通过运行时JIT编译器的逃逸分析来消除一些没有在当前同步块以外被其他线程共享的数据的锁保护，通过逃逸分析也可以在线程本地Stack上进行对象空间的分配（同时还可以减少Heap上的垃圾收集开销）。 轻量级锁（Lightweight Locking）：这种锁实现的背后基于这样一种假设，即在真实的情况下我们程序中的大部分同步代码一般都处于无锁竞争状态（即单线程执行环境），在无锁竞争的情况下完全可以避免调用操作系统层面的重量级互斥锁，取而代之的是在monitorenter和monitorexit中只需要依靠一条CAS原子指令就可以完成锁的获取及释放。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒. 偏向锁（Biased Locking）：是为了在无锁竞争的情况下避免在锁获取过程中执行不必要的CAS原子指令，因为CAS原子指令虽然相对于重量级锁来说开销比较小但还是存在非常可观的本地延迟。 适应性自旋（Adaptive Spinning）：当线程在获取轻量级锁的过程中执行CAS操作失败时，在进入与monitor相关联的操作系统重量级锁（mutex semaphore）前会进入忙等待（Spinning）然后再次尝试，当尝试一定的次数后如果仍然没有成功则调用与该monitor关联的semaphore（即互斥锁）进入到阻塞状态。 锁的升级在Java SE 1.6中为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在JDK1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。 偏向锁在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一个线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。 当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录中存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需要简单测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标示是否被设置为1(表示当前是偏向锁)：如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头中的偏向锁指向当前线程。 偏向锁的撤销偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。下图中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。 膨胀过程当前线程执行CAS获取偏向锁失败（这一步是偏向锁的关键），表示在该锁对象上存在竞争并且这个时候另外一个线程获得偏向锁所有权。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，并从偏向锁所有者的私有Monitor Record列表中获取一个空闲的记录，并将Object设置LightWeight Lock状态并且Mark Word中的LockRecord指向刚才持有偏向锁线程的Monitor record，最后被阻塞在安全点的线程被释放，进入到轻量级锁的执行路径中，同时被撤销偏向锁的线程继续往下执行同步代码。 轻量级锁轻量级锁加锁：线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 轻量级锁解锁：轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。下图是两个线程同时争夺锁，导致锁膨胀的流程图。 因为自旋会消耗CPU，为了避免无用的自旋(比如获得锁的线程被阻塞住了)，一旦锁升级成重量级锁，就不会再恢复成轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程会进行下一轮的夺锁之争。 锁的优缺点对比","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://yoursite.com/tags/多线程/"},{"name":"同步","slug":"同步","permalink":"http://yoursite.com/tags/同步/"}]},{"title":"Android Content Provider实现原理","date":"2018-07-29T12:34:11.000Z","path":"2018/07/29/Android-Content-Provide实现原理/","text":"ContentProvider(内容提供者)用于提供数据的统一访问格式，封装底层的具体实现。对于数据的使用者来说，无需知晓数据的来源是数据库、文件，或者网络，只需简单地使用ContentProvider提供的数据操作接口，也就是增(insert)、删(delete)、改(update)、查(query)四个过程。 ContentProviderContentProvider作为Android四大组件之一，并没有Activity那样复杂的生命周期，只有简单地onCreate过程。ContentProvider是一个抽象类，当实现自己的ContentProvider类，只需继承于ContentProvider，并且实现以下六个abstract方法即可： insert(Uri, ContentValues)：插入新数据； delete(Uri, String, String[])：删除已有数据； update(Uri, ContentValues, String, String[])：更新数据； query(Uri, String[], String, String[], String)：查询数据； onCreate()：执行初始化工作； getType(Uri)：获取数据MIME类型。 ContentResolver其他app或者进程想要操作ContentProvider，则需要先获取其相应的ContentResolver，再利用ContentResolver类来完成对数据的增删改查操作 12345ContentResolver cr = getContentResolver(); //获取ContentResolverUri uri = Uri.parse(\"content://com.gityuan.articles/android/3\");Cursor cursor = cr.query(uri, null, null, null, null); //执行查询操作...cursor.close(); //关闭 继承关系图 进程不存在 client进程：通过binder(调用AMS.getContentProviderImpl)向system_server进程请求相应的provider； system进程：如果目标provider所对应的进程尚未启动，system_server会调用startProcessLocked来启动provider进程； 当进程启动完成，此时cpr.provider ==null，则system_server便会进入wait()状态，等待目标provider发布； provider进程：进程启动后执行完attch到system_server，紧接着执行bindApplication；在这个过程会installProvider以及 publishContentProviders；再binder call到system_server进程； system进程：再回到system_server，发布provider信息，并且通过notify机制，唤醒前面处于wait状态的binder线程；并将 getContentProvider的结果返回给client进程； client进程：接着执行installProvider操作，安装provider的(包含对象记录,引用计数维护等工作)； 进程存在 Client进程在获取provider的过程,发现cpr为空,则调用scheduleInstallProvider来向provider所在进程发出一个oneway的binder请求,并进入wait()状态. provider进程安装完provider信息,则notifyAll()处于等待状态的进程/线程; 如果provider在publish完成之后, 这时再次请求该provider,那就便没有的最右侧的这个过程,直接在AMS.getContentProviderImpl之后便进入AT.installProvider的过程,而不会再次进入wait()过程.","tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"},{"name":"系统","slug":"系统","permalink":"http://yoursite.com/tags/系统/"}]},{"title":"Volatile关键字","date":"2018-07-28T13:26:13.000Z","path":"2018/07/28/Volatile关键字/","text":"Java语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独的获取这个变量。如果有一个字段被声明为Volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。 volatile是如何保证可见性的 ？在java虚拟机的内存模型中，有主内存和工作内存的概念，每个线程对应一个工作内存，并共享主内存的数据，下面看看操作普通变量和volatile变量有什么不同： 对于普通变量：读操作会优先读取工作内存的数据，如果工作内存中不存在，则从主内存中拷贝一份数据到工作内存中；写操作只会修改工作内存的副本数据，这种情况下，其它线程就无法读取变量的最新值。 对于volatile变量，读操作时JMM会把工作内存中对应的值设为无效，要求线程从主内存中读取数据；写操作时JMM会把工作内存中对应的数据刷新到主内存中，这种情况下，其它线程就可以读取变量的最新值。 volatile变量的内存可见性是基于内存屏障(Memory Barrier)实现的，什么是内存屏障？内存屏障，又称内存栅栏，是一个CPU指令。在程序运行时，为了提高执行性能，编译器和处理器会对指令进行重排序，JMM为了保证在不同的编译器和CPU上有相同的结果，通过插入特定类型的内存屏障来禁止特定类型的编译器重排序和处理器重排序，插入一条内存屏障会告诉编译器和CPU：不管什么指令都不能和这条Memory Barrier指令重排序。 1instance = new Singleton(); //instance是volatile变量 转变为汇编语言 可以看到有有一个Lock前缀指令，相当于上述的内存屏障。该指令，在多核处理器下会引发两件事： 将当前处理器缓存行的数据写回到系统内存 这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。 为了提高处理速度，处理器不直接和内存进行通信，而是将系统内存的数据读到内部缓存(L1,L2或其他)后再操作，但操作完不知道何时写到内存。如果对声明了volatile的变量进行写操作，JVM会向处理器发送一条Lock前缀指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器的缓存值仍然是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存一致，就会实现缓存一致性协议，每个处理器通过嗅探在总线上的数据来检查自己的缓存的值是不是过期了，当处理器发现自己缓存行的对应的内存地址被修改，就会将当前处理器的缓存行设置为无效状态，当处理器对这个数据进行修改的时候，会重新从系统内存中把数据读到处理器缓存里。 volatile变量很方便，但也存在一些局限性。volatile通常用作某个操作完成、发生中断或者状态的标志，但比如在做递增操作(count++)时，volatile不足以确保原子性，除非能保证只有一个线程对变量执行写操作。 加锁机制既可以确保可见性又可以确保原子性，volatile只能确保可见性 当且仅当满足以下条件时，才使用volatile变量 对变量的写入操作不依赖变量的当前值，或者能确保只有一个线程更新变量的值，如多线程下执行a++，是无法通过volatile保证结果准确性的 该变量不会与其他状态变量一起纳入不变性条件中 在访问时不用加锁 推荐阅读：占小狼博客","tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://yoursite.com/tags/多线程/"},{"name":"同步","slug":"同步","permalink":"http://yoursite.com/tags/同步/"}]},{"title":"Service组件启动过程","date":"2018-07-27T11:36:40.000Z","path":"2018/07/27/Service组件启动过程/","text":"Service有两种启动方式startService()和bindService() startService 启动流程： Process A进程采用Binder IPC向system_server进程发起startService请求； system_server进程接收到请求后，向zygote进程发送创建进程的请求； zygote进程fork出新的子进程Remote Service进程； Remote Service进程，通过Binder IPC向sytem_server进程发起attachApplication请求； system_server进程在收到请求后，进行一系列准备工作后，再通过binder IPC向remote Service进程发送scheduleCreateService请求； Remote Service进程的binder线程在收到请求后，通过handler向主线程发送CREATE_SERVICE消息； 主线程在收到Message后，通过发射机制创建目标Service，并回调Service.onCreate()方法。 bindService当一个Service组件被一个Activity或一个Service启动时，可以将它们绑定起来，以便启动者方便地得到它的访问接口。 调用流程图： 图中蓝色代表的是Client进程(发起端), 红色代表的是system_server进程, 黄色代表的是target进程(service所在进程); Client进程: 通过getServiceDispatcher获取Client进程的匿名Binder服务端，即LoadedApk.ServiceDispatcher.InnerConnection,该对象继承于IServiceConnection.Stub； 再通过bindService调用到system_server进程; system_server进程: 依次通过scheduleCreateService和scheduleBindService方法, 远程调用到target进程; target进程: 依次执行onCreate()和onBind()方法; 将onBind()方法的返回值IBinder(作为target进程的binder服务端)通过publishService传递到system_server进程; system_server进程: 利用IServiceConnection代理对象向Client进程发起connected()调用, 并把target进程的onBind返回Binder对象的代理端传递到Client进程; Client进程: 回调到onServiceConnection()方法, 该方法的第二个参数便是target进程的binder代理端. 到此便成功地拿到了target进程的代理, 可以畅通无阻地进行交互.","tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"},{"name":"系统","slug":"系统","permalink":"http://yoursite.com/tags/系统/"}]},{"title":"Android广播机制","date":"2018-07-25T12:34:47.000Z","path":"2018/07/25/Android广播机制/","text":"在Android系统中，广播是一种在组件之间进行消息传递的方式。广播机制是一种基于消息发布和订阅的事件驱动模型，即广播发送着负责发布消息，而接受着需要先订阅消息，然后才能接到消息。 广播机制存在一个注册中心，由ActivityManagerService担任。广播接受者订阅消息的表现形式就是将自己注册到AMS中，并指定要接受的广播的类型。广播发送者发送广播时，首先发送到AMS，然后AMS根据这个广播的类型找到相应的广播接受者，最后将这个广播发送它们处理。 BroadcastReceiver分为两类： 静态广播接收者：通过AndroidManifest.xml的标签来申明的BroadcastReceiver。 动态广播接收者：通过AMS.registerReceiver()方式注册的BroadcastReceiver，动态注册更为灵活，可在不需要时通过unregisterReceiver()取消注册。 从广播发送方式可分为： 普通广播：通过Context.sendBroadcast()发送，可并行处理 有序广播：通过Context.sendOrderedBroadcast()发送，串行处理 广播的注册和发送的过程时序图 注册：在ActivityManagerService中，用一个进程记录块来表示这个应用程序进程，它里面有一个列表receivers，专门用来保存这个进程注册的广播接收器。接着，又把这个ReceiverList列表以receiver为Key值保存在ActivityManagerService的成员变量mRegisteredReceivers中，这些都是为了方便在收到广播时，快速找到对应的广播接收器的。 发送： 通过sendBroadcast把一个广播通过Binder进程间通信机制发送给ActivityManagerService，ActivityManagerService根据这个广播的Action类型找到相应的广播接收器，然后把这个广播放进自己的消息队列中去，就完成第一阶段对这个广播的异步分发了。 ActivityManagerService在消息循环中处理这个广播，并通过Binder进程间通信机制把这个广播分发给注册的广播接收分发器ReceiverDispatcher，ReceiverDispatcher把这个广播放进MainActivity所在的线程的消息队列中去，就完成第二阶段对这个广播的异步分发了。 ReceiverDispatcher的内部类Args在MainActivity所在的线程消息循环中处理这个广播，最终是将这个广播分发给所注册的BroadcastReceiver实例的onReceive函数进行处理","tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"},{"name":"BroadCast","slug":"BroadCast","permalink":"http://yoursite.com/tags/BroadCast/"},{"name":"原理","slug":"原理","permalink":"http://yoursite.com/tags/原理/"}]},{"title":"Activity组件启动过程","date":"2018-07-25T11:37:11.000Z","path":"2018/07/25/Activity组件启动过程/","text":"Activity是Android应用程序的四大组件之一，它负责管理Android应用程序的用户界面。 从应用程序的角度，我们将Activity分为两种类型：根Activity和子Activity。根Activity以快捷图标的形式显示在应用程序启动器中，它的启动过程代表了一个Android应用程序的启动过程。 根Activity启动过程 启动流程： 点击桌面App图标，Launcher进程采用Binder IPC向system_server进程发起startActivity请求； system_server进程接收到请求后，向zygote进程发送创建进程的请求； Zygote进程fork出新的子进程，即App进程； App进程，通过Binder IPC向sytem_server进程发起attachApplication请求； system_server进程在收到请求后，进行一系列准备工作后，再通过binder IPC向App进程发送scheduleLaunchActivity请求； App进程的binder线程（ApplicationThread）在收到请求后，通过handler向主线程发送LAUNCH_ACTIVITY消息； 主线程在收到Message后，通过发射机制创建目标Activity，并回调Activity.onCreate()等方法。","tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"},{"name":"系统","slug":"系统","permalink":"http://yoursite.com/tags/系统/"}]},{"title":"ActivityRecord","date":"2018-07-25T10:31:30.000Z","path":"2018/07/25/ActivityRecord/","text":"每一个ActivityRecord都会有一个Activity与之对应，一个Activity可能会有多个ActivityRecord，因为Activity可以被多次实例化，取决于其launchmode。一系列相关的ActivityRecord组成了一个TaskRecord，TaskRecord是存在于ActivityStack中，ActivityStackSupervisor是用来管理这些ActivityStack的。 ActivityRecord: 记录着Activity信息 TaskRecord: 记录着task信息 ActivityStack: 栈信息 ActivityRecordActivity的信息记录在ActivityRecord对象, 并通过通过成员变量task指向TaskRecord ProcessRecord app //跑在哪个进程 TaskRecord task //跑在哪个task ActivityInfo info // Activity信息 int mActivityType //Activity类型 ActivityState state //Activity状态 ApplicationInfo appInfo //跑在哪个app ComponentName realActivity //组件名 String packageName //包名 String processName //进程名 int launchMode //启动模式 int userId // 该Activity运行在哪个用户id TaskRecordTask的信息记录在TaskRecord对象. ActivityStack stack; //当前所属的stack ArrayList mActivities; // 当前task的所有Activity列表int taskId String affinity； 是指root activity的affinity，即该Task中第一个Activity; int mCallingUid; String mCallingPackage； //调用者的包名 ActivityStack ArrayList mTaskHistory //保存所有的Task列表 ArrayList mStacks; //所有stack列表 final int mStackId; int mDisplayId; ActivityRecord mPausingActivity //正在pause ActivityRecord mLastPausedActivity ActivityRecord mResumedActivity //已经resumed ActivityRecord mLastStartedActivity ActivityStackSupervisor ActivityStack mHomeStack //桌面的stack ActivityStack mFocusedStack //当前聚焦stack ActivityStack mLastFocusedStack //正在切换 SparseArray mActivityDisplays //displayId为key SparseArray mActivityContainers // mStackId为key Activity栈关系 一般地，对于没有分屏功能以及虚拟屏的情况下，ActivityStackSupervisor与ActivityDisplay都是系统唯一； ActivityDisplay主要有Home Stack(Launcher等)和App Stack(应用相关)这两个栈； 每个ActivityStack中可以有若干个TaskRecord对象； 每个TaskRecord包含如果个ActivityRecord对象； 每个ActivityRecord记录一个Activity信息。 看完上面的介绍，再来看看Activity的四种启动模式。 standard ： Activity的默认启动模式，在这种模式下启动的activity可以被多次实例化。 singleTop：如果要启动的Activity已经在栈顶，则不会重新创建Activity，只会调用该该Activity的onNewIntent()方法。 如果要启动的Activity不在栈顶，则会重新创建该Activity的实例。 singleTask：这种启动模式的Activity 会在其所在的任务栈中始终保持只有一个实例，当启动这个Activity的时候，系统会搜寻系统中现存的任务栈，如果没有任务栈中有该Activity的实例，则会创建这个Activity属于的任务栈，并正常创建该Activity 实例，否则会把这个任务栈调到前台，且会将任务栈中其实例以上的所有Activity出栈，并调用该实例的onNewIntent()方法将Intent对象传递到这个实例当中。 singleInstance：基本和singleTask一样，不同的是启动Activity时，首先要创建在一个新栈，然后创建该Activity实例并压入新栈中，新栈中只会存在这一个Activity实例。","tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"},{"name":"系统","slug":"系统","permalink":"http://yoursite.com/tags/系统/"}]},{"title":"Android中的进程ProcessRecord","date":"2018-07-25T08:31:27.000Z","path":"2018/07/25/Android中的进程ProcessRecord/","text":"Android系统中用于描述进程的数据结构是ProcessRecord对象，AMS便是管理进程的核心模块。四大组件 （Activity,Service, BroadcastReceiver, ContentProvider）定义在AndroidManifest.xml文件， 每一项都可以用属性android:process指定所运行的进程。同一个app可以运行在通过一个进程，也可以运行在多个进程， 甚至多个app可以共享同一个进程。 进程管理进程关系图 进程与AMS的关联这里只介绍AMS的进程相关的成员变量： mProcessNames：数据类型为ProcessMap，以进程名和userId为key来记录ProcessRecord; 添加进程，addProcessNameLocked() 删除进程，removeProcessNameLocked() mPidsSelfLocked: 数据类型为SparseArray，以进程pid为key来记录ProcessRecord; startProcessLocked()，移除已存在进程，增加新创建进程pid信息； removeProcessLocked，processStartTimedOutLocked，cleanUpApplicationRecordLocked移除进程； mLruProcesses：数据类型为ArrayList，以进程最近使用情况来排序记录ProcessRecord;其中第一个元素代表的便是最近最少使用的进程；updateLruProcessLocked()更新进程队列位置； mRemovedProcesses：数据类型为ArrayList，记录所有需要强制移除的进程； mProcessesToGc：数据类型为ArrayList，记录系统进入idle状态需执行gc操作的进程； mPendingPssProcesses：数据类型为ArrayList，记录将要收集内存使用数据PSS的进程； mProcessesOnHold：数据类型为ArrayList，记录刚开机过程，系统还没与偶准备就绪的情况下， 所有需要启动的进程都放入到该队列； mPersistentStartingProcesses：数据类型ArrayList，正在启动的persistent进程； mHomeProcess: 记录包含home Activity所在的进程； mPreviousProcess：记录用户上一次刚访问的进程；其中mPreviousProcessVisibleTime记录上一个进程的用户访问时间； mProcessList: 数据类型ProcessList，用于进程管理，Adj常量定义位于该文件； 进程与组件的关联系统AMS这边是由ProcessRecord对象记录进程，进程自身比较重要成员变量如下： processName：记录进程名，默认情况下进程名和该进程运行的第一个apk的包名是相同的，当然也可以自定义进程名； pid: 记录进程pid，该值在由进程创建时内核所分配的。 thread：执行完attachApplicationLocked()方法，会把客户端进程ApplicationThread的binder服务的代理端传递到 AMS，并保持到ProcessRecord的成员变量thread；ProcessRecord.makeActive，赋值；ProcessRecord.makeInactive，清空； info：记录运行在该进程的第一个应用； pkgList: 记录运行在该进程中所有的包名，比如通过addPackage()添加； pkgDeps：记录该进程所依赖的包名，比如通过addPackageDependency()添加； lastActivityTime：每次updateLruProcessLocked()过程会更新该值； killedByAm：当值为true，意味着该进程是被AMS所杀，而非由于内存低而被LMK所杀； killed：当值为true，意味着该进程被杀，不论是AMS还是其他方式； waitingToKill：比如cleanUpRemovedTaskLocked()过程会赋值为”remove task”，当该进程处于后台且 任一组件都运行在某个进程，再来说说ProcessRecord对象中与组件的关联关系： connections：举例来说，进程A调用bindService()方法去bind远程进程B的Service。 此时会在进程A的ProcessRecord.connections添加一个ConnectionRecord. pubProviders: 该进程所有对外发布的ContentProvider信息，这是是以ArrayMap形式保存，即 以provider的name为key,以ContentProviderRecord为value的键值对结构体。 conProviders: 当进程A调用query()的过程，会执行getContentProvider()方法去向进程B请求 provider的代理。此时会在进程A的ProcessRecord.conProviders添加一个ContentProviderConnection。 在AMS中使用ProcessMap以Map的方式存储所有进程，而在ProcessRecord中又以List的方式存储在本进程中的所有Activity、Service、provider和BroadCast; AMS的组件管理AMS对所有组件进行管理，各个组件在system_server的核心信息记录如下： Service的信息记录在ActiveServices和AMS Broadcast信息记录在BroadcastQueue和AMS Activity信息记录在ActivityStack，ActivityStackSupervisor，以及AMS; Provider信息记录在ProviderMap和AMS; ActivityAMS对象123456public final class ActivityManagerService extends ...&#123; //当前聚焦的Activity ActivityRecord mFocusedActivity = null; //用于管理各个Activity栈 final ActivityStackSupervisor mStackSupervisor;&#125; ASS对象1234567891011121314151617181920212223242526272829public final class ActivityStackSupervisor implements DisplayListener &#123; //桌面app所在栈 ActivityStack mHomeStack; //当前可以接受Input事件，或许启动下一个Activity的栈 ActivityStack mFocusedStack; //当该值等于mFocusedStack，代表当前栈顶的Activity已进入resumed状态； //当该值等于上一个旧栈时，代表正处理activity切换状态； private ActivityStack mLastFocusedStack; //在完成相应目标前，等待新的Activity成为可见的Activity列表 final ArrayList&lt;ActivityRecord&gt; mWaitingVisibleActivities = new ArrayList&lt;&gt;(); //等待找到下一个可见Activity的等待列表 final ArrayList&lt;IActivityManager.WaitResult&gt; mWaitingActivityVisible = new ArrayList&lt;&gt;(); //等待找到下一个已启动Activity的等待列表 final ArrayList&lt;IActivityManager.WaitResult&gt; mWaitingActivityLaunched = new ArrayList&lt;&gt;(); //等待上一个activity安置完成，则即将进入被stopped的Activity列表 final ArrayList&lt;ActivityRecord&gt; mStoppingActivities = new ArrayList&lt;&gt;(); //等待上一个activity安置完成，则即将进入被finished的Activity列表 final ArrayList&lt;ActivityRecord&gt; mFinishingActivities = new ArrayList&lt;&gt;(); //即将进入sleep状态的进程所对应的Activity列表 final ArrayList&lt;ActivityRecord&gt; mGoingToSleepActivities = new ArrayList&lt;&gt;();&#125; AS对象12345678910111213141516final class ActivityStack&#123; //记录该栈中所有的task private final ArrayList&lt;TaskRecord&gt; mTaskHistory = new ArrayList&lt;&gt;(); //按LRU方式排序的Activity列表，队尾成员是最新活动的Activity final ArrayList&lt;ActivityRecord&gt; mLRUActivities = new ArrayList&lt;&gt;(); //正在执行pausing过程的Activity ActivityRecord mPausingActivity = null; //已处于paused状态的Activity ActivityRecord mLastPausedActivity = null; //已处于Resumed状态的Activity ActivityRecord mResumedActivity = null;&#125; Service12345678910111213141516public final class ActiveServices &#123; //记录不同User下所有的Service信息 final SparseArray&lt;ServiceMap&gt; mServiceMap = new SparseArray&lt;&gt;(); //bind service的连接信息，以IServiceConnection的Bp端作为Keys final ArrayMap&lt;IBinder, ArrayList&lt;ConnectionRecord&gt;&gt; mServiceConnections = new ArrayMap&lt;&gt;(); //已请求启动但尚未启动的Service列表 final ArrayList&lt;ServiceRecord&gt; mPendingServices = new ArrayList&lt;&gt;(); //crash后需要计划重启的Service列表 final ArrayList&lt;ServiceRecord&gt; mRestartingServices = new ArrayList&lt;&gt;(); //正在执行destroyed的service列表 final ArrayList&lt;ServiceRecord&gt; mDestroyingServices = new ArrayList&lt;&gt;();&#125; Broadcast1234567891011121314151617public final class ActivityManagerService extends ...&#123; //前台广播队列 BroadcastQueue mFgBroadcastQueue; //后台广播队列 BroadcastQueue mBgBroadcastQueue; //广播队列数组，也就是前台和后台广播队列 final BroadcastQueue[] mBroadcastQueues = new BroadcastQueue[2]; //粘性广播，[userId，action，ArrayList&lt;Intent&gt;] final SparseArray&lt;ArrayMap&lt;String, ArrayList&lt;Intent&gt;&gt;&gt; mStickyBroadcasts; //动态注册的广播接收者，其中key为客户端InnerReceiver的Bp端，value为ReceiverList final HashMap&lt;IBinder, ReceiverList&gt; mRegisteredReceivers = new HashMap&lt;&gt;(); //从广播intent到已注册接收者的解析器 final IntentResolver&lt;BroadcastFilter, BroadcastFilter&gt; mReceiverResolver；&#125; 123456789public final class BroadcastQueue&#123; //并行广播列表 final ArrayList&lt;BroadcastRecord&gt; mParallelBroadcasts = new ArrayList&lt;&gt;(); //串行广播列表 final ArrayList&lt;BroadcastRecord&gt; mOrderedBroadcasts = new ArrayList&lt;&gt;(); //即将要处理的串行广播，等待目标进程创建完成。每个广播队列只有一个，其他必须等待该广播完成。 BroadcastRecord mPendingBroadcast = null;&#125; Provider1234567public final class ActivityManagerService extends ...&#123; //记录系统所有的provider信息 final ProviderMap mProviderMap; //记录有client正在等待的provider列表，当provider发布完成则从该队列移除 final ArrayList&lt;ContentProviderRecord&gt; mLaunchingProviders;&#125; 1234567891011public final class ProviderMap &#123; //以provider名字(auth)为key的方式所记录的provider信息 private final HashMap&lt;String, ContentProviderRecord&gt; mSingletonByName; //以provider组件名(ComponentName)为key的方式所记录的provider信息 private final HashMap&lt;ComponentName, ContentProviderRecord&gt; mSingletonByClass; //记录不同UserId下的，以auth为key的方式所记录的provider信息 private final SparseArray&lt;HashMap&lt;String, ContentProviderRecord&gt;&gt; mProvidersByNamePerUser; //记录不同UserId下的，以ComponentName为key的方式所记录的provider信息 private final SparseArray&lt;HashMap&lt;ComponentName, ContentProviderRecord&gt;&gt; mProvidersByClassPerUser;&#125; App端的组件信息 App端的组件信息，都保存在ActivityThread和LoadedApk这两个对象，主要保存信息： ActivityThread：记录provider, activity, service在客户端的相关信息； LoadedApk: 记录动态注册的广播接收器，以及bind方式启动service在客户端的相关信息； 转载自Gityuan四大组件之综述","tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"},{"name":"系统","slug":"系统","permalink":"http://yoursite.com/tags/系统/"}]},{"title":"Reactor高性能服务器模型","date":"2018-07-24T08:00:54.000Z","path":"2018/07/24/Reactor高性能服务器模型/","text":"Reactor模型的中心思想是将所有要处理的IO事件及其处理器注册到一个中心的IO多路复用器上，并将主线程阻塞在多路复用器上；当有相应的IO事件到达时，多路复用器将IO事件分发给相应的处理器进行处理。 Reactor模型几个重要组件： Reactor：IO事件的派发者，相当于有分发功能的Selector。 Accept：接受Client的连接，建立对应Client的Handler，并向Reactor注册此Handler。 Handler：和一个Client通讯的实体。 Reactor有三种线程模型： Reactor单线程模型 单线程模式单线程模式是最简单的Reactor模型。Reactor 线程是个多面手，负责多路分离套接字，Accept 新连接，并分派请求到处理器链中。这种单线程模型不能充分利用多核资源，所以实际使用的不多。 Reactor多线程模型 将Handler中的IO操作和非IO操作分开，客户端的请求会直接丢到线程池中。但当客户端进一步增加，Reactor上就会出现瓶颈，它既处理IO操作请求又响应连接请求。 主从Reactor多线程模型 主Reactor用于处理连接请求，从Reactor用于处理IO操作请求。 Netty就是一个实现了Reactor模型的框架，其内部可以根据配置选择使用哪种模型。","tags":[{"name":"Reactor","slug":"Reactor","permalink":"http://yoursite.com/tags/Reactor/"},{"name":"高性能","slug":"高性能","permalink":"http://yoursite.com/tags/高性能/"}]},{"title":"Linux进程调度","date":"2018-07-24T01:28:37.000Z","path":"2018/07/24/Linux进程调度/","text":"进程调度程序是确保进程能有效工作的一个内核子系统。它将决定将哪个进程投入运行，何时运行以及运行多长时间。调度程序没有太复杂的原理，它的原则就是只要有可以执行的进程，那么就总会有程序正在执行。 多任务多任务操作系统是能同时并发地交互执行多个进程的操作系统。可以划分为两类：非抢占式多任务和抢占式多任务。 Linux提供了抢占式的多任务模式。由调度程序决定什么时候停止一个进程的运行，以便其他进程能够得到执行机会。这个强制的挂起动作称为抢占(preemption)。进程在被抢占之前能运行的时间是预先设置好的，这个时间被称为进程的时间片(timeslice)。时间片实际上就是分配给每个可运行进程的处理器时间段。有效管理时间片能够使调度程序从系统全局的角度做出调度决定，这样还可以避免个别进程独占系统资源。 策略策略决定了调度程序在何时让什么进程运行。调度器的策略往往决定系统的整体印象，并且还要负责优化使用处理器时间。 1、I/O消耗型和处理器消耗型的进程进程可以被分为I/O消耗型和处理器消耗型。 I/O消耗型的大部分时间用来提交I/O请求或者等待I/O请求。这样的进程会经常处于可运行状态，但通常都是运行短短一会。 处理器消耗型把时间大多用在执行代码上。除非被抢占，否则它们通常都一直不停运行。对于这种进程，调度策略往往都是尽量降低它们的调度频率，而延长其运行时间。 调度策略通常要在两个矛盾的目标中寻找平衡：进程响应迅速(响应时间短)和最大系统利用率(高吞吐量)。Linux为了保证交互式应用和桌面系统的性能，所有对进程的响应做了优化(缩短响应时间)，更倾向于优先调度I/O消耗型进程。但也并未忽略处理器消耗型进程。 2、进程优先级调度算法中最基本的一类就是基于优先级的调度。通常做法就是优先级高的进程先运行，优先级低的后运行，相同优先级的进程按照轮转方式进行调度。 Linux采用了两种不同的优先级范围。第一种使用nice值，范围从-20到+19，默认为0，越大的nice值意味着更低的优先级。第二种是实时优先级，其值是可配置的，默认情况下它的变化范围是0到99，越高的实时优先级数值意味着进程优先级越高。任何实时进程的优先级都高于普通进程。 3、时间片时间片是一个数值，它表明进程在被抢占前所能持续运行的时间。调度策略必须规定一个默认的时间片。但时间片过长会导致系统对交互的响应表现欠佳，时间片太短会明显增大进程切换带来的处理器消耗时。 Linux的进程调度在Linux2.6.23内核版本中使用了新的进程调度算法，被称为“完全公平调度算法”，简称CFS CFS原理cfs定义了一种新的模型，它给cfs_rq（cfs的run queue）中的每一个进程安排一个虚拟时钟，vruntime。如果一个进程得以执行，随着时间的增长（也就是一个个tick的到来），其vruntime将不断增大。没有得到执行的进程vruntime不变。 而调度器总是选择vruntime跑得最慢的那个进程来执行。这就是所谓的“完全公平”。为了区别不同优先级的进程，优先级高的进程vruntime增长得慢，以至于它可能得到更多的运行机会。 CFS基本设计思路CFS思路很简单，就是根据各个进程的权重分配运行时间。 进程的运行时间计算公式为: 分配给进程的运行时间 = 调度周期 * 进程权重 / 所有进程权重之和 (公式1) 调度周期很好理解，就是将所有处于TASK_RUNNING态进程都调度一遍的时间。 举个例子，比如只有两个进程A, B，权重分别为1和2，调度周期设为30ms，那么分配给A的CPU时间为:30ms*(1/(1+2)) = 10ms; 而B的CPU时间为：30ms*(2/(1+2)) = 20ms。那么在这30ms中A将运行10ms，B将运行20ms。 公平怎么体现呢？它们的运行时间并不一样啊？ 其实公平是体现在另外一个量上面，叫做virtual runtime(vruntime)，它记录着进程已经运行的时间，但是并不是直接记录，而是要根据进程的权重将运行时间放大或者缩小一个比例。 我们来看下从实际运行时间到vruntime的换算公式 vruntime = 实际运行时间 * 1024 / 进程权重 (公式2) 为了不把大家搞晕，这里我直接写1024，实际上它等于nice为0的进程的权重，代码中是NICE_0_LOAD。也就是说，所有进程都以nice为0的进程的权重1024作为基准，计算自己的vruntime增加速度。 还以上面AB两个进程为例，B的权重是A的2倍，那么B的vruntime增加速度只有A的一半。现在我们把公式2中的实际运行时间用公式1来替换，可以得到这么一个结果： vruntime = (调度周期 * 进程权重 / 所有进程总权重) * 1024 / 进程权重 = 调度周期 * 1024 / 所有进程总权重 看出什么眉目没有？没错，虽然进程的权重不同，但是它们的 vruntime增长速度应该是一样的 ，与权重无关。好，既然所有进程的vruntime增长速度宏观上看应该是同时推进的，那么就可以用这个vruntime来选择运行的进程，谁的vruntime值较小就说明它以前占用cpu的时间较短，受到了“不公平”对待，因此下一个运行进程就是它。这样既能公平选择进程，又能保证高优先级进程获得较多的运行时间。这就是CFS的主要思想了。 或者可以这么理解：CFS的思想就是让每个调度实体（没有组调度的情形下就是进程，以后就说进程了）的vruntime互相追赶，而每个调度实体的vruntime增加速度不同，权重越大的增加的越慢，这样就能获得更多的cpu执行时间。 再补充一下权重的来源，权重跟进程nice值之间有一一对应的关系，可以通过全局数组prio_to_weight来转换，nice值越大，权重越低。 参考《Linux内核设计与实现》 linux内核分析——CFS（完全公平调度算法）","tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"系统调用","slug":"系统调用","permalink":"http://yoursite.com/tags/系统调用/"}]},{"title":"Linux进程管理","date":"2018-07-23T08:54:05.000Z","path":"2018/07/23/Linux进程管理/","text":"进程进程就是处于执行期的程序(目标码存放在某种存储介质上)，还包含像打开的文件、挂起的信号、内核内部数据、处理器状态等。实际上，进程就是正在执行的程序代码的实时结果。内核需要有效而透明地管理所有细节。 执行线程，简称线程，是在进程中活动的对象。每个线程都拥有一个独立的程序计数器、进程栈和一组进程寄存器。内核调度的对象是线程而不是进程。Linux系统的线程实现非常特别：它对线程和进程并不特别区别。对Linux而言，线程不过就是一种特殊的进程。 虚拟处理器：多个进程共享同一个处理器，但虚拟处理器给进程一种独占的感觉； 虚拟内存：多进程分享整个内存，但虚拟内存给进程以独占整个内存空间的感觉； 进程是处于执行期的程序以及相关资源的总称。 进程描述符及任务结构内核把进程的列表存放在叫做任务队列(task list)的双向循环链表中。链表中的每一项都是类型为task_struct、称为进程描述符的结构，该结构定义在&lt;linux/sched.h&gt;文件中。进程描述符中包含一个具体进程的所有信息。 进程状态进程描述符中的state域描述了进程的当前状态。最新的kernel进程状态值有： R状态: 分为正在执行和RQ队列等待执行两种状态，该状态是唯一可执行的状态； D状态：不影响任何信号，如果分析过一些系统冻屏/死机重启的案例，会发现很多时候是由于某个进程异常处于D状态而导致系统blocked。 即便如此，也有其存在的价值，比如当进程打开设备驱动文件时，在驱动程序执行完成之前是 不希望被打断的，可能会出现不可预知的状态。 Z状态：出现这个状态往往是父进程没有执行waitpid()或wait4()系统调用， 在这种情况下，内核不会丢弃该死亡进程的信息，系统无法判断是父进程是否还需要该信息。 进程状态转换图： 进程创建Linux进程创建： 通过fork()系统调用创建进程 Linux用户级线程创建：通过pthread库中的pthread_create()创建线程 Linux内核线程创建： 通过kthread_create()创建内核线程","tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"系统调用","slug":"系统调用","permalink":"http://yoursite.com/tags/系统调用/"}]},{"title":"Android消息处理机制","date":"2018-07-22T02:35:20.000Z","path":"2018/07/22/Android消息处理机制/","text":"Android应用程序使用消息来驱动。Android应用程序的每一个线程在启动时，都可以首先在内部创建一个消息队列，然后进入一个无限循环中，不断检查它的消息队列中是否有新的消息需要处理，那么线程就会将它从消息队列中取出，并对它进行处理，否则线程就会进入休眠等待状态。 Android系统主要通过MessageQueue、Looper和Handler三个类来实现Android消息处理机制。MessageQueue用来描述消息队列；Looper用来创建消息队列，以及进入消息循环；Handler用来发送和处理消息。 Android应用程序的消息处理机制不仅在Java代码中使用，还可以在C++代码中使用。 Java层架构图 Looper有一个MessageQueue消息队列； MessageQueue有一组待处理的Message； Message中有一个用于处理消息的Handler； Handler中有Looper和MessageQueue。 1.1创建消息队列Android应用程序消息队列MessageQueue，它可以通过Looper类的静态成员函数prepareMainLooper(主线程)或者prepare(子线程)创建，并且会在C++层中创建一个NativeMessageQueue对象【跳转2.1】。 1.2 loop消息队列创建完成后调用Looper.loop(),进入循环模式，不断重复下面的操作，直到没有消息时退出循环： 调用MessageQueue.next取出下一条Message； 把Message分发给相应的target； 再把分发后的Message回收到消息池，以便重复利用。 MessageQueue.next从MessageQueue中提取下一条message。 当前线程如何得知自己是否有新的消息需要处理？【跳转2.2】 1.3 消息发送消息发送有很多方法，最终调用的都是MessageQueue.enqueueMessage(),将消息添加到消息队列中，when为系统当前的运行时间，不包括休眠时间。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647boolean enqueueMessage(Message msg, long when) &#123; // 每一个普通Message必须有一个target if (msg.target == null) &#123; throw new IllegalArgumentException(\"Message must have a target.\"); &#125; if (msg.isInUse()) &#123; throw new IllegalStateException(msg + \" This message is already in use.\"); &#125; synchronized (this) &#123; if (mQuitting) &#123; //正在退出时，回收msg，加入到消息池 msg.recycle(); return false; &#125; msg.markInUse(); msg.when = when; Message p = mMessages; boolean needWake; if (p == null || when == 0 || when &lt; p.when) &#123; //p为null(代表MessageQueue没有消息） 或者msg的触发时间是队列中最早的， 则进入该该分支 msg.next = p; mMessages = msg; needWake = mBlocked; //当阻塞时需要唤醒 &#125; else &#123; //将消息按时间顺序插入到MessageQueue。一般地，不需要唤醒事件队列，除非 //消息队头存在barrier，并且同时Message是队列中最早的异步消息。 needWake = mBlocked &amp;&amp; p.target == null &amp;&amp; msg.isAsynchronous(); Message prev; for (;;) &#123; prev = p; p = p.next; if (p == null || when &lt; p.when) &#123; break; &#125; if (needWake &amp;&amp; p.isAsynchronous()) &#123; needWake = false; &#125; &#125; msg.next = p; prev.next = msg; &#125; //消息没有退出，我们认为此时mPtr != 0 if (needWake) &#123; nativeWake(mPtr); &#125; &#125; return true;&#125; MessageQueue是按照Message触发时间的先后顺序排列的，队头的消息是将要最早触发的消息。当有消息需要加入消息队列时，会从队列头开始遍历，直到找到消息应该插入的合适位置，以保证所有消息的时间顺序。 当插入的消息在目标消息队列的中间，由于目标消息队列头部没有发生变化，当前线程不需要对目标线程执行唤醒操作 当插入的消息在目标消息队列的头部，当前线程就需要将目标线程唤醒，使目标线程可以处理消息队列头部的消息。如果目标线程休眠，就要调用nativeWake()方法将其唤醒。【跳转2.3】 1.4 消息分发在Looper.loop()中，当发现有消息时，Message中有一个用于处理消息的Handler,调用消息的目标handler，执行dispatchMessage()方法来分发消息。 123456789101112131415public void dispatchMessage(Message msg) &#123; if (msg.callback != null) &#123; //当Message存在回调方法，回调msg.callback.run()方法； handleCallback(msg); &#125; else &#123; if (mCallback != null) &#123; //当Handler存在Callback成员变量时，回调方法handleMessage()； if (mCallback.handleMessage(msg)) &#123; return; &#125; &#125; //Handler自身的回调方法handleMessage() handleMessage(msg); &#125;&#125; 当Message的回调方法不为空时，则回调方法msg.callback.run()，其中callBack数据类型为Runnable,否则进入步骤2； 当Handler的mCallback成员变量不为空时，则回调方法mCallback.handleMessage(msg),否则进入步骤3； 调用Handler自身的回调方法handleMessage()，该方法默认为空，Handler子类通过覆写该方法来完成具体的逻辑。 平时开发中最常使用的是第三种情况，通过覆写handleMessage方法来实现自己的业务逻辑。 Native层Native架构图 2.1 创建消息队列Java层MessageQueue创建过程中调用NativeInit方法，它是由C++层中的android_os_MessageQueue_nativeInit方法实现。然后由它在C++层new MessageQueue()、new Looper()。 在C++层Looper中创建了一个管道pipe，这个管道在一个线程的消息循环过程中起到了非常大的作用。 1234567891011121314151617181920212223void Looper::rebuildEpollLocked() &#123; if (mEpollFd &gt;= 0) &#123; close(mEpollFd); //关闭旧的epoll实例 &#125; mEpollFd = epoll_create(EPOLL_SIZE_HINT); //创建新的epoll实例，并注册wake管道 struct epoll_event eventItem; memset(&amp; eventItem, 0, sizeof(epoll_event)); //把未使用的数据区域进行置0操作 eventItem.events = EPOLLIN; //可读事件 eventItem.data.fd = mWakeEventFd; //将唤醒事件(mWakeEventFd)添加到epoll实例(mEpollFd) int result = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, mWakeEventFd, &amp; eventItem); for (size_t i = 0; i &lt; mRequests.size(); i++) &#123; const Request&amp; request = mRequests.valueAt(i); struct epoll_event eventItem; request.initEventItem(&amp;eventItem); //将request队列的事件，分别添加到epoll实例 int epollResult = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, request.fd, &amp; eventItem); if (epollResult &lt; 0) &#123; ALOGE(\"Error adding epoll events for fd %d while rebuilding epoll set, errno=%d\", request.fd, errno); &#125; &#125;&#125; 通过Linux epoll机制，当一个线程没有新的消息时，它就会休眠在这个管道的读端文件描述符上，直到有新的消息需要处理；其次，当其他线程向这个线程的消息队列发送一个消息后，其他线程就会通过这个管道的写端文件描述符往这个管道写入一个数据，从而唤醒这个线程，以便它可以对刚才发送给它的消息队列中的数据进行处理。 2.2 取出消息MessageQueue.next中调用nativePollOnce方法，最终调用到C++层的Lopper.pollInner，使用epoll_wait方法监听2.1中创建的epoll实例的IO读写事件。 2.3 发送消息向目标线程发送数据，如果线程处于休眠状态，就要先将其唤醒。在2.1中知道线程使用epoll机制监听是否需要处理消息。所以当前线程要唤醒目标线程就只要向它的写端文件描述符写入一个字符，就可以将其唤醒。 Java层 和 Native层 红色虚线关系：Java层和Native层的MessageQueue通过JNI建立关联，彼此之间能相互调用，搞明白这个互调关系，也就搞明白了Java如何调用C++代码，C++代码又是如何调用Java代码。 蓝色虚线关系：Handler/Looper/Message这三大类Java层与Native层并没有任何的真正关联，只是分别在Java层和Native层的handler消息模型中具有相似的功能。都是彼此独立的，各自实现相应的逻辑。 WeakMessageHandler继承于MessageHandler类，NativeMessageQueue继承于MessageQueue类 另外，消息处理流程是先处理Native Message，再处理Native Request，最后处理Java Message。理解了该流程，也就明白有时上层消息很少，但响应时间却较长的真正原因。 总结 Handler通过sendMessage()发送Message到MessageQueue队列； Looper通过loop()，不断提取出达到触发条件的Message，并将Message交给target来处理； 经过dispatchMessage()后，交回给Handler的handleMessage()来进行相应地处理。 将Message加入MessageQueue时，处往管道写入字符，可以会唤醒loop线程；如果MessageQueue中没有Message，并处于Idle状态，则会执行IdelHandler接口中的方法，往往用于做一些清理性地工作。 参考Gityuan博客、《Android系统源代码情景分析》","tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"},{"name":"系统","slug":"系统","permalink":"http://yoursite.com/tags/系统/"}]},{"title":"Linux文件描述符","date":"2018-07-21T05:17:56.000Z","path":"2018/07/21/Linux文件描述符/","text":"概述在Linux系统中的一切都可以看成文件。对于内核而言，所有打开的文件都通过文件描述符引用。文件描述符是一个非负整数，当打开一个现有文件或是创建一个新的文件时，内核向进程返回一个文件描述符。 当读、写一个文件时，使用open或create返回的文件描述符标识该文件，并将其作为参数传递给read或write函数。 下图为标准文件描述符 文件描述符和打开文件之间的关系每一个文件描述符会与一个打开文件相对应，同时，不同的文件描述符也会指向同一个文件。相同的文件可以被不同的进程打开也可以在同一个进程中被多次打开。系统为每一个进程维护了一个文件描述符表，该表的值都是从0开始的，所以在不同的进程中你会看到相同的文件描述符，这种情况下相同文件描述符有可能指向同一个文件，也有可能指向不同的文件。具体情况要具体分析，要理解具体其概况如何，需要查看由内核维护的3个数据结构。 1. 进程级的文件描述符表 2. 系统级的打开文件描述符表 3. 文件系统的i-node表 进程级的描述符表的每一条目记录了单个文件描述符的相关信息。 1. 控制文件描述符操作的一组标志。（目前，此类标志仅定义了一个，即close-on-exec标志） 2. 对打开文件句柄的引用 内核对所有打开的文件的文件维护有一个系统级的描述符表格（open file description table）。有时，也称之为打开文件表（open file table），并将表格中各条目称为打开文件句柄（open file handle）。一个打开文件句柄存储了与一个打开文件相关的全部信息，如下所示： 1. 当前文件偏移量（调用read()和write()时更新，或使用lseek()直接修改） 2. 打开文件时所使用的状态标识（即，open()的flags参数） 3. 文件访问模式（如调用open()时所设置的只读模式、只写模式或读写模式） 4. 与信号驱动相关的设置 5. 对该文件i-node对象的引用 6. 文件类型（例如：常规文件、套接字或FIFO）和访问权限 7. 一个指针，指向该文件所持有的锁列表 8. 文件的各种属性，包括文件大小以及与不同类型操作相关的时间戳 下图展示了文件描述符、打开的文件句柄以及i-node之间的关系，图中，两个进程拥有诸多打开的文件描述符。 在进程A中，文件描述符1和30都指向了同一个打开的文件句柄（标号23）。这可能是通过调用dup()、dup2()、fcntl()或者对同一个文件多次调用了open()函数而形成的。 进程A的文件描述符2和进程B的文件描述符2都指向了同一个打开的文件句柄（标号73）。这种情形可能是在调用fork()后出现的（即，进程A、B是父子进程关系），或者当某进程通过UNIX域套接字将一个打开的文件描述符传递给另一个进程时，也会发生。再者是不同的进程独自去调用open函数打开了同一个文件，此时进程内部的描述符正好分配到与其他进程打开该文件的描述符一样。 此外，进程A的描述符0和进程B的描述符3分别指向不同的打开文件句柄，但这些句柄均指向i-node表的相同条目（1976），换言之，指向同一个文件。发生这种情况是因为每个进程各自对同一个文件发起了open()调用。同一个进程两次打开同一个文件，也会发生类似情况。 总结 由于进程级文件描述符表的存在，不同的进程中会出现相同的文件描述符，它们可能指向同一个文件，也可能指向不同的文件 两个不同的文件描述符，若指向同一个打开文件句柄，将共享同一文件偏移量。因此，如果通过其中一个文件描述符来修改文件偏移量（由调用read()、write()或lseek()所致），那么从另一个描述符中也会观察到变化，无论这两个文件描述符是否属于不同进程，还是同一个进程，情况都是如此。 要获取和修改打开的文件标志（例如：O_APPEND、O_NONBLOCK和O_ASYNC），可执行fcntl()的F_GETFL和F_SETFL操作，其对作用域的约束与上一条颇为类似。 文件描述符标志（即，close-on-exec）为进程和文件描述符所私有。对这一标志的修改将不会影响同一进程或不同进程中的其他文件描述符 部分转载自 http://blog.csdn.net/cywosp/article/details/38965239","tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"系统调用","slug":"系统调用","permalink":"http://yoursite.com/tags/系统调用/"}]},{"title":"I/O多路转换select、poll、epoll","date":"2018-07-21T01:47:22.000Z","path":"2018/07/21/I-O多路转换select、poll/","text":"构造一张我们感兴趣的描述符的列表，然后调用一个函数，直到这些描述符中的一个已经准备好进行I/O操作时，该函数才返回。 在Linux系统中可以使用select、poll、pselect等函数执行I/O多路转换，在从这些函数返回时，进程会被告知哪些描述符已经准备好可以进行I/O。 select系统调用select()会一直阻塞，直到一个或者多个文件描述符集合成为就绪态。 12int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select函数的第一个参数nfds取值为最大描述符加1，意思是在后面三个读、写、异常描述符集参数中找到最大描述符，然后加1。 readfds、writefds、exceptfds是指向描述符集的指针，这三个描述符集说明了我们关心的可读、可写或处于异常条件的各个描述符，每个描述符集存放在一个fd_set数据结构中，为每一可能的描述符保持了一位。 传向select的参数告诉内核：我们所关心的描述符；对于每个描述符我们所关心的状态，读、写和异常；愿意等待多长时间，不等待、等待若干时间或无限等待。 从select返回时，内核告诉我们：已准备好的描述符的数量；对于读、写或异常这三个状态中的一个，哪些描述符已准备好。使用这些返回信息，就可调用相应的IO函数，如read/write，并且确知该函数不会阻塞。select出错返回-1，并设置对应的errno，timeout超时返回0。 pollpoll()和select()很相似。两者的主要区别在于我们要如何指定待检查的文件描述符。 1234567int poll(struct pollfd *fds, nfds_t nfds, int timeout);struct pollfd &#123; int fd; /* file descriptor */ short events; /* requested events */ short revents; /* returned events */&#125;; poll关心的描述符通过pollfd数组设置，pollfd个数为nfds，其中fd为待处理的描述符，events为我们想要描述符处理的事件，包括读、写事件，如POLLIN表示是否有数据可读，由用户通过按位或操作符指定，revents是poll函数的执行结果，告诉我们响应了哪些事件，可通过按位与操作符检查。timeout单位为秒。 select、poll的缺点poll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。 epollepoll是对select和poll的改进。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。epoll机制是Linux最高效的I/O复用机制，在一处等待多个文件句柄的I/O事件。 epoll提供了三个函数，epoll_create,epoll_ctl和epoll_wait。 1234#include &lt;sys/epoll.h&gt;int epoll_create(int size);int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); (1) int epoll_create(int size)创建一个epoll的句柄(实例)，size指定了我们想要通过epoll实例来检查的文件描述符个数。该参数不是一个上限，而是告诉内核应该如何为内部数据结构划分厨师大小。 需要注意的是，当创建好epoll句柄后，它就是会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。 (2) int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)epoll的事件注册函数，它不同与select()是在监听事件时告诉内核要监听什么类型的事件，而是在这里先注册要监听的事件类型。 第一个参数是epoll_create()的返回值 第二个参数表示动作，用三个宏来表示： EPOLL_CTL_ADD：注册新的fd到epfd中； EPOLL_CTL_MOD：修改已经注册的fd的监听事件； EPOLL_CTL_DEL：从epfd中删除一个fd； 第三个参数是需要监听的fd，第四个参数是告诉内核需要监听什么事，struct epoll_event结构如下： 1234struct epoll_event &#123; __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */&#125;; events可以是以下几个宏的集合： EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）； EPOLLOUT：表示对应的文件描述符可以写； EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）； EPOLLERR：表示对应的文件描述符发生错误； EPOLLHUP：表示对应的文件描述符被挂断； EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。 EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里 (3) int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout)等待事件的产生，类似于select()调用。参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。 工作模式epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下： LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。 ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。 ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"系统调用","slug":"系统调用","permalink":"http://yoursite.com/tags/系统调用/"}]},{"title":"Android应用程序进程启动","date":"2018-07-20T12:39:53.000Z","path":"2018/07/20/Android应用程序进程启动/","text":"ActivityManagerService(AMS)在启动一个应用程序组件时，如果发现这个组件所需要的应用程序进程还没有启动起来，AMS就会请求Zygote进程将这个应用进程启动起来。 进程创建的流程如下图(图片来自Gityuan博客) system_server进程通过Socket连接到zygote进程(zygote进程创建时就有一个Socket服务等待连接)，将要创建的应用程序进程的启动参数传给zygote进程。zygote进程fork创建一个新的应用程序进程，并将这个新创建的进程PID返回给AMS。 Zygote进程是通过复制自身的方式来创建一个新的应用程序进程。由于Zygote进程在启动的时候会在内部创建一个虚拟机实例，因此，通过复制它而得到的应用程序进程就很自然得获得了一个虚拟机实例的拷贝。有了这个虚拟机实例后，这个应用程序进程就可以将使用Java开发的应用程序组件运行起来了。 应用程序进程在启动的过程中还会创建一个Binder线程池和一个消息循环。","tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"},{"name":"系统","slug":"系统","permalink":"http://yoursite.com/tags/系统/"}]},{"title":"AMS启动","date":"2018-07-20T03:07:39.000Z","path":"2018/07/20/ActivityManagerService/","text":"startBootstrapServices在SystemServer.run方法中startBootstrapServices() 12345678910111213private void startBootstrapServices() &#123; Installer installer = mSystemServiceManager.startService(Installer.class); //启动AMS服务 mActivityManagerService = mSystemServiceManager.startService( ActivityManagerService.Lifecycle.class).getService(); //设置AMS的系统服务管理器 mActivityManagerService.setSystemServiceManager(mSystemServiceManager); //设置AMS的APP安装器 mActivityManagerService.setInstaller(installer); ... //设置SystemServer mActivityManagerService.setSystemProcess(); &#125; mSystemServiceManager.startService(ActivityManagerService.Lifecycle.class)功能： 创建ActivityManagerService.Lifecycle对象； 调用Lifecycle.onStart()方法。 123456789101112131415161718public static final class Lifecycle extends SystemService &#123; private final ActivityManagerService mService; public Lifecycle(Context context) &#123; super(context); //创建ActivityManagerService mService = new ActivityManagerService(context); &#125; @Override public void onStart() &#123; mService.start(); &#125; public ActivityManagerService getService() &#123; return mService; &#125;&#125; 在Lifecycle中创建AMS实例对象，并调用AMS.start();在new ActivityManagerService(context)创建了三个线程，分别为”ActivityManager”，”android.ui”，”CpuTracker”。 setSystemProcess12345678910111213141516171819202122232425262728293031323334public void setSystemProcess() &#123; try &#123; ServiceManager.addService(Context.ACTIVITY_SERVICE, this, true); //AMS ServiceManager.addService(ProcessStats.SERVICE_NAME, mProcessStats); //进程统计 ServiceManager.addService(\"meminfo\", new MemBinder(this)); //内存 ServiceManager.addService(\"gfxinfo\", new GraphicsBinder(this)); //图像信息 ServiceManager.addService(\"dbinfo\", new DbBinder(this)); //数据库 if (MONITOR_CPU_USAGE) &#123; ServiceManager.addService(\"cpuinfo\", new CpuBinder(this)); //CPU &#125; ServiceManager.addService(\"permission\", new PermissionController(this)); //权限 ServiceManager.addService(\"processinfo\", new ProcessInfoService(this)); //进程服务 ApplicationInfo info = mContext.getPackageManager().getApplicationInfo( \"android\", STOCK_PM_FLAGS); mSystemThread.installSystemApplicationInfo(info, getClass().getClassLoader()); synchronized (this) &#123; //创建ProcessRecord对象 ProcessRecord app = newProcessRecordLocked(info, info.processName, false, 0); app.persistent = true; //设置为persistent进程 app.pid = MY_PID; app.maxAdj = ProcessList.SYSTEM_ADJ; app.makeActive(mSystemThread.getApplicationThread(), mProcessStats); synchronized (mPidsSelfLocked) &#123; mPidsSelfLocked.put(app.pid, app); &#125; updateLruProcessLocked(app, false, null);//维护进程lru updateOomAdjLocked(); //更新adj &#125; &#125; catch (PackageManager.NameNotFoundException e) &#123; throw new RuntimeException(\"\", e); &#125;&#125; 该方法主要就是注册各种服务到ServiceManager。 startOtherServices()12345678910111213141516171819202122232425262728293031323334353637383940414243444546private void startOtherServices() &#123; //安装系统Provider mActivityManagerService.installSystemProviders(); ... mActivityManagerService.systemReady(new Runnable() &#123; public void run() &#123; //phase550 mSystemServiceManager.startBootPhase( SystemService.PHASE_ACTIVITY_MANAGER_READY); mActivityManagerService.startObservingNativeCrashes(); //启动WebView WebViewFactory.prepareWebViewInSystemServer(); //启动系统UI startSystemUi(context); // 执行一系列服务的systemReady方法 networkScoreF.systemReady(); networkManagementF.systemReady(); networkStatsF.systemReady(); networkPolicyF.systemReady(); connectivityF.systemReady(); audioServiceF.systemReady(); Watchdog.getInstance().start(); //Watchdog开始工作 //phase600 mSystemServiceManager.startBootPhase( SystemService.PHASE_THIRD_PARTY_APPS_CAN_START); //执行一系列服务的systemRunning方法 wallpaper.systemRunning(); inputMethodManager.systemRunning(statusBarF); location.systemRunning(); countryDetector.systemRunning(); networkTimeUpdater.systemRunning(); commonTimeMgmtService.systemRunning(); textServiceManagerService.systemRunning(); assetAtlasService.systemRunning(); inputManager.systemRunning(); telephonyRegistry.systemRunning(); mediaRouter.systemRunning(); mmsService.systemRunning(); &#125; &#125;);&#125; 总结 创建AMS实例对象，创建Andoid Runtime，ActivityThread和Context对象； setSystemProcess：注册AMS、meminfo、cpuinfo等服务到ServiceManager； installSystemProviderss，加载SettingsProvider； 启动SystemUIService，再调用一系列服务的systemReady()方法；","tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"},{"name":"系统","slug":"系统","permalink":"http://yoursite.com/tags/系统/"}]},{"title":"Zygote和SystemServer","date":"2018-07-19T12:22:23.000Z","path":"2018/07/19/Zygote和SystemServer/","text":"ZygoteAndroid中所有的应用程序进程都是由Zygote进程通过复制自身的方式创建的，因此将它称为进程孵化器。Zygote进程是Android系统的第一个进程init启动的。 init进程init是Linux系统中用户空间的第一个进程，进程号为1。kernel启动后，在用户空间启动init进程，并调用main()方法执行init的职责： 分析和运行所有的init.rc文件 生成设备驱动节点(通过rc文件创建) 处理子进程的终止 提供属性服务(property) 启动Zygote服务启动脚本在init.zygote.rc文件中定义了Zygote服务： 12service zygote /system/bin/app_process -Xzygote /system/bin --zygote --start-system-server socket zygote stream 660 root system 第一行表示Zygote进程是以服务的方式启动，对应应用程序文件是/system/bin/app_process,start-system-server表示Zygote进程启动结束后需要将System进程也启动。 第二行表示在启动过程中创建一个名为“zygote”的Socket。这个Socket用来执行进程间通信。AMS就是通过这个Socket来请求Zygote进程创建新的应用程序进程的。 进程启动 解析init.zygote.rc中的参数，创建AppRuntime并调用AppRuntime.start()方法； 调用AndroidRuntime的startVM()方法创建虚拟机，再调用startReg()注册JNI函数； 通过JNI方式调用ZygoteInit.main()，第一次进入Java世界； registerZygoteSocket()建立socket通道，zygote作为通信的服务端，用于响应客户端请求； preload()预加载通用类、drawable和color资源、openGL以及共享库以及WebView，用于提高app启动效率； zygote完毕大部分工作，接下来再通过startSystemServer()，fork得力帮手system_server进程，也是上层framework的运行载体。 zygote功成身退，调用runSelectLoop()，随时待命，当接收到请求创建新进程请求时立即唤醒并执行相应工作。 SystemServerZygote进程启动中fork了SystemServer，进程名为system_server，该进程承载着framework的核心服务。 在SystemServer启动过程中加载各种系统服务。 startBootstrapServices() //引导服务 startCoreServices(). //核心服务 startOtherServices(). //其他服务 引导服务(7个)：ActivityManagerService、PowerManagerService、LightsService、DisplayManagerService、PackageManagerService、UserManagerService、SensorService；核心服务(3个)：BatteryService、UsageStatsService、WebViewUpdateService；其他服务(70个+)：AlarmManagerService、VibratorService等。 所有服务启动完成即系统启动完成，调用AMS.finishBooting(),system_server进程进入Looper.loop()状态，等待消息到来。 参考资料：Android系统启动-zygote篇 Gityuan、《Android系统源代码情景分析》","tags":[{"name":"Android","slug":"Android","permalink":"http://yoursite.com/tags/Android/"},{"name":"系统","slug":"系统","permalink":"http://yoursite.com/tags/系统/"}]},{"title":"编译时注解Kapt","date":"2018-07-16T11:59:53.000Z","path":"2018/07/16/编译时注解Kapt/","text":"注解一个注解允许你把额外的元数据关联到一个声明上。然后元数据就可以被相关的源代码工具访问，通过编译好的类文件或是在运行时，取决于这个注解是如何配置的。 –《Kotlin in Action》 注解（也被成为元数据）为我们在代码中添加信息提供了一种形式化的方法，使我们可以在稍后某个时刻非常方便地使用这些数据。 –《Thinging in Java》 在Java和Kotlin中声明注解的方式还是有些差异： 123456789101112Java:public @interface MyAnnotation &#123;&#125;public @interface MyAnnotation2&#123; String value();&#125;Kotlin:annotation class MyAnnotationannotation class MyAnnotation2(val value:String) 元注解可以应用到注解类上的注解被称为元注解。比较常见的元注解有@Target、@Retention 123@Target(AnnotationTarget.ANNOTATION_CLASS)@MustBeDocumentedpublic annotation class Target(vararg val allowedTargets: AnnotationTarget) 123456789101112131415161718192021222324252627282930313233public enum class AnnotationTarget &#123; /** Class, interface or object, annotation class is also included */ CLASS, /** Annotation class only */ ANNOTATION_CLASS, /** Generic type parameter (unsupported yet) */ TYPE_PARAMETER, /** Property */ PROPERTY, /** Field, including property's backing field */ FIELD, /** Local variable */ LOCAL_VARIABLE, /** Value parameter of a function or a constructor */ VALUE_PARAMETER, /** Constructor only (primary or secondary) */ CONSTRUCTOR, /** Function (constructors are not included) */ FUNCTION, /** Property getter only */ PROPERTY_GETTER, /** Property setter only */ PROPERTY_SETTER, /** Type usage */ TYPE, /** Any expression */ EXPRESSION, /** File */ FILE, /** Type alias */ @SinceKotlin(\"1.1\") TYPEALIAS&#125; Target表明你的注解可以被应用的元素类型，包括类、文件、函数、属性等，如果需要你可以声明多个对象。 12@Target(AnnotationTarget.ANNOTATION_CLASS)public annotation class Retention(val value: AnnotationRetention = AnnotationRetention.RUNTIME) 12345678public enum class AnnotationRetention &#123; /** Annotation isn't stored in binary output */ SOURCE, /** Annotation is stored in binary output, but invisible for reflection */ BINARY, /** Annotation is stored in binary output and visible for reflection (default retention) */ RUNTIME&#125; Retention被用来说明你声明的注解是否会被存储到.class文件，以及在运行时是否可以通过反射来访问它。 注解分类从取值的方式来说可以分为两类：编译时注解和运行时注解。 运行时注解使用反射在程序运行时操作。目前最著名的使用运行时注解的开源库就是Retrofit。（由于运行时注解使用了反射，必然会影响到效率) 编译时注解顾名思义，就是编译时去处理的注解。dagger，butterKnife，包括谷data binding，都用到了编译时注解。其核心就是编译时注解+APT+动态生成字节码。 APT和KAPTAPT (Annotation Processor Tool):注解处理器是一个在javac中的，用来编译时扫描和处理的注解的工具。你可以为特定的注解，注册你自己的注解处理器。注解处理器可以生成Java代码，这些生成的Java代码会组成 .java 文件，但不能修改已经存在的Java类（即不能向已有的类中添加方法）。而这些生成的Java文件，会同时与其他普通的手写Java源代码一起被javac编译。KAPT与APT完全相同，只是在Kotlin下的注解处理器。 实例使用编译时注解+APT+动态生成字节码完成了一个butterKnife最基础的findViewById的功能，适合入门学习。 一、声明注解在项目中新建一个java library，声明两个注解，一个用来注解类，一个用来注解。 12345678@Target(AnnotationTarget.CLASS)@Retention(AnnotationRetention.SOURCE)annotation class MyClass@Target(AnnotationTarget.FIELD)@Retention(AnnotationRetention.SOURCE)annotation class findView(val value: Int = -1) 使用注解 1234567891011121314@MyClassclass MainActivity : Activity() &#123; @findView(R.id.text1) var text123: TextView? = null @findView(R.id.text2) var text2: TextView? = null override fun onCreate(savedInstanceState: Bundle?) &#123; super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) &#125;&#125; 二、获取注解创建一个类继承自AbstractProcessor 123456789101112131415161718@AutoService(Processor::class)@SupportedSourceVersion(SourceVersion.RELEASE_8)class MyProcessor : AbstractProcessor() &#123; override fun getSupportedAnnotationTypes(): Set&lt;String&gt; &#123; return setOf(MyClass::class.java.canonicalName) &#125; override fun init(processingEnv: ProcessingEnvironment) &#123; super.init(processingEnv) &#125; override fun process(annotations: MutableSet&lt;out TypeElement&gt;, roundEnv: RoundEnvironment): Boolean &#123; return true &#125;&#125; 三、动态生成字节码使用kotlinpoet动态生成代码 1234567891011121314151617181920212223242526272829303132333435363738override fun process(annotations: MutableSet&lt;out TypeElement&gt;, roundEnv: RoundEnvironment): Boolean &#123; mLogger.info(\"processor start\") //获取所有用@MyClass注解的类 val elements = roundEnv.getElementsAnnotatedWith(MyClass::class.java) elements.forEach &#123; val typeElement = it as TypeElement val members = elementUtils!!.getAllMembers(typeElement) //创建一个bingdView的方法，参数为activity，并使用JvmStatic注解 val bindFunBuilder = FunSpec.builder(\"bindView\").addParameter(\"activity\", typeElement.asClassName()).addAnnotation(JvmStatic::class.java) members.forEach &#123; //获取所有@findview注解的属性 val find: findView? = it.getAnnotation(findView::class.java) if (find != null) &#123; mLogger.info(\"find annotation \" + it.simpleName) //方法中添加findviewById bindFunBuilder.addStatement(\"activity.$&#123;it.simpleName&#125; = activity.findViewById($&#123;find.value&#125;)\") &#125; &#125; val bindFun = bindFunBuilder.build() //生成一个由@MyClass注解的类的名称加_bindView后缀的类，其中有一个静态方法bindView val file = FileSpec.builder(getPackageName(typeElement), it.simpleName.toString()+\"_bindView\") .addType(TypeSpec.classBuilder(it.simpleName.toString()+\"_bindView\") .addType(TypeSpec.companionObjectBuilder() .addFunction(bindFun) .build()) .build()) .build() file.writeFile() &#125; mLogger.info(\"end\") return true &#125; 编译代码，本例就会在build下生成一个MainActivity_bindView的类，其中有一个静态方法bindview，传入的参数是activity，方法中是我们注解的text123和text2的findviewById。只要在Activity启动时调用这个静态方法就可以实现View的绑定。 四、调用在MainActivity中调用静态方法就可以绑定View，但是由于这个类是编译时生成的，在MainActivity中其实并不知道有这个类存在，无法直接调用。这个时候就要使用反射了。我们在生成类的时候使用“类名”+“_bindView”的方式，知道了静态方法的类名就可以使用反射执行方法了。 12345678910111213class MyKapt &#123; companion object &#123; fun bindView(target: Any) &#123; val classs = target.javaClass val claName = classs.name + \"_bindView\" val clazz = Class.forName(claName) val bindMethod = clazz.getMethod(\"bindView\", target::class.java) val ob = clazz.newInstance() bindMethod.invoke(ob, target) &#125; &#125;&#125; MainActivity中： 12345override fun onCreate(savedInstanceState: Bundle?) &#123; super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) MyKapt.bindView(this) &#125; 搞定！这是我写的简单Demo项目Demo","tags":[{"name":"编译时注解","slug":"编译时注解","permalink":"http://yoursite.com/tags/编译时注解/"},{"name":"KAPT","slug":"KAPT","permalink":"http://yoursite.com/tags/KAPT/"}]},{"title":"Linux内存映射","date":"2018-07-16T08:07:51.000Z","path":"2018/07/16/内存映射mmap/","text":"概述内存映射简单来说就是将内核空间的一段内存区域映射到用户空间，这样用户对这段内存区域的修改可以直接反映到内核空间，相反，内核空间对这段区域的修改也可以反映到用户空间。在这样对于内核空间和用户空间之间需要大量数据传输等操作的话效率非常高。 mmap()函数就是在Linux系统中用来实现内存映射的。 映射分为两种： 文件映射：将一个文件的一部分直接映射到调用进程的虚拟内存中。一旦一个文件被映射后就可以通过在相应的内存区域中操作字节来访问文件内容了。 匿名映射：一个匿名映射没有对应的文件。（就是用户空间需要分配一定的物理内存来存储数据,这部分内存不属于任何文件,内核就使用匿名映射将内存中的某段物理地址与用户空间一一映射,这样用户就可用直接操作虚拟地址范围的这段物理内存） 在代码中,文件映射的操作就是:open,read,write,close,mmap… 操作的虚拟地址都属于文件映射。 malloc 分配的虚拟地址属于匿名映射. mmap()函数用户空间mmap()函数void *mmap(void *addr, size_t length, int prot, int flags,int fd, off_t offset)，下面就其参数解释如下： start：用户进程中要映射的用户空间的起始地址，通常为NULL（由内核来指定）length：要映射的内存区域的大小prot：期望的内存保护标志flags：指定映射对象的类型fd：文件描述符（由open函数返回）offset：设置在内核空间中已经分配好的的内存区域中的偏移，例如文件的偏移量，大小为PAGE_SIZE的整数倍返回值：mmap()返回被映射区的指针，该指针就是需要映射的内核空间在用户空间的虚拟地址 映射共享 一个进程的映射中的内存可以与其他进程中的映射共享（即各个进程的页表条目指向RAM中相同分页）。这种情况会在两种情况下发生： 当两个进程映射了同一个文件的同一个区域时它们会共享物理内存的相同分页。 通过fork()创建的子进程会继承其父进程的映射的副本，并且这些映射所引用的物理内存分页与父进程中相应映射所引用的分页相同。 当两个或更多个进程共享相同分页时，每个进程都有可能看到其他进程对分页内容做出的变更，当然要取决于映射是私有的还是共享的。 私有映射(MAP_PRIVATE)：在映射内容上发生的变更对其他进程不可见，对于文件映射来说，变更将不会在底层文件上进行。内核使用写时复制(copy-on-write)技术完成了这个任务。这意味着当一个进程试图修改一个分页的内容时，内核首先会为该进程创建一个新的分页并将需要修改的分页中的数据复制到新分页中。 共享映射(MAP_SHARED)：变更对所有共享映射的进程可见。 各种内存映射的用途","tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"系统调用","slug":"系统调用","permalink":"http://yoursite.com/tags/系统调用/"}]}]